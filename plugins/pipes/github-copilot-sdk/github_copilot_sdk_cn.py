"""
title: GitHub Copilot Official SDK Pipe
author: Fu-Jie
author_url: https://github.com/Fu-Jie/awesome-openwebui
funding_url: https://github.com/open-webui
openwebui_id: ce96f7b4-12fc-4ac3-9a01-875713e69359
description: é›†æˆ GitHub Copilot SDKã€‚æ”¯æŒåŠ¨æ€æ¨¡å‹ã€å¤šè½®å¯¹è¯ã€æµå¼è¾“å‡ºã€å¤šæ¨¡æ€è¾“å…¥ã€æ— é™ä¼šè¯åŠå‰ç«¯è°ƒè¯•æ—¥å¿—ã€‚
version: 0.2.3
requirements: github-copilot-sdk
"""

import os
import time
import json
import base64
import tempfile
import asyncio
import logging
import shutil
import subprocess
import sys
from typing import Optional, Union, AsyncGenerator, List, Any, Dict
from pydantic import BaseModel, Field
from datetime import datetime, timezone
import contextlib

# å¯¼å…¥ Copilot SDK æ¨¡å—
from copilot import CopilotClient, define_tool

# Setup logger
logger = logging.getLogger(__name__)


class RandomNumberParams(BaseModel):
    min: int = Field(description="æœ€å°å€¼ï¼ˆåŒ…å«ï¼‰")
    max: int = Field(description="æœ€å¤§å€¼ï¼ˆåŒ…å«ï¼‰")


@define_tool(description="åœ¨æŒ‡å®šèŒƒå›´å†…ç”Ÿæˆéšæœºæ•´æ•°ã€‚")
async def generate_random_number(params: RandomNumberParams) -> str:
    import random

    if params.min >= params.max:
        raise ValueError("min å¿…é¡»å°äº max")
    number = random.randint(params.min, params.max)
    return f"ç”Ÿæˆçš„éšæœºæ•°: {number}"


class Pipe:
    class Valves(BaseModel):
        GH_TOKEN: str = Field(
            default="",
            description="GitHub ç»†ç²’åº¦ Tokenï¼ˆéœ€è¦ Copilot Requests æƒé™ï¼‰",
        )
        MODEL_ID: str = Field(
            default="gpt-5-mini",
            description="é»˜è®¤ Copilot æ¨¡å‹åï¼ˆåŠ¨æ€è·å–å¤±è´¥æ—¶ä½¿ç”¨ï¼‰",
        )
        CLI_PATH: str = Field(
            default="/usr/local/bin/copilot",
            description="Copilot CLI è·¯å¾„",
        )
        DEBUG: bool = Field(
            default=False,
            description="å¯ç”¨æŠ€æœ¯è°ƒè¯•æ—¥å¿—ï¼ˆè¿æ¥ä¿¡æ¯ç­‰ï¼‰",
        )
        LOG_LEVEL: str = Field(
            default="error",
            description="Copilot CLI æ—¥å¿—çº§åˆ«ï¼šnone, error, warning, info, debug, all",
        )
        SHOW_THINKING: bool = Field(
            default=True,
            description="æ˜¾ç¤ºæ¨¡å‹æ¨ç†/æ€è€ƒè¿‡ç¨‹",
        )
        SHOW_WORKSPACE_INFO: bool = Field(
            default=True,
            description="è°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤ºä¼šè¯å·¥ä½œç©ºé—´è·¯å¾„ä¸æ‘˜è¦",
        )
        EXCLUDE_KEYWORDS: str = Field(
            default="",
            description="æ’é™¤åŒ…å«è¿™äº›å…³é”®è¯çš„æ¨¡å‹ï¼ˆé€—å·åˆ†éš”ï¼Œå¦‚ï¼šcodex, haikuï¼‰",
        )
        WORKSPACE_DIR: str = Field(
            default="",
            description="æ–‡ä»¶æ“ä½œçš„å—é™å·¥ä½œåŒºç›®å½•ï¼›ä¸ºç©ºåˆ™ä½¿ç”¨å½“å‰è¿›ç¨‹ç›®å½•",
        )
        INFINITE_SESSION: bool = Field(
            default=True,
            description="å¯ç”¨æ— é™ä¼šè¯ï¼ˆè‡ªåŠ¨ä¸Šä¸‹æ–‡å‹ç¼©ï¼‰",
        )
        COMPACTION_THRESHOLD: float = Field(
            default=0.8,
            description="åå°å‹ç¼©é˜ˆå€¼ (0.0-1.0)",
        )
        BUFFER_THRESHOLD: float = Field(
            default=0.95,
            description="ç¼“å†²åŒºè€—å°½é˜ˆå€¼ (0.0-1.0)",
        )
        TIMEOUT: int = Field(
            default=300,
            description="æ¯ä¸ªæµå¼åˆ†å—è¶…æ—¶ï¼ˆç§’ï¼‰",
        )
        CUSTOM_ENV_VARS: str = Field(
            default="",
            description='è‡ªå®šä¹‰ç¯å¢ƒå˜é‡ï¼ˆJSON æ ¼å¼ï¼Œä¾‹å¦‚ {"VAR": "value"}ï¼‰',
        )
        ENABLE_TOOLS: bool = Field(
            default=False,
            description="å¯ç”¨è‡ªå®šä¹‰å·¥å…·ï¼ˆä¾‹å¦‚ï¼šéšæœºæ•°ï¼‰",
        )
        AVAILABLE_TOOLS: str = Field(
            default="all",
            description="å¯ç”¨å·¥å…·ï¼š'all' æˆ–é€—å·åˆ†éš”åˆ—è¡¨ï¼ˆä¾‹å¦‚ï¼š'generate_random_number'ï¼‰",
        )
        REASONING_EFFORT: str = Field(
            default="medium",
            description="æ¨ç†å¼ºåº¦çº§åˆ«: low, medium, high. (gpt-5.2-codex é¢å¤–æ”¯æŒ xhigh)",
        )
        ENFORCE_FORMATTING: bool = Field(
            default=True,
            description="åœ¨ç³»ç»Ÿæç¤ºè¯ä¸­æ·»åŠ æ ¼å¼åŒ–æŒ‡å¯¼ï¼Œä»¥æé«˜è¾“å‡ºçš„å¯è¯»æ€§ï¼ˆæ®µè½ã€æ¢è¡Œã€ç»“æ„ï¼‰ã€‚",
        )

    class UserValves(BaseModel):
        REASONING_EFFORT: str = Field(
            default="",
            description="æ¨ç†å¼ºåº¦çº§åˆ« (low, medium, high, xhigh)ã€‚ç•™ç©ºä»¥ä½¿ç”¨å…¨å±€è®¾ç½®ã€‚",
        )
        CLI_PATH: str = Field(
            default="",
            description="è‡ªå®šä¹‰ Copilot CLI è·¯å¾„ã€‚ç•™ç©ºä»¥ä½¿ç”¨å…¨å±€è®¾ç½®ã€‚",
        )
        DEBUG: bool = Field(
            default=False,
            description="å¯ç”¨æŠ€æœ¯è°ƒè¯•æ—¥å¿—ï¼ˆè¿æ¥ä¿¡æ¯ç­‰ï¼‰",
        )
        SHOW_THINKING: bool = Field(
            default=True,
            description="æ˜¾ç¤ºæ¨¡å‹æ¨ç†/æ€è€ƒè¿‡ç¨‹",
        )
        MODEL_ID: str = Field(
            default="",
            description="è‡ªå®šä¹‰æ¨¡å‹ ID (ä¾‹å¦‚ gpt-4o)ã€‚ç•™ç©ºä»¥ä½¿ç”¨å…¨å±€é»˜è®¤å€¼ã€‚",
        )

    def __init__(self):
        self.type = "pipe"
        self.id = "copilotsdk"
        self.name = "copilotsdk"
        self.valves = self.Valves()
        self.temp_dir = tempfile.mkdtemp(prefix="copilot_images_")
        self.thinking_started = False
        self._model_cache = []  # æ¨¡å‹åˆ—è¡¨ç¼“å­˜

    def __del__(self):
        try:
            shutil.rmtree(self.temp_dir)
        except:
            pass

    # ==================== ç³»ç»Ÿå›ºå®šå…¥å£ ====================
    # pipe() æ˜¯ OpenWebUI è°ƒç”¨çš„ç¨³å®šå…¥å£ã€‚
    # å°†è¯¥éƒ¨åˆ†æ”¾åœ¨å‰é¢ï¼Œä¾¿äºå¿«é€Ÿå®šä½ä¸ç»´æŠ¤ã€‚
    # ======================================================
    async def pipe(
        self,
        body: dict,
        __metadata__: Optional[dict] = None,
        __user__: Optional[dict] = None,
        __event_emitter__=None,
        __event_call__=None,
    ) -> Union[str, AsyncGenerator]:
        return await self._pipe_impl(
            body,
            __metadata__=__metadata__,
            __user__=__user__,
            __event_emitter__=__event_emitter__,
            __event_call__=__event_call__,
        )

    # ==================== åŠŸèƒ½æ€§åˆ†åŒºè¯´æ˜ ====================
    # 1) å·¥å…·æ³¨å†Œï¼šå®šä¹‰å·¥å…·å¹¶åœ¨ _initialize_custom_tools ä¸­æ³¨å†Œ
    # 2) è°ƒè¯•æ—¥å¿—ï¼š_emit_debug_log / _emit_debug_log_sync
    # 3) æç¤ºè¯/ä¼šè¯ï¼š_extract_system_prompt / _build_session_config / _build_prompt
    # 4) è¿è¡Œæµç¨‹ï¼špipe() è´Ÿè´£è¯·æ±‚ï¼Œstream_response() è´Ÿè´£æµå¼è¾“å‡º
    # ======================================================
    # ==================== è‡ªå®šä¹‰å·¥å…·ç¤ºä¾‹ ====================
    # å·¥å…·æ³¨å†Œï¼šåœ¨æ¨¡å—çº§åˆ«æ·»åŠ  @define_tool è£…é¥°çš„å‡½æ•°ï¼Œ
    # ç„¶ååœ¨ _initialize_custom_tools() çš„ all_tools å­—å…¸ä¸­æ³¨å†Œã€‚

    def _extract_text_from_content(self, content) -> str:
        """ä»å„ç§æ¶ˆæ¯å†…å®¹æ ¼å¼ä¸­æå–æ–‡æœ¬å†…å®¹"""
        if isinstance(content, str):
            return content
        elif isinstance(content, list):
            text_parts = []
            for item in content:
                if isinstance(item, dict) and item.get("type") == "text":
                    text_parts.append(item.get("text", ""))
            return " ".join(text_parts)
        return ""

    def _apply_formatting_hint(self, prompt: str) -> str:
        """åœ¨å¯ç”¨æ ¼å¼åŒ–æ—¶ï¼Œå‘ç”¨æˆ·æç¤ºè¯è¿½åŠ è½»é‡æ ¼å¼åŒ–è¦æ±‚ã€‚"""
        if not self.valves.ENFORCE_FORMATTING:
            return prompt

        if not prompt:
            return prompt

        if "[æ ¼å¼åŒ–æŒ‡å—]" in prompt or "[æ ¼å¼åŒ–è¦æ±‚]" in prompt:
            return prompt

        formatting_hint = (
            "\n\n[æ ¼å¼åŒ–è¦æ±‚]\n" "è¯·ä½¿ç”¨æ¸…æ™°çš„æ®µè½ä¸æ¢è¡Œï¼Œå¿…è¦æ—¶ä½¿ç”¨é¡¹ç›®ç¬¦å·åˆ—è¡¨ã€‚"
        )
        return f"{prompt}{formatting_hint}"

    def _dedupe_preserve_order(self, items: List[str]) -> List[str]:
        """å»é‡ä¿åº"""
        seen = set()
        result = []
        for item in items:
            if not item or item in seen:
                continue
            seen.add(item)
            result.append(item)
        return result

    def _collect_model_ids(
        self, body: dict, request_model: str, real_model_id: str
    ) -> List[str]:
        """æ”¶é›†å¯èƒ½çš„æ¨¡å‹ IDï¼ˆæ¥è‡ªè¯·æ±‚/metadata/body paramsï¼‰"""
        model_ids: List[str] = []
        if request_model:
            model_ids.append(request_model)
        if request_model.startswith(f"{self.id}-"):
            model_ids.append(request_model[len(f"{self.id}-") :])
        if real_model_id:
            model_ids.append(real_model_id)

        metadata = body.get("metadata", {})
        if isinstance(metadata, dict):
            meta_model = metadata.get("model")
            meta_model_id = metadata.get("model_id")
            if isinstance(meta_model, str):
                model_ids.append(meta_model)
            if isinstance(meta_model_id, str):
                model_ids.append(meta_model_id)

        body_params = body.get("params", {})
        if isinstance(body_params, dict):
            for key in ("model", "model_id", "modelId"):
                val = body_params.get(key)
                if isinstance(val, str):
                    model_ids.append(val)

        return self._dedupe_preserve_order(model_ids)

    async def _extract_system_prompt(
        self,
        body: dict,
        messages: List[dict],
        request_model: str,
        real_model_id: str,
        __event_call__=None,
    ) -> tuple[Optional[str], str]:
        """ä» metadata/æ¨¡å‹ DB/body/messages æå–ç³»ç»Ÿæç¤ºè¯"""
        system_prompt_content: Optional[str] = None
        system_prompt_source = ""

        # 1) metadata.model.params.system
        metadata = body.get("metadata", {})
        if isinstance(metadata, dict):
            meta_model = metadata.get("model")
            if isinstance(meta_model, dict):
                meta_params = meta_model.get("params")
                if isinstance(meta_params, dict) and meta_params.get("system"):
                    system_prompt_content = meta_params.get("system")
                    system_prompt_source = "metadata.model.params"
                    await self._emit_debug_log(
                        f"ä» metadata.model.params æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                        __event_call__,
                    )

        # 2) æ¨¡å‹ DB
        if not system_prompt_content:
            try:
                from open_webui.models.models import Models

                model_ids_to_try = self._collect_model_ids(
                    body, request_model, real_model_id
                )
                for mid in model_ids_to_try:
                    model_record = Models.get_model_by_id(mid)
                    if model_record and hasattr(model_record, "params"):
                        params = model_record.params
                        if isinstance(params, dict):
                            system_prompt_content = params.get("system")
                            if system_prompt_content:
                                system_prompt_source = f"model_db:{mid}"
                                await self._emit_debug_log(
                                    f"ä»æ¨¡å‹æ•°æ®åº“æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                                    __event_call__,
                                )
                                break
            except Exception as e:
                await self._emit_debug_log(
                    f"ä»æ¨¡å‹æ•°æ®åº“æå–ç³»ç»Ÿæç¤ºè¯å¤±è´¥: {e}",
                    __event_call__,
                )

        # 3) body.params.system
        if not system_prompt_content:
            body_params = body.get("params", {})
            if isinstance(body_params, dict):
                system_prompt_content = body_params.get("system")
                if system_prompt_content:
                    system_prompt_source = "body_params"
                    await self._emit_debug_log(
                        f"ä» body.params æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                        __event_call__,
                    )

        # 4) messages (role=system)
        if not system_prompt_content:
            for msg in messages:
                if msg.get("role") == "system":
                    system_prompt_content = self._extract_text_from_content(
                        msg.get("content", "")
                    )
                    if system_prompt_content:
                        system_prompt_source = "messages_system"
                        await self._emit_debug_log(
                            f"ä»æ¶ˆæ¯ä¸­æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                            __event_call__,
                        )
                    break

        return system_prompt_content, system_prompt_source

    def _build_client_config(self, body: dict) -> dict:
        """æ ¹æ® Valves å’Œè¯·æ±‚æ„å»º CopilotClient é…ç½®"""
        cwd = self.valves.WORKSPACE_DIR if self.valves.WORKSPACE_DIR else os.getcwd()
        client_config = {}
        if os.environ.get("COPILOT_CLI_PATH"):
            client_config["cli_path"] = os.environ["COPILOT_CLI_PATH"]
        client_config["cwd"] = cwd

        if self.valves.LOG_LEVEL:
            client_config["log_level"] = self.valves.LOG_LEVEL

        if self.valves.CUSTOM_ENV_VARS:
            try:
                custom_env = json.loads(self.valves.CUSTOM_ENV_VARS)
                if isinstance(custom_env, dict):
                    client_config["env"] = custom_env
            except:
                pass

        return client_config

    def _build_session_config(
        self,
        chat_id: Optional[str],
        real_model_id: str,
        custom_tools: List[Any],
        system_prompt_content: Optional[str],
        is_streaming: bool,
        reasoning_effort: str = "",
    ):
        """æ„å»º Copilot SDK çš„ SessionConfig"""
        from copilot.types import SessionConfig, InfiniteSessionConfig

        infinite_session_config = None
        if self.valves.INFINITE_SESSION:
            infinite_session_config = InfiniteSessionConfig(
                enabled=True,
                background_compaction_threshold=self.valves.COMPACTION_THRESHOLD,
                buffer_exhaustion_threshold=self.valves.BUFFER_THRESHOLD,
            )

        system_message_config = None
        if system_prompt_content or self.valves.ENFORCE_FORMATTING:
            # æ„å»ºç³»ç»Ÿæ¶ˆæ¯å†…å®¹
            system_parts = []

            if system_prompt_content:
                system_parts.append(system_prompt_content)

            if self.valves.ENFORCE_FORMATTING:
                formatting_instruction = (
                    "\n\n[æ ¼å¼åŒ–æŒ‡å—]\n"
                    "åœ¨æä¾›è§£é‡Šæˆ–æè¿°æ—¶ï¼š\n"
                    "- ä½¿ç”¨æ¸…æ™°çš„æ®µè½åˆ†éš”ï¼ˆåŒæ¢è¡Œï¼‰\n"
                    "- å°†é•¿å¥æ‹†åˆ†ä¸ºå¤šä¸ªçŸ­å¥\n"
                    "- å¯¹å¤šä¸ªè¦ç‚¹ä½¿ç”¨é¡¹ç›®ç¬¦å·æˆ–ç¼–å·åˆ—è¡¨\n"
                    "- ä¸ºä¸»è¦éƒ¨åˆ†æ·»åŠ æ ‡é¢˜ï¼ˆ##ã€###ï¼‰\n"
                    "- ç¡®ä¿ä¸åŒä¸»é¢˜ä¹‹é—´æœ‰é€‚å½“çš„é—´è·"
                )
                system_parts.append(formatting_instruction)
                logger.info(f"[ENFORCE_FORMATTING] å·²æ·»åŠ æ ¼å¼åŒ–æŒ‡å¯¼åˆ°ç³»ç»Ÿæç¤ºè¯")

            if system_parts:
                system_message_config = {
                    "mode": "append",
                    "content": "\n".join(system_parts),
                }

        # å‡†å¤‡ä¼šè¯é…ç½®å‚æ•°
        session_params = {
            "session_id": chat_id if chat_id else None,
            "model": real_model_id,
            "streaming": is_streaming,
            "tools": custom_tools,
            "system_message": system_message_config,
            "infinite_sessions": infinite_session_config,
        }

        # å¦‚æœä¸æ˜¯é»˜è®¤å€¼ï¼ˆmediumï¼‰ï¼Œæ·»åŠ  reasoning_effort
        if reasoning_effort and reasoning_effort.lower() != "medium":
            session_params["reasoning_effort"] = reasoning_effort.lower()

        return SessionConfig(**session_params)

    def _dedupe_preserve_order(self, items: List[str]) -> List[str]:
        """å»é‡ä¿åº"""
        seen = set()
        result = []
        for item in items:
            if not item or item in seen:
                continue
            seen.add(item)
            result.append(item)
        return result

    def _collect_model_ids(
        self, body: dict, request_model: str, real_model_id: str
    ) -> List[str]:
        """æ”¶é›†å¯èƒ½çš„æ¨¡å‹ IDï¼ˆæ¥è‡ªè¯·æ±‚/metadata/body paramsï¼‰"""
        model_ids: List[str] = []
        if request_model:
            model_ids.append(request_model)
        if request_model.startswith(f"{self.id}-"):
            model_ids.append(request_model[len(f"{self.id}-") :])
        if real_model_id:
            model_ids.append(real_model_id)

        metadata = body.get("metadata", {})
        if isinstance(metadata, dict):
            meta_model = metadata.get("model")
            meta_model_id = metadata.get("model_id")
            if isinstance(meta_model, str):
                model_ids.append(meta_model)
            if isinstance(meta_model_id, str):
                model_ids.append(meta_model_id)

        body_params = body.get("params", {})
        if isinstance(body_params, dict):
            for key in ("model", "model_id", "modelId"):
                val = body_params.get(key)
                if isinstance(val, str):
                    model_ids.append(val)

        return self._dedupe_preserve_order(model_ids)

    async def _extract_system_prompt(
        self,
        body: dict,
        messages: List[dict],
        request_model: str,
        real_model_id: str,
        __event_call__=None,
    ) -> tuple[Optional[str], str]:
        """ä» metadata/æ¨¡å‹ DB/body/messages æå–ç³»ç»Ÿæç¤ºè¯"""
        system_prompt_content: Optional[str] = None
        system_prompt_source = ""

        # 1) metadata.model.params.system
        metadata = body.get("metadata", {})
        if isinstance(metadata, dict):
            meta_model = metadata.get("model")
            if isinstance(meta_model, dict):
                meta_params = meta_model.get("params")
                if isinstance(meta_params, dict) and meta_params.get("system"):
                    system_prompt_content = meta_params.get("system")
                    system_prompt_source = "metadata.model.params"
                    await self._emit_debug_log(
                        f"ä» metadata.model.params æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                        __event_call__,
                    )

        # 2) æ¨¡å‹ DB
        if not system_prompt_content:
            try:
                from open_webui.models.models import Models

                model_ids_to_try = self._collect_model_ids(
                    body, request_model, real_model_id
                )
                for mid in model_ids_to_try:
                    model_record = Models.get_model_by_id(mid)
                    if model_record and hasattr(model_record, "params"):
                        params = model_record.params
                        if isinstance(params, dict):
                            system_prompt_content = params.get("system")
                            if system_prompt_content:
                                system_prompt_source = f"model_db:{mid}"
                                await self._emit_debug_log(
                                    f"ä»æ¨¡å‹æ•°æ®åº“æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                                    __event_call__,
                                )
                                break
            except Exception as e:
                await self._emit_debug_log(
                    f"ä»æ¨¡å‹æ•°æ®åº“æå–ç³»ç»Ÿæç¤ºè¯å¤±è´¥: {e}",
                    __event_call__,
                )

        # 3) body.params.system
        if not system_prompt_content:
            body_params = body.get("params", {})
            if isinstance(body_params, dict):
                system_prompt_content = body_params.get("system")
                if system_prompt_content:
                    system_prompt_source = "body_params"
                    await self._emit_debug_log(
                        f"ä» body.params æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                        __event_call__,
                    )

        # 4) messages (role=system)
        if not system_prompt_content:
            for msg in messages:
                if msg.get("role") == "system":
                    system_prompt_content = self._extract_text_from_content(
                        msg.get("content", "")
                    )
                    if system_prompt_content:
                        system_prompt_source = "messages_system"
                        await self._emit_debug_log(
                            f"ä»æ¶ˆæ¯ä¸­æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                            __event_call__,
                        )
                    break

        return system_prompt_content, system_prompt_source

    def _initialize_custom_tools(self):
        """æ ¹æ®é…ç½®åˆå§‹åŒ–è‡ªå®šä¹‰å·¥å…·"""
        if not self.valves.ENABLE_TOOLS:
            return []

        # å®šä¹‰æ‰€æœ‰å¯ç”¨å·¥å…·ï¼ˆåœ¨æ­¤æ³¨å†Œæ–°å·¥å…·ï¼‰
        all_tools = {
            "generate_random_number": generate_random_number,
        }

        # æ ¹æ®é…ç½®è¿‡æ»¤
        if self.valves.AVAILABLE_TOOLS == "all":
            return list(all_tools.values())

        # ä»…å¯ç”¨æŒ‡å®šçš„å·¥å…·
        enabled = [t.strip() for t in self.valves.AVAILABLE_TOOLS.split(",")]
        return [all_tools[name] for name in enabled if name in all_tools]

    async def _emit_debug_log(self, message: str, __event_call__=None):
        """åœ¨ DEBUG å¼€å¯æ—¶å°†æ—¥å¿—è¾“å‡ºåˆ°å‰ç«¯æ§åˆ¶å°ã€‚"""
        if not self.valves.DEBUG:
            return

        logger.debug(f"[Copilot Pipe] {message}")

        if not __event_call__:
            return

        try:
            js_code = f"""
                (async function() {{
                    console.debug("%c[Copilot Pipe] " + {json.dumps(message, ensure_ascii=False)}, "color: #3b82f6;");
                }})();
            """
            await __event_call__({"type": "execute", "data": {"code": js_code}})
        except Exception as e:
            logger.debug(f"[Copilot Pipe] å‰ç«¯è°ƒè¯•æ—¥å¿—å¤±è´¥: {e}")

    def _emit_debug_log_sync(self, message: str, __event_call__=None):
        """åœ¨éå¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­è¾“å‡ºè°ƒè¯•æ—¥å¿—ã€‚"""
        if not self.valves.DEBUG:
            return

        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            logger.debug(f"[Copilot Pipe] {message}")
            return

        loop.create_task(self._emit_debug_log(message, __event_call__))

    async def _emit_native_message(self, message_data: dict, __event_call__=None):
        """å‘é€åŸç”Ÿ OpenAI æ ¼å¼æ¶ˆæ¯äº‹ä»¶ç”¨äºå·¥å…·è°ƒç”¨/ç»“æœã€‚"""
        if not __event_call__:
            return

        try:
            await __event_call__({"type": "message", "data": message_data})
            await self._emit_debug_log(
                f"å·²å‘é€åŸç”Ÿæ¶ˆæ¯: {message_data.get('role')} - {list(message_data.keys())}",
                __event_call__,
            )
        except Exception as e:
            logger.warning(f"å‘é€åŸç”Ÿæ¶ˆæ¯å¤±è´¥: {e}")
            await self._emit_debug_log(
                f"åŸç”Ÿæ¶ˆæ¯å‘é€å¤±è´¥: {e}ã€‚å›é€€åˆ°æ–‡æœ¬æ˜¾ç¤ºã€‚", __event_call__
            )

    def _get_user_context(self):
        """è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆå ä½ï¼Œé¢„ç•™ï¼‰ã€‚"""
        return {}

    def _get_chat_context(
        self, body: dict, __metadata__: Optional[dict] = None, __event_call__=None
    ) -> Dict[str, str]:
        """
        é«˜åº¦å¯é çš„èŠå¤©ä¸Šä¸‹æ–‡æå–é€»è¾‘ã€‚
        ä¼˜å…ˆçº§ï¼š__metadata__ > body['chat_id'] > body['metadata']['chat_id']
        """
        chat_id = ""
        source = "none"

        # 1. ä¼˜å…ˆä» __metadata__ è·å– (OpenWebUI æ³¨å…¥çš„æœ€å¯é æ¥æº)
        if __metadata__ and isinstance(__metadata__, dict):
            chat_id = __metadata__.get("chat_id", "")
            if chat_id:
                source = "__metadata__"

        # 2. å…¶æ¬¡ä» body é¡¶å±‚è·å–
        if not chat_id and isinstance(body, dict):
            chat_id = body.get("chat_id", "")
            if chat_id:
                source = "body_root"

        # 3. æœ€åä» body.metadata è·å–
        if not chat_id and isinstance(body, dict):
            body_metadata = body.get("metadata", {})
            if isinstance(body_metadata, dict):
                chat_id = body_metadata.get("chat_id", "")
                if chat_id:
                    source = "body_metadata"

        # è°ƒè¯•ï¼šè®°å½• ID æ¥æº
        if chat_id:
            self._emit_debug_log_sync(
                f"æå–åˆ° ChatID: {chat_id} (æ¥æº: {source})", __event_call__
            )
        else:
            # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œè®°å½•ä¸€ä¸‹ body çš„é”®ï¼Œæ–¹ä¾¿æ’æŸ¥
            keys = list(body.keys()) if isinstance(body, dict) else "not a dict"
            self._emit_debug_log_sync(
                f"è­¦å‘Š: æœªèƒ½æå–åˆ° ChatIDã€‚Body é”®: {keys}", __event_call__
            )

        return {
            "chat_id": str(chat_id).strip(),
        }

    async def pipes(self) -> List[dict]:
        """åŠ¨æ€è·å–æ¨¡å‹åˆ—è¡¨"""
        # å¦‚æœæœ‰ç¼“å­˜ï¼Œç›´æ¥è¿”å›
        if self._model_cache:
            return self._model_cache

        await self._emit_debug_log("æ­£åœ¨åŠ¨æ€è·å–æ¨¡å‹åˆ—è¡¨...")
        try:
            self._setup_env()
            if not self.valves.GH_TOKEN:
                return [{"id": f"{self.id}-error", "name": "Error: GH_TOKEN not set"}]

            client_config = {}
            if os.environ.get("COPILOT_CLI_PATH"):
                client_config["cli_path"] = os.environ["COPILOT_CLI_PATH"]

            client = CopilotClient(client_config)
            try:
                await client.start()
                models = await client.list_models()

                # æ›´æ–°ç¼“å­˜
                self._model_cache = []
                exclude_list = [
                    k.strip().lower()
                    for k in self.valves.EXCLUDE_KEYWORDS.split(",")
                    if k.strip()
                ]

                models_with_info = []
                for m in models:
                    # å…¼å®¹å­—å…¸å’Œå¯¹è±¡è®¿é—®æ–¹å¼
                    m_id = (
                        m.get("id") if isinstance(m, dict) else getattr(m, "id", str(m))
                    )
                    m_name = (
                        m.get("name")
                        if isinstance(m, dict)
                        else getattr(m, "name", m_id)
                    )
                    m_policy = (
                        m.get("policy")
                        if isinstance(m, dict)
                        else getattr(m, "policy", {})
                    )
                    m_billing = (
                        m.get("billing")
                        if isinstance(m, dict)
                        else getattr(m, "billing", {})
                    )

                    # æ£€æŸ¥ç­–ç•¥çŠ¶æ€
                    state = (
                        m_policy.get("state")
                        if isinstance(m_policy, dict)
                        else getattr(m_policy, "state", "enabled")
                    )
                    if state == "disabled":
                        continue

                    # è¿‡æ»¤é€»è¾‘
                    if any(kw in m_id.lower() for kw in exclude_list):
                        continue

                    # è·å–å€ç‡
                    multiplier = (
                        m_billing.get("multiplier", 1)
                        if isinstance(m_billing, dict)
                        else getattr(m_billing, "multiplier", 1)
                    )

                    # æ ¼å¼åŒ–æ˜¾ç¤ºåç§°
                    if multiplier == 0:
                        display_name = f"-ğŸ”¥ {m_id} (unlimited)"
                    else:
                        display_name = f"-{m_id} ({multiplier}x)"

                    models_with_info.append(
                        {
                            "id": f"{self.id}-{m_id}",
                            "name": display_name,
                            "multiplier": multiplier,
                            "raw_id": m_id,
                        }
                    )

                # æ’åºï¼šå€ç‡å‡åºï¼Œç„¶åæ˜¯åŸå§‹IDå‡åº
                models_with_info.sort(key=lambda x: (x["multiplier"], x["raw_id"]))
                self._model_cache = [
                    {"id": m["id"], "name": m["name"]} for m in models_with_info
                ]

                await self._emit_debug_log(
                    f"æˆåŠŸè·å– {len(self._model_cache)} ä¸ªæ¨¡å‹ (å·²è¿‡æ»¤)"
                )
                return self._model_cache
            except Exception as e:
                await self._emit_debug_log(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
                # å¤±è´¥æ—¶è¿”å›é»˜è®¤æ¨¡å‹
                return [
                    {
                        "id": f"{self.id}-{self.valves.MODEL_ID}",
                        "name": f"GitHub Copilot ({self.valves.MODEL_ID})",
                    }
                ]
            finally:
                await client.stop()
        except Exception as e:
            await self._emit_debug_log(f"Pipes Error: {e}")
            return [
                {
                    "id": f"{self.id}-{self.valves.MODEL_ID}",
                    "name": f"GitHub Copilot ({self.valves.MODEL_ID})",
                }
            ]

    async def _get_client(self):
        """Helper to get or create a CopilotClient instance."""
        # ç¡®å®šå·¥ä½œç©ºé—´ç›®å½•
        cwd = self.valves.WORKSPACE_DIR if self.valves.WORKSPACE_DIR else os.getcwd()

        client_config = {}
        if os.environ.get("COPILOT_CLI_PATH"):
            client_config["cli_path"] = os.environ["COPILOT_CLI_PATH"]
        client_config["cwd"] = cwd

        # è®¾ç½®æ—¥å¿—çº§åˆ«
        if self.valves.LOG_LEVEL:
            client_config["log_level"] = self.valves.LOG_LEVEL

        # æ·»åŠ è‡ªå®šä¹‰ç¯å¢ƒå˜é‡
        if self.valves.CUSTOM_ENV_VARS:
            try:
                custom_env = json.loads(self.valves.CUSTOM_ENV_VARS)
                if isinstance(custom_env, dict):
                    client_config["env"] = custom_env
            except:
                pass  # é™é»˜å¤±è´¥ï¼Œå› ä¸ºè¿™æ˜¯åŒæ­¥æ–¹æ³•ä¸”ä¸åº”å½±å“ä¸»æµç¨‹

        client = CopilotClient(client_config)
        await client.start()
        return client

    def _setup_env(self, __event_call__=None):
        cli_path = self.valves.CLI_PATH
        found = False

        if os.path.exists(cli_path):
            found = True

        if not found:
            sys_path = shutil.which("copilot")
            if sys_path:
                cli_path = sys_path
                found = True

        if not found:
            try:
                subprocess.run(
                    "curl -fsSL https://gh.io/copilot-install | bash",
                    shell=True,
                    check=True,
                )
                if os.path.exists(self.valves.CLI_PATH):
                    cli_path = self.valves.CLI_PATH
                    found = True
            except:
                pass

        if found:
            os.environ["COPILOT_CLI_PATH"] = cli_path
            cli_dir = os.path.dirname(cli_path)
            if cli_dir not in os.environ["PATH"]:
                os.environ["PATH"] = f"{cli_dir}:{os.environ['PATH']}"

            if self.valves.DEBUG:
                self._emit_debug_log_sync(
                    f"Copilot CLI å·²å®šä½: {cli_path}", __event_call__
                )

        if self.valves.GH_TOKEN:
            os.environ["GH_TOKEN"] = self.valves.GH_TOKEN
            os.environ["GITHUB_TOKEN"] = self.valves.GH_TOKEN
        else:
            if self.valves.DEBUG:
                self._emit_debug_log_sync("Warning: GH_TOKEN æœªè®¾ç½®ã€‚", __event_call__)

    def _process_images(self, messages, __event_call__=None):
        attachments = []
        text_content = ""
        if not messages:
            return "", []
        last_msg = messages[-1]
        content = last_msg.get("content", "")

        if isinstance(content, list):
            for item in content:
                if item.get("type") == "text":
                    text_content += item.get("text", "")
                elif item.get("type") == "image_url":
                    image_url = item.get("image_url", {}).get("url", "")
                    if image_url.startswith("data:image"):
                        try:
                            header, encoded = image_url.split(",", 1)
                            ext = header.split(";")[0].split("/")[-1]
                            file_name = f"image_{len(attachments)}.{ext}"
                            file_path = os.path.join(self.temp_dir, file_name)
                            with open(file_path, "wb") as f:
                                f.write(base64.b64decode(encoded))
                            attachments.append(
                                {
                                    "type": "file",
                                    "path": file_path,
                                    "display_name": file_name,
                                }
                            )
                            self._emit_debug_log_sync(
                                f"Image processed: {file_path}", __event_call__
                            )
                        except Exception as e:
                            self._emit_debug_log_sync(
                                f"Image error: {e}", __event_call__
                            )
        else:
            text_content = str(content)
        return text_content, attachments

    def _sync_copilot_config(self, reasoning_effort: str, __event_call__=None):
        """
        åŠ¨æ€æ›´æ–° ~/.copilot/config.json ä¸­çš„ reasoning_effort è®¾ç½®ã€‚
        å¦‚æœ API æ³¨å…¥è¢«å¿½ç•¥ï¼Œè¿™æä¾›äº†æœ€åçš„ä¿éšœã€‚
        """
        if not reasoning_effort:
            return

        effort = reasoning_effort

        # æ£€æŸ¥æ¨¡å‹å¯¹ xhigh çš„æ”¯æŒ
        # ç›®å‰ä»… gpt-5.2-codex æ”¯æŒ xhigh
        # åœ¨ _sync_copilot_config ä¸­å¾ˆéš¾è·å¾—å‡†ç¡®çš„å½“å‰æ¨¡å‹ IDï¼Œ
        # å› æ­¤è¿™é‡Œæˆ‘ä»¬æ”¾å®½é™åˆ¶ï¼Œå…è®¸å†™å…¥ xhighã€‚
        # å¦‚æœæ¨¡å‹ä¸æ”¯æŒï¼ŒCopilot CLI å¯èƒ½ä¼šå¿½ç•¥æˆ–é™çº§å¤„ç†ï¼Œä½†è¿™æ¯”åœ¨è¿™é‡Œç¡¬ç¼–ç åˆ¤æ–­æ›´å®‰å…¨ï¼Œ
        # å› ä¸ºè·å–å½“å‰è¯·æ±‚çš„ body éœ€è¦ä¿®æ”¹å‡½æ•°ç­¾åã€‚

        try:
            # ç›®æ ‡æ ‡å‡†è·¯å¾„ ~/.copilot/config.json
            config_path = os.path.expanduser("~/.copilot/config.json")
            config_dir = os.path.dirname(config_path)

            # ä»…åœ¨ç›®å½•å­˜åœ¨æ—¶æ‰§è¡Œï¼ˆé¿å…åœ¨é”™è¯¯ç¯å¢ƒåˆ›å»ºåƒåœ¾æ–‡ä»¶ï¼‰
            if not os.path.exists(config_dir):
                return

            data = {}
            # è¯»å–ç°æœ‰é…ç½®
            if os.path.exists(config_path):
                try:
                    with open(config_path, "r") as f:
                        data = json.load(f)
                except Exception:
                    data = {}

            # å¦‚æœå€¼æœ‰å˜åŒ–åˆ™æ›´æ–°
            current_val = data.get("reasoning_effort")
            if current_val != effort:
                data["reasoning_effort"] = effort
                try:
                    with open(config_path, "w") as f:
                        json.dump(data, f, indent=4)

                    self._emit_debug_log_sync(
                        f"å·²åŠ¨æ€æ›´æ–° ~/.copilot/config.json: reasoning_effort='{effort}'",
                        __event_call__,
                    )
                except Exception as e:
                    self._emit_debug_log_sync(
                        f"å†™å…¥ config.json å¤±è´¥: {e}", __event_call__
                    )
        except Exception as e:
            self._emit_debug_log_sync(f"é…ç½®åŒæ­¥æ£€æŸ¥å¤±è´¥: {e}", __event_call__)

    # ==================== å†…éƒ¨å®ç° ====================
    # _pipe_impl() åŒ…å«ä¸»è¯·æ±‚å¤„ç†é€»è¾‘ã€‚
    # ================================================
    async def _pipe_impl(
        self,
        body: dict,
        __metadata__: Optional[dict] = None,
        __user__: Optional[dict] = None,
        __event_emitter__=None,
        __event_call__=None,
    ) -> Union[str, AsyncGenerator]:
        self._setup_env(__event_call__)
        if not self.valves.GH_TOKEN:
            return "Error: è¯·åœ¨ Valves ä¸­é…ç½® GH_TOKENã€‚"

        # è§£æç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹
        request_model = body.get("model", "")
        real_model_id = self.valves.MODEL_ID  # é»˜è®¤å€¼

        # ç¡®å®šæœ‰æ•ˆçš„æ¨ç†å¼ºåº¦å’Œè°ƒè¯•è®¾ç½®
        if __user__:
            raw_valves = __user__.get("valves", {})
            if isinstance(raw_valves, self.UserValves):
                user_valves = raw_valves
            elif isinstance(raw_valves, dict):
                user_valves = self.UserValves(**raw_valves)
            else:
                user_valves = self.UserValves()
        else:
            user_valves = self.UserValves()
        effective_reasoning_effort = (
            user_valves.REASONING_EFFORT
            if user_valves.REASONING_EFFORT
            else self.valves.REASONING_EFFORT
        )
        # å¦‚æœç”¨æˆ·å¯ç”¨äº† DEBUGï¼Œåˆ™è¦†ç›–å…¨å±€è®¾ç½®
        if user_valves.DEBUG:
            self.valves.DEBUG = True

        # å¤„ç† SHOW_THINKINGï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è®¾ç½®ï¼‰
        show_thinking = (
            user_valves.SHOW_THINKING
            if user_valves.SHOW_THINKING is not None
            else self.valves.SHOW_THINKING
        )

        if request_model.startswith(f"{self.id}-"):
            real_model_id = request_model[len(f"{self.id}-") :]
            await self._emit_debug_log(
                f"ä½¿ç”¨é€‰æ‹©çš„æ¨¡å‹: {real_model_id}", __event_call__
            )

        messages = body.get("messages", [])
        if not messages:
            return "No messages."

        # ä½¿ç”¨æ”¹è¿›çš„åŠ©æ‰‹è·å– Chat ID
        chat_ctx = self._get_chat_context(body, __metadata__, __event_call__)
        chat_id = chat_ctx.get("chat_id")

        # ä»å¤šä¸ªæ¥æºæå–ç³»ç»Ÿæç¤ºè¯
        system_prompt_content, system_prompt_source = await self._extract_system_prompt(
            body, messages, request_model, real_model_id, __event_call__
        )

        if system_prompt_content:
            preview = system_prompt_content[:60].replace("\n", " ")
            await self._emit_debug_log(
                f"ç³»ç»Ÿæç¤ºè¯å·²ç¡®è®¤ï¼ˆæ¥æº: {system_prompt_source}, é•¿åº¦: {len(system_prompt_content)}, é¢„è§ˆ: {preview}ï¼‰",
                __event_call__,
            )

        is_streaming = body.get("stream", False)
        await self._emit_debug_log(f"è¯·æ±‚æµå¼ä¼ è¾“: {is_streaming}", __event_call__)

        client = CopilotClient(self._build_client_config(body))
        should_stop_client = True
        try:
            await client.start()

            # åˆå§‹åŒ–è‡ªå®šä¹‰å·¥å…·
            custom_tools = self._initialize_custom_tools()
            if custom_tools:
                tool_names = [t.name for t in custom_tools]
                await self._emit_debug_log(
                    f"å·²å¯ç”¨ {len(custom_tools)} ä¸ªè‡ªå®šä¹‰å·¥å…·: {tool_names}",
                    __event_call__,
                )

            session = None

            if chat_id:
                try:
                    # å°è¯•ç›´æ¥ä½¿ç”¨ chat_id ä½œä¸º session_id æ¢å¤ä¼šè¯
                    session = await client.resume_session(chat_id)
                    await self._emit_debug_log(
                        f"å·²é€šè¿‡ ChatID æ¢å¤ä¼šè¯: {chat_id}", __event_call__
                    )

                    # æ˜¾ç¤ºå·¥ä½œç©ºé—´ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if self.valves.DEBUG and self.valves.SHOW_WORKSPACE_INFO:
                        if session.workspace_path:
                            await self._emit_debug_log(
                                f"ä¼šè¯å·¥ä½œç©ºé—´: {session.workspace_path}",
                                __event_call__,
                            )

                    is_new_session = False
                except Exception as e:
                    # æ¢å¤å¤±è´¥ï¼Œç£ç›˜ä¸Šå¯èƒ½ä¸å­˜åœ¨è¯¥ä¼šè¯
                    reasoning_effort = (effective_reasoning_effort,)
                    await self._emit_debug_log(
                        f"ä¼šè¯ {chat_id} ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ ({str(e)})ï¼Œå°†åˆ›å»ºæ–°ä¼šè¯ã€‚",
                        __event_call__,
                    )
                    session = None

            if session is None:
                session_config = self._build_session_config(
                    chat_id,
                    real_model_id,
                    custom_tools,
                    system_prompt_content,
                    is_streaming,
                )
                if system_prompt_content:
                    await self._emit_debug_log(
                        f"é…ç½®ç³»ç»Ÿæ¶ˆæ¯ï¼ˆæ¨¡å¼: appendï¼‰",
                        __event_call__,
                    )

                # æ˜¾ç¤ºç³»ç»Ÿé…ç½®é¢„è§ˆ
                if system_prompt_content or self.valves.ENFORCE_FORMATTING:
                    preview_parts = []
                    if system_prompt_content:
                        preview_parts.append(
                            f"è‡ªå®šä¹‰æç¤ºè¯: {system_prompt_content[:100]}..."
                        )
                    if self.valves.ENFORCE_FORMATTING:
                        preview_parts.append("æ ¼å¼åŒ–æŒ‡å¯¼: å·²å¯ç”¨")

                    if isinstance(session_config, dict):
                        system_config = session_config.get("system_message", {})
                    else:
                        system_config = getattr(session_config, "system_message", None)

                    if isinstance(system_config, dict):
                        full_content = system_config.get("content", "")
                    else:
                        full_content = ""

                    await self._emit_debug_log(
                        f"ç³»ç»Ÿæ¶ˆæ¯é…ç½® - {', '.join(preview_parts)} (æ€»é•¿åº¦: {len(full_content)} å­—ç¬¦)",
                        __event_call__,
                    )

                session = await client.create_session(config=session_config)

                # è·å–æ–°ä¼šè¯ ID
                new_sid = getattr(session, "session_id", getattr(session, "id", None))
                await self._emit_debug_log(f"åˆ›å»ºäº†æ–°ä¼šè¯: {new_sid}", __event_call__)

                # æ˜¾ç¤ºæ–°ä¼šè¯çš„å·¥ä½œç©ºé—´ä¿¡æ¯
                if self.valves.DEBUG and self.valves.SHOW_WORKSPACE_INFO:
                    if session.workspace_path:
                        await self._emit_debug_log(
                            f"ä¼šè¯å·¥ä½œç©ºé—´: {session.workspace_path}",
                            __event_call__,
                        )

            # æ„å»º Promptï¼ˆåŸºäºä¼šè¯ï¼šä»…å‘é€æœ€æ–°ç”¨æˆ·è¾“å…¥ï¼‰
            prompt = self._apply_formatting_hint(last_text)

            send_payload = {"prompt": prompt, "mode": "immediate"}
            if attachments:
                send_payload["attachments"] = attachments

            if body.get("stream", False):
                # ç¡®å®š UI æ˜¾ç¤ºçš„ä¼šè¯çŠ¶æ€æ¶ˆæ¯
                init_msg = ""
                if self.valves.DEBUG:
                    if is_new_session:
                        new_sid = getattr(
                            session, "session_id", getattr(session, "id", "unknown")
                        )
                        init_msg = f"> [Debug] åˆ›å»ºäº†æ–°ä¼šè¯: {new_sid}\n"
                    else:
                        init_msg = f"> [Debug] å·²é€šè¿‡ ChatID æ¢å¤ä¼šè¯: {chat_id}\n"

                return self.stream_response(
                    client,
                    session,
                    send_payload,
                    init_msg,
                    __event_call__,
                    reasoning_effort=effective_reasoning_effort,
                    show_thinking=show_thinking,
                )
            else:
                try:
                    response = await session.send_and_wait(send_payload)
                    return response.data.content if response else "Empty response."
                finally:
                    # æ¸…ç†ï¼šå¦‚æœæ²¡æœ‰ chat_idï¼ˆä¸´æ—¶ä¼šè¯ï¼‰ï¼Œé”€æ¯ä¼šè¯
                    if not chat_id:
                        try:
                            await session.destroy()
                        except Exception as cleanup_error:
                            await self._emit_debug_log(
                                f"ä¼šè¯æ¸…ç†è­¦å‘Š: {cleanup_error}",
                                __event_call__,
                            )
        except Exception as e:
            await self._emit_debug_log(f"è¯·æ±‚é”™è¯¯: {e}", __event_call__)
            return f"Error: {str(e)}"
        finally:
            if should_stop_client:
                try:
                    await client.stop()
                except:
                    pass

    async def stream_response(
        self,
        client,
        session,
        send_payload,
        init_message: str = "",
        __event_call__=None,
        reasoning_effort: str = "",
        show_thinking: bool = True,
    ) -> AsyncGenerator:
        """
        ä» Copilot SDK æµå¼ä¼ è¾“å“åº”ï¼Œå¤„ç†å„ç§äº‹ä»¶ç±»å‹ã€‚
        éµå¾ªå®˜æ–¹ SDK æ¨¡å¼è¿›è¡Œäº‹ä»¶å¤„ç†å’Œæµå¼ä¼ è¾“ã€‚
        """
        from copilot.generated.session_events import SessionEventType

        queue = asyncio.Queue()
        done = asyncio.Event()
        SENTINEL = object()
        # ä½¿ç”¨æœ¬åœ°çŠ¶æ€æ¥å¤„ç†å¹¶å‘å’Œè·Ÿè¸ª
        state = {"thinking_started": False, "content_sent": False}
        has_content = False  # è¿½è¸ªæ˜¯å¦å·²ç»è¾“å‡ºäº†å†…å®¹
        active_tools = {}  # æ˜ å°„ tool_call_id åˆ°å·¥å…·åç§°

        def get_event_type(event) -> str:
            """æå–äº‹ä»¶ç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œå¤„ç†æšä¸¾å’Œå­—ç¬¦ä¸²ç±»å‹ã€‚"""
            if hasattr(event, "type"):
                event_type = event.type
                # å¤„ç† SessionEventType æšä¸¾
                if hasattr(event_type, "value"):
                    return event_type.value
                return str(event_type)
            return "unknown"

        def safe_get_data_attr(event, attr: str, default=None):
            """
            å®‰å…¨åœ°ä» event.data æå–å±æ€§ã€‚
            åŒæ—¶å¤„ç†å­—å…¸è®¿é—®å’Œå¯¹è±¡å±æ€§è®¿é—®ã€‚
            """
            if not hasattr(event, "data") or event.data is None:
                return default

            data = event.data

            # é¦–å…ˆå°è¯•ä½œä¸ºå­—å…¸
            if isinstance(data, dict):
                return data.get(attr, default)

            # å°è¯•ä½œä¸ºå¯¹è±¡å±æ€§
            return getattr(data, attr, default)

        def handler(event):
            """
            äº‹ä»¶å¤„ç†å™¨ï¼Œéµå¾ªå®˜æ–¹ SDK æ¨¡å¼ã€‚
            å¤„ç†æµå¼å¢é‡ã€æ¨ç†ã€å·¥å…·äº‹ä»¶å’Œä¼šè¯çŠ¶æ€ã€‚
            """
            event_type = get_event_type(event)

            # === æ¶ˆæ¯å¢é‡äº‹ä»¶ï¼ˆä¸»è¦æµå¼å†…å®¹ï¼‰===
            if event_type == "assistant.message_delta":
                # å®˜æ–¹ï¼šPython SDK ä½¿ç”¨ event.data.delta_content
                delta = safe_get_data_attr(
                    event, "delta_content"
                ) or safe_get_data_attr(event, "deltaContent")
                if delta:
                    state["content_sent"] = True
                    if state["thinking_started"]:
                        queue.put_nowait("\n</think>\n")
                        state["thinking_started"] = False
                    queue.put_nowait(delta)

            # === å®Œæ•´æ¶ˆæ¯äº‹ä»¶ï¼ˆéæµå¼å“åº”ï¼‰ ===
            elif event_type == "assistant.message":
                # å¤„ç†å®Œæ•´æ¶ˆæ¯ï¼ˆå½“ SDK è¿”å›å®Œæ•´å†…å®¹è€Œä¸æ˜¯å¢é‡æ—¶ï¼‰
                content = safe_get_data_attr(event, "content") or safe_get_data_attr(
                    event, "message"
                )
                if content:
                    state["content_sent"] = True
                    if state["thinking_started"]:
                        queue.put_nowait("\n</think>\n")
                        state["thinking_started"] = False
                    queue.put_nowait(content)

            # === æ¨ç†å¢é‡äº‹ä»¶ï¼ˆæ€ç»´é“¾æµå¼ä¼ è¾“ï¼‰===
            elif event_type == "assistant.reasoning_delta":
                delta = safe_get_data_attr(
                    event, "delta_content"
                ) or safe_get_data_attr(event, "deltaContent")
                if delta:
                    # å¦‚æœå†…å®¹å·²ç»å¼€å§‹ï¼ŒæŠ‘åˆ¶è¿Ÿåˆ°çš„æ¨ç†
                    if state["content_sent"]:
                        return

                    if not state["thinking_started"] and show_thinking:
                        queue.put_nowait("<think>\n")
                        state["thinking_started"] = True
                    if state["thinking_started"]:
                        queue.put_nowait(delta)

            # === å®Œæ•´æ¨ç†äº‹ä»¶ï¼ˆéæµå¼æ¨ç†ï¼‰ ===
            elif event_type == "assistant.reasoning":
                # å¤„ç†å®Œæ•´æ¨ç†å†…å®¹
                reasoning = safe_get_data_attr(event, "content") or safe_get_data_attr(
                    event, "reasoning"
                )
                if reasoning:
                    # å¦‚æœå†…å®¹å·²ç»å¼€å§‹ï¼ŒæŠ‘åˆ¶å»¶è¿Ÿåˆ°è¾¾çš„æ¨ç†
                    if state["content_sent"]:
                        return

                    if not state["thinking_started"] and show_thinking:
                        queue.put_nowait("<think>\n")
                        state["thinking_started"] = True
                    if state["thinking_started"]:
                        queue.put_nowait(reasoning)

            # === å·¥å…·æ‰§è¡Œäº‹ä»¶ ===
            elif event_type == "tool.execution_start":
                tool_name = (
                    safe_get_data_attr(event, "name")
                    or safe_get_data_attr(event, "tool_name")
                    or "æœªçŸ¥å·¥å…·"
                )
                tool_call_id = safe_get_data_attr(event, "tool_call_id", "")

                # è·å–å·¥å…·å‚æ•°
                tool_args = {}
                try:
                    args_obj = safe_get_data_attr(event, "arguments")
                    if isinstance(args_obj, dict):
                        tool_args = args_obj
                    elif isinstance(args_obj, str):
                        tool_args = json.loads(args_obj)
                except:
                    pass

                if tool_call_id:
                    active_tools[tool_call_id] = {
                        "name": tool_name,
                        "arguments": tool_args,
                    }

                # åœ¨æ˜¾ç¤ºå·¥å…·å‰å…³é—­æ€è€ƒæ ‡ç­¾
                if state["thinking_started"]:
                    queue.put_nowait("\n</think>\n")
                    state["thinking_started"] = False

                # ä½¿ç”¨æ”¹è¿›çš„æ ¼å¼å±•ç¤ºå·¥å…·è°ƒç”¨
                if tool_args:
                    tool_args_json = json.dumps(tool_args, indent=2, ensure_ascii=False)
                    tool_display = f"\n\n<details>\n<summary>ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}</summary>\n\n**å‚æ•°:**\n\n```json\n{tool_args_json}\n```\n\n</details>\n\n"
                else:
                    tool_display = f"\n\n<details>\n<summary>ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}</summary>\n\n*æ— å‚æ•°*\n\n</details>\n\n"

                queue.put_nowait(tool_display)

                self._emit_debug_log_sync(f"å·¥å…·å¼€å§‹: {tool_name}", __event_call__)

            elif event_type == "tool.execution_complete":
                tool_call_id = safe_get_data_attr(event, "tool_call_id", "")
                tool_info = active_tools.get(tool_call_id)

                # å¤„ç†æ—§çš„å­—ç¬¦ä¸²æ ¼å¼å’Œæ–°çš„å­—å…¸æ ¼å¼
                if isinstance(tool_info, str):
                    tool_name = tool_info
                elif isinstance(tool_info, dict):
                    tool_name = tool_info.get("name", "æœªçŸ¥å·¥å…·")
                else:
                    tool_name = "æœªçŸ¥å·¥å…·"

                # å°è¯•è·å–ç»“æœå†…å®¹
                result_content = ""
                result_type = "success"
                try:
                    result_obj = safe_get_data_attr(event, "result")
                    if hasattr(result_obj, "content"):
                        result_content = result_obj.content
                    elif isinstance(result_obj, dict):
                        result_content = result_obj.get("content", "")
                        result_type = result_obj.get("result_type", "success")
                        if not result_content:
                            # å¦‚æœæ²¡æœ‰ content å­—æ®µï¼Œå°è¯•åºåˆ—åŒ–æ•´ä¸ªå­—å…¸
                            result_content = json.dumps(
                                result_obj, indent=2, ensure_ascii=False
                            )
                except Exception as e:
                    self._emit_debug_log_sync(f"æå–ç»“æœæ—¶å‡ºé”™: {e}", __event_call__)
                    result_type = "failure"
                    result_content = f"é”™è¯¯: {str(e)}"

                # ä½¿ç”¨æ”¹è¿›çš„æ ¼å¼å±•ç¤ºå·¥å…·ç»“æœ
                if result_content:
                    status_icon = "âœ…" if result_type == "success" else "âŒ"

                    # å°è¯•æ£€æµ‹å†…å®¹ç±»å‹ä»¥ä¾¿æ›´å¥½åœ°æ ¼å¼åŒ–
                    is_json = False
                    try:
                        json_obj = (
                            json.loads(result_content)
                            if isinstance(result_content, str)
                            else result_content
                        )
                        if isinstance(json_obj, (dict, list)):
                            result_content = json.dumps(
                                json_obj, indent=2, ensure_ascii=False
                            )
                            is_json = True
                    except:
                        pass

                    # æ ¹æ®å†…å®¹ç±»å‹æ ¼å¼åŒ–
                    if is_json:
                        # JSON å†…å®¹ï¼šä½¿ç”¨ä»£ç å—å’Œè¯­æ³•é«˜äº®
                        result_display = f"\n<details>\n<summary>{status_icon} æ‰§è¡Œç»“æœ: {tool_name}</summary>\n\n```json\n{result_content}\n```\n\n</details>\n\n"
                    else:
                        # çº¯æ–‡æœ¬ï¼šä¿ç•™æ ¼å¼ï¼Œä¸ä½¿ç”¨ä»£ç å—
                        result_display = f"\n<details>\n<summary>{status_icon} æ‰§è¡Œç»“æœ: {tool_name}</summary>\n\n{result_content}\n\n</details>\n\n"

                    queue.put_nowait(result_display)

            elif event_type == "tool.execution_progress":
                # å·¥å…·æ‰§è¡Œè¿›åº¦æ›´æ–°ï¼ˆç”¨äºé•¿æ—¶é—´è¿è¡Œçš„å·¥å…·ï¼‰
                tool_call_id = safe_get_data_attr(event, "tool_call_id", "")
                tool_info = active_tools.get(tool_call_id)
                tool_name = (
                    tool_info.get("name", "æœªçŸ¥å·¥å…·")
                    if isinstance(tool_info, dict)
                    else "æœªçŸ¥å·¥å…·"
                )

                progress = safe_get_data_attr(event, "progress", 0)
                message = safe_get_data_attr(event, "message", "")

                if message:
                    progress_display = f"\n> ğŸ”„ **{tool_name}**: {message}\n"
                    queue.put_nowait(progress_display)

                self._emit_debug_log_sync(
                    f"å·¥å…·è¿›åº¦: {tool_name} - {progress}%", __event_call__
                )

            elif event_type == "tool.execution_partial_result":
                # æµå¼å·¥å…·ç»“æœï¼ˆç”¨äºå¢é‡è¾“å‡ºçš„å·¥å…·ï¼‰
                tool_call_id = safe_get_data_attr(event, "tool_call_id", "")
                tool_info = active_tools.get(tool_call_id)
                tool_name = (
                    tool_info.get("name", "æœªçŸ¥å·¥å…·")
                    if isinstance(tool_info, dict)
                    else "æœªçŸ¥å·¥å…·"
                )

                partial_content = safe_get_data_attr(event, "content", "")
                if partial_content:
                    queue.put_nowait(partial_content)

                self._emit_debug_log_sync(f"å·¥å…·éƒ¨åˆ†ç»“æœ: {tool_name}", __event_call__)

            # === ä½¿ç”¨ç»Ÿè®¡äº‹ä»¶ ===
            elif event_type == "assistant.usage":
                # å½“å‰åŠ©æ‰‹å›åˆçš„ token ä½¿ç”¨é‡
                if self.valves.DEBUG:
                    input_tokens = safe_get_data_attr(event, "input_tokens", 0)
                    output_tokens = safe_get_data_attr(event, "output_tokens", 0)
                    total_tokens = safe_get_data_attr(event, "total_tokens", 0)
                pass

            elif event_type == "session.usage_info":
                # ä¼šè¯ç´¯è®¡ä½¿ç”¨ä¿¡æ¯
                pass

            # === ä¼šè¯çŠ¶æ€äº‹ä»¶ ===
            elif event_type == "session.compaction_start":
                self._emit_debug_log_sync("ä¼šè¯å‹ç¼©å·²å¼€å§‹", __event_call__)

            elif event_type == "session.compaction_complete":
                self._emit_debug_log_sync("ä¼šè¯å‹ç¼©å·²å®Œæˆ", __event_call__)

            elif event_type == "session.idle":
                # ä¼šè¯å¤„ç†å®Œæˆ - å‘å‡ºå®Œæˆä¿¡å·
                done.set()
                try:
                    queue.put_nowait(SENTINEL)
                except:
                    pass

            elif event_type == "session.error":
                error_msg = safe_get_data_attr(event, "message", "æœªçŸ¥é”™è¯¯")
                queue.put_nowait(f"\n[é”™è¯¯: {error_msg}]")
                done.set()
                try:
                    queue.put_nowait(SENTINEL)
                except:
                    pass

        unsubscribe = session.on(handler)

        self._emit_debug_log_sync(f"å·²è®¢é˜…äº‹ä»¶ã€‚æ­£åœ¨å‘é€è¯·æ±‚...", __event_call__)

        # ä½¿ç”¨ asyncio.create_task é˜²æ­¢ session.send é˜»å¡æµè¯»å–
        # å¦‚æœ SDK å®ç°ç­‰å¾…å®Œæˆã€‚
        send_task = asyncio.create_task(session.send(send_payload))
        self._emit_debug_log_sync(f"Prompt å·²å‘é€ (å¼‚æ­¥ä»»åŠ¡å·²å¯åŠ¨)", __event_call__)

        # å®‰å…¨çš„åˆå§‹ yieldï¼Œå¸¦é”™è¯¯å¤„ç†
        try:
            if self.valves.DEBUG:
                yield "<think>\n"
                if init_message:
                    yield init_message

                if reasoning_effort and reasoning_effort != "off":
                    yield f"> [Debug] å·²æ³¨å…¥æ¨ç†å¼ºåº¦ (Reasoning Effort): {reasoning_effort.upper()}\n"

                yield "> [Debug] è¿æ¥å·²å»ºç«‹ï¼Œç­‰å¾…å“åº”...\n"
                self.thinking_started = True
        except Exception as e:
            # å¦‚æœåˆå§‹ yield å¤±è´¥ï¼Œè®°å½•ä½†ç»§ç»­å¤„ç†
            self._emit_debug_log_sync(f"åˆå§‹ yield è­¦å‘Š: {e}", __event_call__)

        try:
            while not done.is_set():
                try:
                    chunk = await asyncio.wait_for(
                        queue.get(), timeout=float(self.valves.TIMEOUT)
                    )
                    if chunk is SENTINEL:
                        break
                    if chunk:
                        has_content = True
                        try:
                            yield chunk
                        except Exception as yield_error:
                            # å®¢æˆ·ç«¯å…³é—­è¿æ¥ï¼Œä¼˜é›…åœæ­¢
                            self._emit_debug_log_sync(
                                f"Yield é”™è¯¯ï¼ˆå®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Ÿï¼‰: {yield_error}",
                                __event_call__,
                            )
                            break
                except asyncio.TimeoutError:
                    if done.is_set():
                        break
                    if self.thinking_started:
                        try:
                            yield f"> [Debug] ç­‰å¾…å“åº”ä¸­ (å·²è¶…è¿‡ {self.valves.TIMEOUT} ç§’)...\n"
                        except:
                            # å¦‚æœè¶…æ—¶æœŸé—´ yield å¤±è´¥ï¼Œè¿æ¥å·²æ–­å¼€
                            break
                    continue

            while not queue.empty():
                chunk = queue.get_nowait()
                if chunk is SENTINEL:
                    break
                if chunk:
                    has_content = True
                    try:
                        yield chunk
                    except:
                        # è¿æ¥å…³é—­ï¼Œåœæ­¢ yielding
                        break

            if self.thinking_started:
                try:
                    yield "\n</think>\n"
                    has_content = True
                except:
                    pass  # è¿æ¥å·²å…³é—­

            # æ ¸å¿ƒä¿®å¤ï¼šå¦‚æœæ•´ä¸ªè¿‡ç¨‹æ²¡æœ‰ä»»ä½•è¾“å‡ºï¼Œè¿”å›ä¸€ä¸ªæç¤ºï¼Œé˜²æ­¢ OpenWebUI æŠ¥é”™
            if not has_content:
                try:
                    yield "âš ï¸ Copilot æœªè¿”å›ä»»ä½•å†…å®¹ã€‚è¯·æ£€æŸ¥æ¨¡å‹ ID æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•åœ¨ Valves ä¸­å¼€å¯ DEBUG æ¨¡å¼æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ã€‚"
                except:
                    pass  # è¿æ¥å·²å…³é—­

        except Exception as e:
            try:
                yield f"\n[Stream Error: {str(e)}]"
            except:
                pass  # è¿æ¥å·²å…³é—­
        finally:
            unsubscribe()
            # é”€æ¯ä¼šè¯å¯¹è±¡ä»¥é‡Šæ”¾å†…å­˜ï¼Œä½†ä¿ç•™ç£ç›˜æ•°æ®
            await session.destroy()
