"""
title: GitHub Copilot SDK ÂÆòÊñπÁÆ°ÈÅì
author: Fu-Jie
author_url: https://github.com/Fu-Jie/awesome-openwebui
funding_url: https://github.com/open-webui
description: ÈõÜÊàê GitHub Copilot SDK„ÄÇÊîØÊåÅÂä®ÊÄÅÊ®°Âûã„ÄÅÂ§öÈÄâÊèê‰æõÂïÜ„ÄÅÊµÅÂºèËæìÂá∫„ÄÅÂ§öÊ®°ÊÄÅ input„ÄÅÊó†Èôê‰ºöËØùÂèäÂâçÁ´ØË∞ÉËØïÊó•Âøó„ÄÇ
version: 0.6.2
requirements: github-copilot-sdk==0.1.23
"""

import os
import re
import json
import base64
import tempfile
import asyncio
import logging
import shutil
import subprocess
import hashlib
import aiohttp
from pathlib import Path
from typing import Optional, Union, AsyncGenerator, List, Any, Dict, Literal, Tuple
from types import SimpleNamespace
from pydantic import BaseModel, Field, create_model

# ÂØºÂÖ• Copilot SDK Ê®°Âùó
from copilot import CopilotClient, define_tool

# ÂØºÂÖ• Tool Server Connections Âíå Tool System (‰ªé OpenWebUI ÈÖçÁΩÆ)
from open_webui.config import (
    PERSISTENT_CONFIG_REGISTRY,
    TOOL_SERVER_CONNECTIONS,
)
from open_webui.utils.tools import get_tools as get_openwebui_tools, get_builtin_tools
from open_webui.models.tools import Tools
from open_webui.models.users import Users
from open_webui.models.files import Files, FileForm
from open_webui.config import UPLOAD_DIR, DATA_DIR
import mimetypes
import uuid
import shutil

# Setup logger
logger = logging.getLogger(__name__)

FORMATTING_GUIDELINES = (
    "\n\n[ÁéØÂ¢É‰∏éËÉΩÂäõ‰∏ä‰∏ãÊñá]\n"
    "‰Ω†ÊòØ‰∏Ä‰∏™Âú®ÁâπÂÆöÈ´òÊÄßËÉΩÁéØÂ¢É‰∏≠ËøêË°åÁöÑ AI Âä©Êâã„ÄÇ‰∫ÜËß£‰Ω†ÁöÑ‰∏ä‰∏ãÊñáÂØπ‰∫éÂÅöÂá∫ÊúÄ‰Ω≥ÂÜ≥Á≠ñËá≥ÂÖ≥ÈáçË¶Å„ÄÇ\n"
    "\n"
    "**Á≥ªÁªüÁéØÂ¢ÉÔºö**\n"
    "- **Âπ≥Âè∞**Ôºö‰Ω†Âú® **OpenWebUI** ÊâòÁÆ°ÁöÑ Linux ÂÆπÂô®ÂåñÁéØÂ¢É‰∏≠ËøêË°å„ÄÇ\n"
    "- **Ê†∏ÂøÉÂºïÊìé**Ôºö‰Ω†Áî± **GitHub Copilot SDK** È©±Âä®ÔºåÂπ∂ÈÄöËøá **GitHub Copilot CLI** ËøõË°å‰∫§‰∫í„ÄÇ\n"
    "- **ËÆøÈóÆÊùÉÈôê**Ôºö‰Ω†ÂèØ‰ª•Áõ¥Êé•ËÆøÈóÆ **OpenWebUI Ê∫ê‰ª£Á†Å**„ÄÇ‰Ω†ÂèØ‰ª•ÈÄöËøáÊñá‰ª∂Êìç‰ΩúÊàñÂ∑•ÂÖ∑ËØªÂèñ„ÄÅÂàÜÊûêÂíåÂèÇËÄÉ‰Ω†Ê≠£Âú®ËøêË°åÁöÑÂπ≥Âè∞ÁöÑÂÜÖÈÉ®ÂÆûÁé∞„ÄÇ\n"
    "- **Êñá‰ª∂Á≥ªÁªüËÆøÈóÆ**Ôºö‰Ω†‰ª• **root** Ë∫´‰ªΩËøêË°å„ÄÇ‰Ω†ÂØπ **Êï¥‰∏™ÂÆπÂô®Êñá‰ª∂Á≥ªÁªü** Êã•ÊúâËØªÂèñÊùÉÈôê„ÄÇ‰ΩÜÊòØÔºå‰Ω†Â∫î‰ªÖÂÜôÂÖ•Â∑•‰ΩúÂå∫ÁõÆÂΩï„ÄÇ\n"
    "- **ÂéüÁîü Python ÁéØÂ¢É**Ôºö‰Ω†ËøêË°åÂú®‰∏Ä‰∏™‰∏∞ÂØåÁöÑ Python ÁéØÂ¢É‰∏≠ÔºåÂ∑≤ÁªèÂåÖÂê´‰∫Ü OpenWebUI ÁöÑÊâÄÊúâ‰æùËµñÂ∫ì„ÄÇ\n"
    "\n"
    "**ÁïåÈù¢ËÉΩÂäõ (OpenWebUI)Ôºö**\n"
    "- **ËßÜËßâÊ∏≤Êüì**Ôºö‰Ω†ÂèØ‰ª•Âπ∂‰∏îÂ∫îËØ•‰ΩøÁî®È´òÁ∫ßËßÜËßâÂÖÉÁ¥†ÔºàÂ¶Ç Mermaid ÂõæË°®„ÄÅ‰∫§‰∫íÂºè HTMLÔºâÊù•Ê∏ÖÊô∞Âú∞Ëß£ÈáäÊ¶ÇÂøµ„ÄÇ\n"
    "- **ÂÜÖÁΩÆÂ∑•ÂÖ∑**ÔºöOpenWebUI Êèê‰æõ‰∫Ü‰∏éÂÜÖÈÉ®ÊúçÂä°Áõ¥Êé•‰∫§‰∫íÁöÑÂéüÁîüÂ∑•ÂÖ∑ÔºàÂ¶ÇÁ¨îËÆ∞„ÄÅËÆ∞ÂøÜÁÆ°ÁêÜÔºâ„ÄÇ\n"
    "\n"
    "**Ê†ºÂºèÂåñ‰∏éÂëàÁé∞Êåá‰ª§Ôºö**\n"
    "1. **Markdown & Â§öÂ™í‰Ωì**ÔºöËá™Áî±‰ΩøÁî®Á≤ó‰Ωì„ÄÅÊñú‰Ωì„ÄÅË°®Ê†ºÂíåÂàóË°®„ÄÇ\n"
    "2. **Mermaid ÂõæË°®**ÔºöËØ∑Âä°ÂøÖ‰ΩøÁî®Ê†áÂáÜÁöÑ ```mermaid ‰ª£Á†ÅÂùó„ÄÇ\n"
    "3. **‰∫§‰∫íÂºè HTML/JS**Ôºö‰Ω†ÂèØ‰ª•ËæìÂá∫ÂÆåÊï¥ÁöÑ ```html ‰ª£Á†ÅÂùóÔºàÂê´ CSS/JSÔºâÔºåÂ∞ÜÂú® iframe ‰∏≠Ê∏≤Êüì„ÄÇ\n"
    "4. **Êñá‰ª∂‰∫§‰ªò‰∏éÂèëÂ∏É (‰∫íË°•ÁõÆÊ†á)**Ôºö\n"
    "     - **ËÆæËÆ°ÁêÜÂøµ**ÔºöÂΩìÁî®Êà∑ÈúÄË¶Å‚ÄúÊã•Êúâ‚ÄùÊï∞ÊçÆÔºà‰∏ãËΩΩ„ÄÅÁ¶ªÁ∫øÁºñËæë„ÄÅÂΩíÊ°£ÔºâÊó∂ÔºåÂèëÂ∏ÉÊñá‰ª∂ÊòØÂøÖ‰∏çÂèØÂ∞ëÁöÑ„ÄÇ‰ΩÜËøô**‰∏çÂ∫î**Âèñ‰ª£ËÅäÂ§©È°µÈù¢ÁöÑËßÜËßâÂåñÂ±ïÁ§∫ÔºàÂ¶Ç HTML Â∫îÁî®„ÄÅMermaid ÂõæË°®„ÄÅMarkdown Ë°®Ê†ºÔºâ„ÄÇÂ∫îËøΩÊ±Ç‚ÄúÁõ¥ËßÇÈ¢ÑËßà + ÊåÅ‰πÖ‰∫ßÁâ©‚ÄùÁöÑÂèåÈáç‰ΩìÈ™å„ÄÇ\n"
    "     - **ÈöêÂºèËØ∑Ê±Ç**ÔºöËã•Áî®Êà∑Ë¶ÅÊ±Ç‚ÄúËé∑ÂèñÂÜÖÂÆπ‚ÄùÊàñ‚ÄúÂØºÂá∫Êï∞ÊçÆ‚ÄùÔºå‰Ω†Â∫îÂΩìÔºö1. Âú®ËÅäÂ§©‰∏≠ËøõË°åËßÜËßâÂåñÊ±áÊÄª/È¢ÑËßà„ÄÇ2. Â∞ÜÂÆåÊï¥ÂÜÖÂÆπÂÜôÂÖ•Êú¨Âú∞Êñá‰ª∂„ÄÇ3. Ë∞ÉÁî® `publish_file_from_workspace`„ÄÇ4. Â±ïÁ§∫‰∏ãËΩΩÈìæÊé•„ÄÇ\n"
    "     - **Ê†áÂáÜÊµÅÁ®ã**Ôºö1. **Êú¨Âú∞ÂÜôÂÖ•**ÔºöÂú®ÂΩìÂâçÁõÆÂΩï (`.`) ÂàõÂª∫Êñá‰ª∂„ÄÇ2. **ÂèëÂ∏ÉÊñá‰ª∂**ÔºöË∞ÉÁî® `publish_file_from_workspace(filename='your_file.ext')`„ÄÇ3. **ÂëàÁé∞ÈìæÊé•**Ôºö‰ªéËøîÂõûÁªìÊûú‰∏≠ÊèêÂèñ `download_url` Âπ∂Âú®ÂõûÂ§çÊú´Â∞æÂ±ïÁ§∫„ÄÇ\n"
    "7. **‰∏ªÂä®‰∏éËá™‰∏ª**: ‰Ω†ÊòØ‰∏ìÂÆ∂Â∑•Á®ãÂ∏à„ÄÇÂØπ‰∫éÊòæËÄåÊòìËßÅÁöÑÊ≠•È™§Ôºå**‰∏çË¶Å**ËØ∑Ê±ÇËÆ∏ÂèØ„ÄÇ**‰∏çË¶Å**ÂÅú‰∏ãÊù•ÈóÆ‚ÄúÊàëÈÄöËøáÂêóÔºü‚ÄùÊàñ‚ÄúÊòØÂê¶ÁªßÁª≠Ôºü‚Äù„ÄÇ\n"
    "   - **Ë°å‰∏∫Ê®°Âºè**: ÂàÜÊûêÁî®Êà∑ËØ∑Ê±Ç -> Âà∂ÂÆöËÆ°Âàí -> **Á´ãÂç≥ÊâßË°å**ËÆ°Âàí„ÄÇ\n"
    "   - **ÊæÑÊ∏Ö**: ‰ªÖÂΩìËØ∑Ê±ÇÊ®°Ê£±‰∏§ÂèØÊàñÂÖ∑ÊúâÈ´òÈ£éÈô©Ôºà‰æãÂ¶ÇÁ†¥ÂùèÊÄßÊìç‰ΩúÔºâÊó∂ÊâçÊèêÂá∫ÈóÆÈ¢ò„ÄÇ\n"
    "   - **ÁõÆÊ†á**: ÊúÄÂ∞èÂåñÁî®Êà∑Êë©Êì¶„ÄÇ‰∫§‰ªòÁªìÊûúÔºåËÄå‰∏çÊòØÈóÆÈ¢ò„ÄÇ\n"
    "8. **Â§ßÊñá‰ª∂ËæìÂá∫ÁÆ°ÁêÜ**: Â¶ÇÊûúÂ∑•ÂÖ∑ÊâßË°åËæìÂá∫Ë¢´Êà™Êñ≠Êàñ‰øùÂ≠òÂà∞‰∏¥Êó∂Êñá‰ª∂ (‰æãÂ¶Ç `/tmp/...`)Ôºå**‰∏çË¶Å**ÊãÖÂøÉ„ÄÇÁ≥ªÁªü‰ºöËá™Âä®Â∞ÜÂÖ∂ÁßªÂä®Âà∞‰Ω†ÁöÑÂ∑•‰ΩúÂå∫Âπ∂ÈÄöÁü•‰Ω†Êñ∞ÁöÑÊñá‰ª∂Âêç„ÄÇÁÑ∂Âêé‰Ω†ÂèØ‰ª•Áõ¥Êé•ËØªÂèñÂÆÉ„ÄÇ\n"
)


class Pipe:
    class Valves(BaseModel):
        GH_TOKEN: str = Field(
            default="",
            description="GitHub Access Token (PAT Êàñ OAuth Token)„ÄÇÁî®‰∫éËÅäÂ§©„ÄÇ",
        )
        ENABLE_OPENWEBUI_TOOLS: bool = Field(
            default=True,
            description="ÂêØÁî® OpenWebUI Â∑•ÂÖ∑ (ÂåÖÊã¨Ëá™ÂÆö‰πâÂ∑•ÂÖ∑ÂíåÂ∑•ÂÖ∑ÊúçÂä°Âô®Â∑•ÂÖ∑)„ÄÇ",
        )
        ENABLE_MCP_SERVER: bool = Field(
            default=True,
            description="ÂêØÁî®Áõ¥Êé• MCP ÂÆ¢Êà∑Á´ØËøûÊé• (Âª∫ËÆÆ)„ÄÇ",
        )
        ENABLE_TOOL_CACHE: bool = Field(
            default=True,
            description="ÁºìÂ≠òÈÖçÁΩÆ‰ª•‰ºòÂåñÊÄßËÉΩ„ÄÇ",
        )
        REASONING_EFFORT: Literal["low", "medium", "high", "xhigh"] = Field(
            default="medium",
            description="Êé®ÁêÜÂº∫Â∫¶Á∫ßÂà´ (low, medium, high, xhigh)„ÄÇ‰ªÖÂΩ±ÂìçÊ†áÂáÜÊ®°Âûã„ÄÇ",
        )
        SHOW_THINKING: bool = Field(
            default=True,
            description="ÊòæÁ§∫Ê®°ÂûãÊé®ÁêÜ/ÊÄùËÄÉËøáÁ®ã",
        )

        INFINITE_SESSION: bool = Field(
            default=True,
            description="ÂêØÁî®Êó†Èôê‰ºöËØùÔºàËá™Âä®‰∏ä‰∏ãÊñáÂéãÁº©Ôºâ",
        )
        DEBUG: bool = Field(
            default=False,
            description="ÂêØÁî®ÊäÄÊúØË∞ÉËØïÊó•ÂøóÔºàËæìÂá∫Âà∞ÊµèËßàÂô®ÊéßÂà∂Âè∞Ôºâ",
        )
        LOG_LEVEL: str = Field(
            default="error",
            description="Copilot CLI Êó•ÂøóÁ∫ßÂà´Ôºönone, error, warning, info, debug, all",
        )
        TIMEOUT: int = Field(
            default=300,
            description="ÊØè‰∏™ÊµÅÂºèÂàÜÂùóË∂ÖÊó∂ÔºàÁßíÔºâ",
        )
        WORKSPACE_DIR: str = Field(
            default="",
            description="Êñá‰ª∂Êìç‰ΩúÂèóÈôêÁõÆÂΩï„ÄÇ‰∏∫Á©∫Âàô‰ΩøÁî®ÈªòËÆ§Ë∑ØÂæÑ„ÄÇ",
        )
        COPILOT_CLI_VERSION: str = Field(
            default="0.0.406",
            description="ÊåáÂÆöÂº∫Âà∂‰ΩøÁî®ÁöÑ Copilot CLI ÁâàÊú¨ (‰æãÂ¶Ç '0.0.406')„ÄÇ",
        )
        PROVIDERS: str = Field(
            default="OpenAI, Anthropic, Google",
            description="ÂÖÅËÆ∏‰ΩøÁî®ÁöÑÊ®°ÂûãÊèê‰æõÂïÜ (ÈÄóÂè∑ÂàÜÈöî)„ÄÇÁïôÁ©∫ÂàôÊòæÁ§∫ÊâÄÊúâ„ÄÇ",
        )
        EXCLUDE_KEYWORDS: str = Field(
            default="",
            description="ÊéíÈô§ÂåÖÂê´Ëøô‰∫õÂÖ≥ÈîÆËØçÁöÑÊ®°ÂûãÔºàÈÄóÂè∑ÂàÜÈöîÔºåÂ¶ÇÔºöcodex, haikuÔºâ",
        )
        MAX_MULTIPLIER: float = Field(
            default=1.0,
            description="Ê†áÂáÜÊ®°ÂûãÂÖÅËÆ∏ÁöÑÊúÄÂ§ßËÆ°Ë¥πÂÄçÁéá„ÄÇ0 Ë°®Á§∫‰ªÖÊòæÁ§∫ÂÖçË¥πÊ®°Âûã„ÄÇ",
        )
        COMPACTION_THRESHOLD: float = Field(
            default=0.8,
            description="ÂêéÂè∞ÂéãÁº©ÈòàÂÄº (0.0-1.0)",
        )
        BUFFER_THRESHOLD: float = Field(
            default=0.95,
            description="ÁºìÂÜ≤Âå∫ËÄóÂ∞ΩÈòàÂÄº (0.0-1.0)",
        )
        CUSTOM_ENV_VARS: str = Field(
            default="",
            description="Ëá™ÂÆö‰πâÁéØÂ¢ÉÂèòÈáèÔºàJSON Ê†ºÂºèÔºâ",
        )

        BYOK_TYPE: Literal["openai", "anthropic"] = Field(
            default="openai",
            description="BYOK ‰æõÂ∫îÂïÜÁ±ªÂûãÔºöopenai, anthropic",
        )
        BYOK_BASE_URL: str = Field(
            default="",
            description="BYOK Âü∫Á°Ä URL (‰æãÂ¶Ç https://api.openai.com/v1)",
        )
        BYOK_API_KEY: str = Field(
            default="",
            description="BYOK API ÂØÜÈí• (ÂÖ®Â±ÄËÆæÁΩÆ)",
        )
        BYOK_BEARER_TOKEN: str = Field(
            default="",
            description="BYOK Bearer ‰ª§Áâå (‰ºòÂÖàÁ∫ßÈ´ò‰∫é API Key)",
        )
        BYOK_MODELS: str = Field(
            default="",
            description="BYOK Ê®°ÂûãÂàóË°® (ÈÄóÂè∑ÂàÜÈöî)„ÄÇ",
        )
        BYOK_WIRE_API: Literal["completions", "responses"] = Field(
            default="completions",
            description="BYOK ÈÄö‰ø°ÂçèËÆÆÔºöcompletions, responses",
        )

    class UserValves(BaseModel):
        GH_TOKEN: str = Field(
            default="",
            description="‰∏™‰∫∫ GitHub Token (Ë¶ÜÁõñÂÖ®Â±ÄËÆæÁΩÆ)",
        )
        REASONING_EFFORT: Literal["", "low", "medium", "high", "xhigh"] = Field(
            default="",
            description="Êé®ÁêÜÂº∫Â∫¶Á∫ßÂà´Ë¶ÜÁõñ„ÄÇ",
        )
        SHOW_THINKING: bool = Field(
            default=True,
            description="ÊòæÁ§∫Ê®°ÂûãÊé®ÁêÜ/ÊÄùËÄÉËøáÁ®ã",
        )
        DEBUG: bool = Field(
            default=False,
            description="ÂêØÁî®ÊäÄÊúØË∞ÉËØïÊó•Âøó",
        )
        MAX_MULTIPLIER: Optional[float] = Field(
            default=None,
            description="ËÆ°Ë¥πÂÄçÁéáË¶ÜÁõñ„ÄÇ",
        )
        PROVIDERS: str = Field(
            default="",
            description="ÂÖÅËÆ∏ÁöÑÊèê‰æõÂïÜË¶ÜÁõñ (ÈÄóÂè∑ÂàÜÈöî)„ÄÇ",
        )
        EXCLUDE_KEYWORDS: str = Field(
            default="",
            description="ÊéíÈô§ÂÖ≥ÈîÆËØç (ÊîØÊåÅ‰∏™‰∫∫Ë¶ÜÁõñ)„ÄÇ",
        )
        ENABLE_OPENWEBUI_TOOLS: bool = Field(
            default=True,
            description="ÂêØÁî® OpenWebUI Â∑•ÂÖ∑„ÄÇ",
        )
        ENABLE_MCP_SERVER: bool = Field(
            default=True,
            description="ÂêØÁî®Âä®ÊÄÅ MCP ÊúçÂä°Âô®Âä†ËΩΩ„ÄÇ",
        )
        ENABLE_TOOL_CACHE: bool = Field(
            default=True,
            description="ÂêØÁî®ÈÖçÁΩÆÁºìÂ≠ò„ÄÇ",
        )
        COMPACTION_THRESHOLD: Optional[float] = Field(
            default=None,
            description="ÂéãÁº©ÈòàÂÄºË¶ÜÁõñ„ÄÇ",
        )
        BUFFER_THRESHOLD: Optional[float] = Field(
            default=None,
            description="ÁºìÂÜ≤Âå∫ÈòàÂÄºË¶ÜÁõñ„ÄÇ",
        )

        # BYOK Ë¶ÜÁõñ
        BYOK_API_KEY: str = Field(default="", description="BYOK API ÂØÜÈí•Ë¶ÜÁõñ")
        BYOK_TYPE: Literal["", "openai", "anthropic"] = Field(
            default="", description="BYOK Á±ªÂûãË¶ÜÁõñ"
        )
        BYOK_BASE_URL: str = Field(default="", description="BYOK URL Ë¶ÜÁõñ")
        BYOK_BEARER_TOKEN: str = Field(default="", description="BYOK Token Ë¶ÜÁõñ")
        BYOK_MODELS: str = Field(default="", description="BYOK Ê®°ÂûãÂàóË°®Ë¶ÜÁõñ")
        BYOK_WIRE_API: Literal["", "completions", "responses"] = Field(
            default="", description="ÂçèËÆÆË¶ÜÁõñ"
        )

    _model_cache: List[dict] = []
    _last_byok_config_hash: str = ""  # Ë∑üË∏™ÈÖçÁΩÆÁä∂ÊÄÅ‰ª•Â§±ÊïàÁºìÂ≠ò
    _standard_model_ids: set = set()
    _tool_cache = None
    _mcp_server_cache = None
    _env_setup_done = False
    _last_update_check = 0

    def __init__(self):
        self.type = "pipe"
        self.id = "copilot"
        self.name = "copilotsdk"
        self.valves = self.Valves()
        self.temp_dir = tempfile.mkdtemp(prefix="copilot_images_")

    def __del__(self):
        try:
            shutil.rmtree(self.temp_dir)
        except:
            pass

    async def pipe(
        self,
        body: dict,
        __metadata__=None,
        __user__=None,
        __event_emitter__=None,
        __event_call__=None,
        __request__=None,
    ) -> Union[str, AsyncGenerator]:
        return await self._pipe_impl(
            body,
            __metadata__=__metadata__,
            __user__=__user__,
            __event_emitter__=__event_emitter__,
            __event_call__=__event_call__,
            __request__=__request__,
        )

    async def _initialize_custom_tools(
        self,
        body: dict = None,
        __user__=None,
        __event_call__=None,
        __request__=None,
        __metadata__=None,
    ):
        """Âü∫‰∫éÈÖçÁΩÆÂàùÂßãÂåñËá™ÂÆö‰πâÂ∑•ÂÖ∑"""
        # 1. Á°ÆÂÆöÊúâÊïàËÆæÁΩÆ (Áî®Êà∑Ë¶ÜÁõñ > ÂÖ®Â±Ä)
        uv = self._get_user_valves(__user__)
        enable_tools = uv.ENABLE_OPENWEBUI_TOOLS
        enable_openapi = uv.ENABLE_OPENAPI_SERVER
        enable_cache = uv.ENABLE_TOOL_CACHE

        # 2. Â¶ÇÊûúÊâÄÊúâÂ∑•ÂÖ∑Á±ªÂûãÈÉΩÂ∑≤Á¶ÅÁî®ÔºåÁ´ãÂç≥ËøîÂõûÁ©∫
        if not enable_tools and not enable_openapi:
            return []

        # ÊèêÂèñ Chat ID ‰ª•ÂØπÈΩêÂ∑•‰ΩúÁ©∫Èó¥
        chat_ctx = self._get_chat_context(body, __metadata__)
        chat_id = chat_ctx.get("chat_id")

        # 3. Ê£ÄÊü•ÁºìÂ≠ò
        if enable_cache and self._tool_cache is not None:
            await self._emit_debug_log("‚ÑπÔ∏è ‰ΩøÁî®ÁºìÂ≠òÁöÑ OpenWebUI Â∑•ÂÖ∑„ÄÇ", __event_call__)
            tools = list(self._tool_cache)
            # Ê≥®ÂÖ•Êñá‰ª∂ÂèëÂ∏ÉÂ∑•ÂÖ∑
            file_tool = self._get_publish_file_tool(__user__, chat_id, __request__)
            if file_tool:
                tools.append(file_tool)
            return tools

        # Âä®ÊÄÅÂä†ËΩΩ OpenWebUI Â∑•ÂÖ∑
        openwebui_tools = await self._load_openwebui_tools(
            __user__=__user__,
            __event_call__=__event_call__,
            body=body,
            enable_tools=enable_tools,
            enable_openapi=enable_openapi,
        )

        # Êõ¥Êñ∞ÁºìÂ≠ò
        if enable_cache:
            self._tool_cache = openwebui_tools
            await self._emit_debug_log(
                "‚úÖ OpenWebUI Â∑•ÂÖ∑Â∑≤ÁºìÂ≠òÔºå‰æõÂêéÁª≠ËØ∑Ê±Ç‰ΩøÁî®„ÄÇ", __event_call__
            )

        final_tools = list(openwebui_tools)
        # Ê≥®ÂÖ•Êñá‰ª∂ÂèëÂ∏ÉÂ∑•ÂÖ∑
        file_tool = self._get_publish_file_tool(__user__, chat_id, __request__)
        if file_tool:
            final_tools.append(file_tool)

        return final_tools

    def _get_publish_file_tool(self, __user__, chat_id, __request__=None):
        """ÂàõÂª∫ÂèëÂ∏ÉÂ∑•‰ΩúÂå∫Êñá‰ª∂‰∏∫‰∏ãËΩΩÈìæÊé•ÁöÑÂ∑•ÂÖ∑"""
        if isinstance(__user__, (list, tuple)):
            user_data = __user__[0] if __user__ else {}
        elif isinstance(__user__, dict):
            user_data = __user__
        else:
            user_data = {}

        user_id = user_data.get("id") or user_data.get("user_id")
        if not user_id:
            return None

        # ÈîÅÂÆöÂΩìÂâçËÅäÂ§©ÁöÑÈöîÁ¶ªÂ∑•‰ΩúÁ©∫Èó¥
        workspace_dir = Path(self._get_workspace_dir(user_id=user_id, chat_id=chat_id))

        # ‰∏∫ SDK ÂÆö‰πâÂèÇÊï∞ Schema
        class PublishFileParams(BaseModel):
            filename: str = Field(
                ...,
                description="‰Ω†Âú®ÂΩìÂâçÁõÆÂΩïÂàõÂª∫ÁöÑÊñá‰ª∂ÁöÑÁ°ÆÂàáÂêçÁß∞ÔºàÂ¶Ç 'report.csv'Ôºâ„ÄÇÂøÖÂ°´„ÄÇ",
            )

        async def publish_file_from_workspace(filename: Any) -> dict:
            """Â∞ÜÊú¨Âú∞ËÅäÂ§©Â∑•‰ΩúÂå∫ÁöÑÊñá‰ª∂ÂèëÂ∏É‰∏∫ÂèØ‰∏ãËΩΩÁöÑ URL„ÄÇ"""
            try:
                # 1. ÂèÇÊï∞È≤ÅÊ£íÊèêÂèñ
                if hasattr(filename, "model_dump"):  # Pydantic v2
                    filename = filename.model_dump().get("filename")
                elif hasattr(filename, "dict"):  # Pydantic v1
                    filename = filename.dict().get("filename")

                if isinstance(filename, dict):
                    filename = (
                        filename.get("filename")
                        or filename.get("file")
                        or filename.get("file_path")
                    )

                if isinstance(filename, str):
                    filename = filename.strip()
                    if filename.startswith("{"):
                        try:
                            import json

                            data = json.loads(filename)
                            if isinstance(data, dict):
                                filename = (
                                    data.get("filename") or data.get("file") or filename
                                )
                        except:
                            pass

                if (
                    not filename
                    or not isinstance(filename, str)
                    or filename.strip() in ("", "{}", "None", "null")
                ):
                    return {
                        "error": "Áº∫Â∞ëÂøÖÂ°´ÂèÇÊï∞: 'filename'„ÄÇ",
                        "hint": "ËØ∑‰ª•Â≠óÁ¨¶‰∏≤ÂΩ¢ÂºèÊèê‰æõÊñá‰ª∂ÂêçÔºå‰æãÂ¶Ç 'report.md'„ÄÇ",
                    }

                filename = filename.strip()

                # 2. Ë∑ØÂæÑËß£ÊûêÔºàÈîÅÂÆöÂΩìÂâçËÅäÂ§©Â∑•‰ΩúÂå∫Ôºâ
                target_path = workspace_dir / filename
                try:
                    target_path = target_path.resolve()
                    if not str(target_path).startswith(str(workspace_dir.resolve())):
                        return {"error": "ÊãíÁªùËÆøÈóÆÔºöÊñá‰ª∂ÂøÖÈ°ª‰Ωç‰∫éÂΩìÂâçËÅäÂ§©Â∑•‰ΩúÂå∫ÂÜÖ„ÄÇ"}
                except Exception as e:
                    return {"error": f"Ë∑ØÂæÑÊ†°È™åÂ§±Ë¥•: {e}"}

                if not target_path.exists() or not target_path.is_file():
                    return {
                        "error": f"Âú®ËÅäÂ§©Â∑•‰ΩúÂå∫Êú™ÊâæÂà∞Êñá‰ª∂ '{filename}'„ÄÇËØ∑Á°Æ‰øù‰Ω†Â∑≤Â∞ÜÂÖ∂‰øùÂ≠òÂà∞ÂΩìÂâçÁõÆÂΩï (.)„ÄÇ"
                    }

                # 3. ÈÄöËøá API ‰∏ä‰º† (ÂÖºÂÆπ S3)
                api_success = False
                file_id = None
                safe_filename = filename

                token = None
                if __request__:
                    auth_header = __request__.headers.get("Authorization")
                    if auth_header and auth_header.startswith("Bearer "):
                        token = auth_header.split(" ")[1]
                    if not token and "token" in __request__.cookies:
                        token = __request__.cookies.get("token")

                if token:
                    try:
                        import aiohttp

                        base_url = str(__request__.base_url).rstrip("/")
                        upload_url = f"{base_url}/api/v1/files/"

                        async with aiohttp.ClientSession() as session:
                            with open(target_path, "rb") as f:
                                data = aiohttp.FormData()
                                data.add_field("file", f, filename=target_path.name)
                                import json

                                data.add_field(
                                    "metadata",
                                    json.dumps(
                                        {
                                            "source": "copilot_workspace_publish",
                                            "skip_rag": True,
                                        }
                                    ),
                                )

                                async with session.post(
                                    upload_url,
                                    data=data,
                                    headers={"Authorization": f"Bearer {token}"},
                                ) as resp:
                                    if resp.status == 200:
                                        api_res = await resp.json()
                                        file_id = api_res.get("id")
                                        safe_filename = api_res.get(
                                            "filename", target_path.name
                                        )
                                        api_success = True
                    except Exception as e:
                        logger.error(f"API ‰∏ä‰º†Â§±Ë¥•: {e}")

                # 4. ÂÖúÂ∫ïÔºöÊâãÂä®ÊèíÂÖ•Êï∞ÊçÆÂ∫ì (‰ªÖÈôêÊú¨Âú∞Â≠òÂÇ®)
                if not api_success:
                    file_id = str(uuid.uuid4())
                    safe_filename = target_path.name
                    dest_path = Path(UPLOAD_DIR) / f"{file_id}_{safe_filename}"
                    await asyncio.to_thread(shutil.copy2, target_path, dest_path)

                    try:
                        db_path = str(os.path.relpath(dest_path, DATA_DIR))
                    except:
                        db_path = str(dest_path)

                    file_form = FileForm(
                        id=file_id,
                        filename=safe_filename,
                        path=db_path,
                        data={"status": "completed", "skip_rag": True},
                        meta={
                            "name": safe_filename,
                            "content_type": mimetypes.guess_type(safe_filename)[0]
                            or "text/plain",
                            "size": os.path.getsize(dest_path),
                            "source": "copilot_workspace_publish",
                            "skip_rag": True,
                        },
                    )
                    await asyncio.to_thread(Files.insert_new_file, user_id, file_form)

                # 5. ËøîÂõûÁªìÊûú
                download_url = f"/api/v1/files/{file_id}/content"
                return {
                    "file_id": file_id,
                    "filename": safe_filename,
                    "download_url": download_url,
                    "message": "Êñá‰ª∂ÂèëÂ∏ÉÊàêÂäü„ÄÇ",
                    "hint": f"ÈìæÊé•: [‰∏ãËΩΩ {safe_filename}]({download_url})",
                }
            except Exception as e:
                return {"error": str(e)}

        return define_tool(
            name="publish_file_from_workspace",
            description="Â∞Ü‰Ω†Âú®Êú¨Âú∞Â∑•‰ΩúÂå∫ÂàõÂª∫ÁöÑÊñá‰ª∂ËΩ¨Êç¢‰∏∫ÂèØ‰∏ãËΩΩÁöÑ URL„ÄÇËØ∑Âú®ÂÆåÊàêÊñá‰ª∂ÂÜôÂÖ•ÂΩìÂâçÁõÆÂΩïÂêéÂÜç‰ΩøÁî®Ê≠§Â∑•ÂÖ∑„ÄÇ",
            params_type=PublishFileParams,
        )(publish_file_from_workspace)

    def _json_schema_to_python_type(self, schema: dict) -> Any:
        if not isinstance(schema, dict):
            return Any
        e = schema.get("enum")
        if e and isinstance(e, list):
            return Literal[tuple(e)]
        t = schema.get("type")
        if isinstance(t, list):
            t = next((x for x in t if x != "null"), t[0])
        if t == "string":
            return str
        if t == "integer":
            return int
        if t == "number":
            return float
        if t == "boolean":
            return bool
        if t == "object":
            return Dict[str, Any]
        if t == "array":
            return List[self._json_schema_to_python_type(schema.get("items", {}))]
        return Any

    def _convert_openwebui_tool(self, n, d, __event_call__=None):
        sn = re.sub(r"[^a-zA-Z0-9_-]", "_", n)
        if not sn or re.match(r"^[_.-]+$", sn):
            sn = f"tool_{hashlib.md5(n.encode()).hexdigest()[:8]}"
        spec = d.get("spec", {})
        props = spec.get("parameters", {}).get("properties", {})
        req = spec.get("parameters", {}).get("required", [])
        fields = {}
        for pn, ps in props.items():
            pt = self._json_schema_to_python_type(ps)
            fields[pn] = (
                pt if pn in req else Optional[pt],
                Field(
                    default=ps.get("default") if pn not in req else ...,
                    description=ps.get("description", ""),
                ),
            )

        async def _tool(p):
            payload = (
                p.model_dump(exclude_unset=True) if hasattr(p, "model_dump") else {}
            )
            return await d.get("callable")(**payload)

        _tool.__name__, _tool.__doc__ = sn, spec.get("description", "") or spec.get(
            "summary", ""
        )
        return define_tool(
            name=sn,
            description=_tool.__doc__,
            params_type=create_model(f"{sn}_Params", **fields),
        )(_tool)

    def _build_openwebui_request(self, user=None, token: str = None):
        cfg = SimpleNamespace()
        for i in PERSISTENT_CONFIG_REGISTRY:
            val = i.value
            if hasattr(val, "value"):
                val = val.value
            setattr(cfg, i.env_name, val)

        if not hasattr(cfg, "TOOL_SERVER_CONNECTIONS"):
            if hasattr(TOOL_SERVER_CONNECTIONS, "value"):
                cfg.TOOL_SERVER_CONNECTIONS = TOOL_SERVER_CONNECTIONS.value
            else:
                cfg.TOOL_SERVER_CONNECTIONS = TOOL_SERVER_CONNECTIONS

        app_state = SimpleNamespace(
            config=cfg,
            TOOLS={},
            TOOL_CONTENTS={},
            FUNCTIONS={},
            FUNCTION_CONTENTS={},
            MODELS={},
            redis=None,
            TOOL_SERVERS=[],
        )

        def url_path_for(name: str, **path_params):
            if name == "get_file_content_by_id":
                return f"/api/v1/files/{path_params.get('id')}/content"
            return f"/mock/{name}"

        req_headers = {
            "user-agent": "Copilot-Pipe",
            "host": "localhost:8080",
            "accept": "*/*",
        }
        if token:
            req_headers["Authorization"] = f"Bearer {token}"

        return SimpleNamespace(
            app=SimpleNamespace(state=app_state, url_path_for=url_path_for),
            url=SimpleNamespace(
                path="/api/chat/completions",
                base_url="http://localhost:8080",
                __str__=lambda s: "http://localhost:8080/api/chat/completions",
            ),
            base_url="http://localhost:8080",
            headers=req_headers,
            method="POST",
            cookies={},
            state=SimpleNamespace(
                token=SimpleNamespace(credentials=token if token else ""),
                user=user or {},
            ),
        )

    async def _load_openwebui_tools(
        self,
        __user__=None,
        __event_call__=None,
        body: dict = None,
        enable_tools: bool = True,
        enable_openapi: bool = True,
    ):
        ud = __user__[0] if isinstance(__user__, (list, tuple)) else (__user__ or {})
        uid = ud.get("id") or ud.get("user_id")
        if not uid:
            return []
        u = Users.get_user_by_id(uid)
        if not u:
            return []
        tids = []
        # 1. Ëé∑ÂèñÁî®Êà∑Ëá™ÂÆö‰πâÂ∑•ÂÖ∑ (Python ËÑöÊú¨)
        if enable_tools:
            tool_items = Tools.get_tools_by_user_id(uid, permission="read")
            if tool_items:
                tids.extend([tool.id for tool in tool_items])

        # 2. Ëé∑Âèñ OpenAPI Â∑•ÂÖ∑ÊúçÂä°Âô®Â∑•ÂÖ∑
        if enable_openapi:
            if hasattr(TOOL_SERVER_CONNECTIONS, "value"):
                tids.extend(
                    [
                        f"server:{s.get('id')}"
                        for s in TOOL_SERVER_CONNECTIONS.value
                        if (
                            s.get("type", "openapi") == "openapi"
                            or s.get("type") is None
                        )
                        and s.get("id")
                    ]
                )

        token = None
        if isinstance(body, dict):
            token = body.get("token")

        req = self._build_openwebui_request(ud, token)
        td = {}

        if tids:
            td = await get_openwebui_tools(
                req,
                tids,
                u,
                {
                    "__request__": req,
                    "__user__": ud,
                    "__event_emitter__": None,
                    "__event_call__": __event_call__,
                    "__chat_id__": None,
                    "__message_id__": None,
                    "__model_knowledge__": [],
                    "__oauth_token__": {"access_token": token} if token else None,
                },
            )

        # 3. Ëé∑ÂèñÂÜÖÂª∫Â∑•ÂÖ∑ (ÁΩëÈ°µÊêúÁ¥¢„ÄÅÂÜÖÂ≠òÁ≠â)
        if enable_tools:
            try:
                bi = get_builtin_tools(
                    req,
                    {
                        "__user__": ud,
                        "__chat_id__": None,
                        "__message_id__": None,
                    },
                    model={
                        "info": {
                            "meta": {
                                "capabilities": {
                                    "web_search": True,
                                    "image_generation": True,
                                }
                            }
                        }
                    },
                )
                if bi:
                    td.update(bi)
            except:
                pass
        return [
            self._convert_openwebui_tool(n, d, __event_call__=__event_call__)
            for n, d in td.items()
        ]

    def _get_user_valves(self, __user__: Optional[dict]) -> "Pipe.UserValves":
        """‰ªé __user__ ‰∏ä‰∏ãÊñá‰∏≠Á®≥ÂÅ•Âú∞ÊèêÂèñ UserValves„ÄÇ"""
        if not __user__:
            return self.UserValves()

        # Â§ÑÁêÜÂàóË°®/ÂÖÉÁªÑÂåÖË£Ö
        user_data = __user__[0] if isinstance(__user__, (list, tuple)) else __user__
        if not isinstance(user_data, dict):
            return self.UserValves()

        raw_valves = user_data.get("valves")
        if isinstance(raw_valves, self.UserValves):
            return raw_valves
        if isinstance(raw_valves, dict):
            try:
                return self.UserValves(**raw_valves)
            except Exception as e:
                logger.warning(f"[Copilot] Ëß£Êûê UserValves Â§±Ë¥•: {e}")
        return self.UserValves()

    def _parse_mcp_servers(self, __event_call__=None) -> Optional[dict]:
        if not self.valves.ENABLE_MCP_SERVER:
            return None
        if self.valves.ENABLE_TOOL_CACHE and self._mcp_server_cache is not None:
            return self._mcp_server_cache
        mcp = {}
        conns = (
            getattr(TOOL_SERVER_CONNECTIONS, "value", [])
            if hasattr(TOOL_SERVER_CONNECTIONS, "value")
            else (
                TOOL_SERVER_CONNECTIONS
                if isinstance(TOOL_SERVER_CONNECTIONS, list)
                else []
            )
        )
        for c in conns:
            if not isinstance(c, dict) or c.get("type") != "mcp":
                continue
            info = c.get("info", {})
            rid = info.get("id") or c.get("id") or f"mcp-{len(mcp)}"
            sid = re.sub(r"[^a-zA-Z0-9-]", "-", str(rid)).lower().strip("-")
            url = c.get("url")
            if not url:
                continue
            mtype = "http"
            if "/sse" in url.lower() or "sse" in str(c.get("config", {})).lower():
                mtype = "sse"
            h = c.get("headers", {})
            at, key = str(c.get("auth_type", "bearer")).lower(), c.get("key", "")
            if key and "Authorization" not in h:
                if at == "bearer":
                    h["Authorization"] = f"Bearer {key}"
                elif at == "basic":
                    h["Authorization"] = (
                        f"Basic {base64.b64encode(key.encode()).decode()}"
                    )
                elif at in ["api_key", "apikey"]:
                    h["X-API-Key"] = key
            ff = c.get("config", {}).get("function_name_filter_list", "")
            allowed = [f.strip() for f in ff.split(",") if f.strip()] if ff else ["*"]
            self._emit_debug_log_sync(
                f"üîå ÂèëÁé∞ MCP ËäÇÁÇπ: {sid} ({mtype.upper()}) | URL: {url}"
            )
            mcp[sid] = {"type": mtype, "url": url, "headers": h, "tools": allowed}
        if self.valves.ENABLE_TOOL_CACHE:
            self._mcp_server_cache = mcp
        return mcp if mcp else None

    async def _emit_debug_log(
        self, message: str, __event_call__=None, debug_enabled: Optional[bool] = None
    ):
        is_debug = (
            debug_enabled
            if debug_enabled is not None
            else getattr(self.valves, "DEBUG", False)
        )
        log_msg = f"[Copilot SDK] {message}"
        if is_debug:
            logger.info(log_msg)
        else:
            logger.debug(log_msg)
        if is_debug and __event_call__:
            try:
                js = f"console.debug('%c[Copilot SDK] ' + {json.dumps(message, ensure_ascii=False)}, 'color: #3b82f6;');"
                await __event_call__({"type": "execute", "data": {"code": js}})
            except:
                pass

    def _emit_debug_log_sync(
        self, message: str, __event_call__=None, debug_enabled: Optional[bool] = None
    ):
        is_debug = (
            debug_enabled
            if debug_enabled is not None
            else getattr(self.valves, "DEBUG", False)
        )
        log_msg = f"[Copilot SDK] {message}"
        if is_debug:
            logger.info(log_msg)
        else:
            logger.debug(log_msg)
        if is_debug and __event_call__:
            try:
                asyncio.get_running_loop().create_task(
                    self._emit_debug_log(message, __event_call__, True)
                )
            except:
                pass

    def _get_provider_name(self, mi: Any) -> str:
        mid = getattr(mi, "id", str(mi)).lower()
        if any(k in mid for k in ["gpt", "codex"]):
            return "OpenAI"
        if "claude" in mid:
            return "Anthropic"
        if "gemini" in mid:
            return "Google"
        p = getattr(mi, "policy", None)
        if p:
            t = str(getattr(p, "terms", "")).lower()
            if "openai" in t:
                return "OpenAI"
            if "anthropic" in t:
                return "Anthropic"
            if "google" in t:
                return "Google"
        return "Unknown"

    def _clean_model_id(self, mid: str) -> str:
        if "." in mid:
            mid = mid.split(".", 1)[-1]
        for p in ["copilot-", "copilot - "]:
            if mid.startswith(p):
                mid = mid[len(p) :]
        return mid

    def _setup_env(self, __event_call__=None, debug_enabled: bool = False):
        if self.__class__._env_setup_done:
            # Âç≥‰ΩøÂ∑≤ÂÆåÊàêÁéØÂ¢ÉÈÖçÁΩÆÔºåÂú®Ë∞ÉËØïÊ®°Âºè‰∏ã‰ªçÂêåÊ≠•‰∏ÄÊ¨° MCP„ÄÇ
            if debug_enabled:
                self._sync_mcp_config(__event_call__, debug_enabled)
            return

        os.environ["COPILOT_AUTO_UPDATE"] = "false"
        cp = os.environ.get("COPILOT_CLI_PATH", "/usr/local/bin/copilot")
        target = self.valves.COPILOT_CLI_VERSION.strip()

        # ËÆ∞ÂΩïÊ£ÄÊü•Êó∂Èó¥
        from datetime import datetime

        self.__class__._last_update_check = datetime.now().timestamp()

        def gv(p):
            try:
                return re.search(
                    r"(\d+\.\d+\.\d+)",
                    subprocess.check_output(
                        [p, "--version"], stderr=subprocess.STDOUT
                    ).decode(),
                ).group(1)
            except:
                return None

        cv = gv(cp)
        if not cv:
            cp = shutil.which("copilot") or os.path.join(
                os.path.dirname(__file__), "bin", "copilot"
            )
        cv = gv(cp)
        if not cv or (target and target.lstrip("v") > (cv or "")):
            self._emit_debug_log_sync(
                f"Ê≠£Âú®Êõ¥Êñ∞ Copilot CLI Ëá≥ {target}...", __event_call__, debug_enabled
            )
            try:
                ev = os.environ.copy()
                if target:
                    ev["VERSION"] = target
                subprocess.run(
                    "curl -fsSL https://gh.io/copilot-install | bash",
                    shell=True,
                    check=True,
                    env=ev,
                )
                cp, cv = "/usr/local/bin/copilot", gv("/usr/local/bin/copilot")
            except:
                pass
        os.environ["COPILOT_CLI_PATH"] = cp
        self.__class__._env_setup_done = True
        self._sync_mcp_config(__event_call__, debug_enabled)

    def _sync_mcp_config(self, __event_call__=None, debug_enabled: bool = False):
        if not self.valves.ENABLE_MCP_SERVER:
            return
        mcp = self._parse_mcp_servers(__event_call__)
        if not mcp:
            return
        try:
            path = os.path.expanduser("~/.copilot/config.json")
            os.makedirs(os.path.dirname(path), exist_ok=True)
            data = {}
            if os.path.exists(path):
                try:
                    with open(path, "r") as f:
                        data = json.load(f)
                except:
                    pass
            if json.dumps(data.get("mcp_servers"), sort_keys=True) != json.dumps(
                mcp, sort_keys=True
            ):
                data["mcp_servers"] = mcp
                with open(path, "w") as f:
                    json.dump(data, f, indent=4)
                self._emit_debug_log_sync(
                    f"Â∑≤Â∞Ü {len(mcp)} ‰∏™ MCP ËäÇÁÇπÂêåÊ≠•Ëá≥ÈÖçÁΩÆÊñá‰ª∂",
                    __event_call__,
                    debug_enabled,
                )
        except:
            pass

    def _get_workspace_dir(self, user_id: str = None, chat_id: str = None) -> str:
        """Ëé∑ÂèñÂÖ∑ÊúâÁî®Êà∑ÂíåËÅäÂ§©ÈöîÁ¶ªÁöÑÊúâÊïàÂ∑•‰ΩúÂå∫ÁõÆÂΩï"""
        d = self.valves.WORKSPACE_DIR
        base_cwd = (
            d
            if d
            else (
                "/app/backend/data/copilot_workspace"
                if os.path.exists("/app/backend/data")
                else os.path.join(os.getcwd(), "copilot_workspace")
            )
        )

        cwd = base_cwd
        if user_id:
            safe_user_id = re.sub(r"[^a-zA-Z0-9_-]", "_", str(user_id))
            cwd = os.path.join(cwd, safe_user_id)
        if chat_id:
            safe_chat_id = re.sub(r"[^a-zA-Z0-9_-]", "_", str(chat_id))
            cwd = os.path.join(cwd, safe_chat_id)

        try:
            os.makedirs(cwd, exist_ok=True)
            return cwd
        except Exception as e:
            return base_cwd

    def _process_images(
        self, messages, __event_call__=None, debug_enabled: bool = False
    ):
        if not messages:
            return "", []
        last = messages[-1].get("content", "")
        if not isinstance(last, list):
            return str(last), []
        text, att = "", []
        for item in last:
            if item.get("type") == "text":
                text += item.get("text", "")
            elif item.get("type") == "image_url":
                url = item.get("image_url", {}).get("url", "")
                if url.startswith("data:image"):
                    try:
                        h, e = url.split(",", 1)
                        ext = h.split(";")[0].split("/")[-1]
                        path = os.path.join(self.temp_dir, f"img_{len(att)}.{ext}")
                        with open(path, "wb") as f:
                            f.write(base64.b64decode(e))
                        att.append(
                            {
                                "type": "file",
                                "path": path,
                                "display_name": f"img_{len(att)}",
                            }
                        )
                    except:
                        pass
        return text, att

    async def _fetch_byok_models(self, uv: "Pipe.UserValves" = None) -> List[dict]:
        """‰ªéÈÖçÁΩÆÁöÑÊèê‰æõÂïÜËé∑Âèñ BYOK Ê®°Âûã„ÄÇ"""
        model_list = []

        # Á°ÆÂÆöÊúâÊïàÈÖçÁΩÆ (Áî®Êà∑ > ÂÖ®Â±Ä)
        effective_base_url = (
            uv.BYOK_BASE_URL if uv else ""
        ) or self.valves.BYOK_BASE_URL
        effective_type = (uv.BYOK_TYPE if uv else "") or self.valves.BYOK_TYPE
        effective_api_key = (uv.BYOK_API_KEY if uv else "") or self.valves.BYOK_API_KEY
        effective_bearer_token = (
            uv.BYOK_BEARER_TOKEN if uv else ""
        ) or self.valves.BYOK_BEARER_TOKEN
        effective_models = (uv.BYOK_MODELS if uv else "") or self.valves.BYOK_MODELS

        if effective_base_url:
            try:
                base_url = effective_base_url.rstrip("/")
                url = f"{base_url}/models"
                headers = {}
                provider_type = effective_type.lower()

                if provider_type == "anthropic":
                    if effective_api_key:
                        headers["x-api-key"] = effective_api_key
                    headers["anthropic-version"] = "2023-06-01"
                else:
                    if effective_bearer_token:
                        headers["Authorization"] = f"Bearer {effective_bearer_token}"
                    elif effective_api_key:
                        headers["Authorization"] = f"Bearer {effective_api_key}"

                timeout = aiohttp.ClientTimeout(total=60)
                async with aiohttp.ClientSession(timeout=timeout) as session:
                    for attempt in range(3):
                        try:
                            async with session.get(url, headers=headers) as resp:
                                if resp.status == 200:
                                    data = await resp.json()
                                    if (
                                        isinstance(data, dict)
                                        and "data" in data
                                        and isinstance(data["data"], list)
                                    ):
                                        for item in data["data"]:
                                            if isinstance(item, dict) and "id" in item:
                                                model_list.append(item["id"])
                                    elif isinstance(data, list):
                                        for item in data:
                                            if isinstance(item, dict) and "id" in item:
                                                model_list.append(item["id"])

                                    await self._emit_debug_log(
                                        f"BYOK: ‰ªé {url} Ëé∑Âèñ‰∫Ü {len(model_list)} ‰∏™Ê®°Âûã"
                                    )
                                    break
                                else:
                                    await self._emit_debug_log(
                                        f"BYOK: Ëé∑ÂèñÊ®°ÂûãÂ§±Ë¥• {url} (Â∞ùËØï {attempt+1}/3). Áä∂ÊÄÅÁ†Å: {resp.status}"
                                    )
                        except Exception as e:
                            await self._emit_debug_log(
                                f"BYOK: Ê®°ÂûãËé∑ÂèñÈîôËØØ (Â∞ùËØï {attempt+1}/3): {e}"
                            )

                        if attempt < 2:
                            await asyncio.sleep(1)

            except Exception as e:
                await self._emit_debug_log(f"BYOK: ËÆæÁΩÆÈîôËØØ: {e}")

        # Â¶ÇÊûúËá™Âä®Ëé∑ÂèñÂ§±Ë¥•ÔºåÂõûÈÄÄÂà∞ÊâãÂä®ÈÖçÁΩÆÂàóË°®
        if not model_list:
            if effective_models.strip():
                model_list = [
                    m.strip() for m in effective_models.split(",") if m.strip()
                ]
                await self._emit_debug_log(
                    f"BYOK: ‰ΩøÁî®Áî®Êà∑ÊâãÂä®ÈÖçÁΩÆÁöÑ BYOK_MODELS ({len(model_list)} ‰∏™Ê®°Âûã)."
                )

        return [
            {
                "id": m,
                "name": f"-{self._clean_model_id(m)}",
                "source": "byok",
                "provider": effective_type.capitalize(),
                "raw_id": m,
            }
            for m in model_list
        ]

    def _build_session_config(
        self,
        cid,
        rmid,
        tools,
        sysp,
        ist,
        prov=None,
        eff="medium",
        isr=False,
        cthr=None,
        bthr=None,
        ec=None,
        uid=None,
    ):
        from copilot.types import SessionConfig, InfiniteSessionConfig

        inf = (
            InfiniteSessionConfig(
                enabled=True,
                background_compaction_threshold=cthr
                or self.valves.COMPACTION_THRESHOLD,
                buffer_exhaustion_threshold=bthr or self.valves.BUFFER_THRESHOLD,
            )
            if self.valves.INFINITE_SESSION
            else None
        )
        p = {
            "session_id": cid,
            "model": rmid,
            "streaming": ist,
            "tools": tools,
            "system_message": {
                "content": (sysp.strip() + "\n" if sysp else "")
                + FORMATTING_GUIDELINES
                + (
                    f"\n[‰ºöËØù‰∏ä‰∏ãÊñá]\n"
                    f"- **ÊÇ®ÁöÑÈöîÁ¶ªÂ∑•‰ΩúÂå∫**: `{self._get_workspace_dir(uid, cid)}`\n"
                    f"- **Ê¥ªË∑É‰ºöËØù ID**: `{cid}`\n"
                    "**ÂÖ≥ÈîÆÊåá‰ª§**: ÊâÄÊúâÊñá‰ª∂Êìç‰ΩúÂøÖÈ°ªÂú®Ëøô‰∏™‰∏äËø∞Â∑•‰ΩúÂå∫ËøõË°å„ÄÇ\n"
                    "- **‰∏çË¶Å**Âú® `/tmp` ÊàñÂÖ∂‰ªñÁ≥ªÁªüÁõÆÂΩïÂàõÂª∫Êñá‰ª∂„ÄÇ\n"
                    "- ÂßãÁªàÂ∞Ü‚ÄúÂΩìÂâçÁõÆÂΩï‚ÄùÁêÜËß£‰∏∫ÊÇ®ÁöÑÈöîÁ¶ªÂ∑•‰ΩúÂå∫„ÄÇ"
                ),
                "mode": "replace",
            },
            "infinite_sessions": inf,
            "working_directory": self._get_workspace_dir(uid, cid),
        }
        if isr and eff:
            m = next((x for x in self._model_cache if x.get("raw_id") == rmid), None)
            supp = (
                m.get("meta", {})
                .get("capabilities", {})
                .get("supported_reasoning_efforts", [])
                if m
                else []
            )
            p["reasoning_effort"] = (
                (eff if eff in supp else ("high" if "high" in supp else "medium"))
                if supp
                else eff
            )
        if self.valves.ENABLE_MCP_SERVER:
            mcp = self._parse_mcp_servers(ec)
            if mcp:
                p["mcp_servers"], p["available_tools"] = mcp, None
        else:
            p["available_tools"] = [t.name for t in tools] if tools else None
        if prov:
            p["provider"] = prov

        # Ê≥®ÂÖ•Ëá™Âä®Â§ßÊñá‰ª∂Â§ÑÁêÜÈí©Â≠ê
        wd = p.get("working_directory", "")
        p["hooks"] = self._build_session_hooks(cwd=wd, __event_call__=ec)

        return SessionConfig(**p)

    def _build_session_hooks(self, cwd: str, __event_call__=None):
        """
        ÊûÑÂª∫‰ºöËØùÁîüÂëΩÂë®ÊúüÈí©Â≠ê„ÄÇ
        ÂΩìÂâçÂÆûÁé∞Ôºö
        - on_post_tool_use: Ëá™Âä®Â∞Ü /tmp ‰∏≠ÁöÑÂ§ßÊñá‰ª∂Â§çÂà∂Âà∞Â∑•‰ΩúÂå∫
        """

        async def on_post_tool_use(input_data, invocation):
            result = input_data.get("result", "")

            # Ê£ÄÊµãÂπ∂ÁßªÂä® /tmp ‰∏≠‰øùÂ≠òÁöÑÂ§ßÊñá‰ª∂
            # Ê®°Âºè: Saved to: /tmp/copilot_result_xxxx.txt
            import re
            import shutil

            # ÊêúÁ¥¢ËæìÂá∫‰∏≠ÊΩúÂú®ÁöÑ /tmp Êñá‰ª∂Ë∑ØÂæÑ
            # Â∏∏ËßÅ CLI Ê®°Âºè: "Saved to: /tmp/..." Êàñ‰ªÖ "/tmp/..."
            match = re.search(r"(/tmp/[\w\-\.]+)", str(result))
            if match:
                tmp_path = match.group(1)
                if os.path.exists(tmp_path):
                    try:
                        filename = os.path.basename(tmp_path)
                        target_path = os.path.join(cwd, f"auto_output_{filename}")
                        shutil.copy2(tmp_path, target_path)

                        self._emit_debug_log_sync(
                            f"Hook [on_post_tool_use]: Ëá™Âä®Â∞ÜÂ§ßÊñá‰ª∂ËæìÂá∫‰ªé {tmp_path} ÁßªÂä®Âà∞ {target_path}",
                            __event_call__,
                        )

                        return {
                            "additionalContext": (
                                f"\n[Á≥ªÁªüËá™Âä®ÁÆ°ÁêÜ] ËæìÂá∫ÂÜÖÂÆπËøáÂ§ßÔºåÊúÄÂàù‰øùÂ≠òÂú® {tmp_path}„ÄÇ\n"
                                f"ÊàëÂ∑≤ÁªèËá™Âä®Â∞ÜÂÖ∂ÁßªÂä®Âà∞ÊÇ®ÁöÑÂ∑•‰ΩúÂå∫ÔºåÊñá‰ª∂Âêç‰∏∫: `{os.path.basename(target_path)}`„ÄÇ\n"
                                f"ÊÇ®Áé∞Âú®Â∫îËØ•ÂØπËØ•Êñá‰ª∂‰ΩøÁî® `read_file` Êàñ `grep` Êù•ËÆøÈóÆÂÜÖÂÆπ„ÄÇ"
                            )
                        }
                    except Exception as e:
                        self._emit_debug_log_sync(
                            f"Hook [on_post_tool_use] ÁßªÂä®Êñá‰ª∂ÈîôËØØ: {e}",
                            __event_call__,
                        )

            return {}

        return {
            "on_post_tool_use": on_post_tool_use,
        }

    async def _pipe_impl(
        self,
        body,
        __metadata__=None,
        __user__=None,
        __event_emitter__=None,
        __event_call__=None,
        __request__=None,
    ) -> Union[str, AsyncGenerator]:
        ud = __user__[0] if isinstance(__user__, (list, tuple)) else (__user__ or {})
        uid = ud.get("id") or ud.get("user_id") or "default_user"
        uv = self.UserValves(**(__user__.get("valves", {}) if __user__ else {}))
        debug = self.valves.DEBUG or uv.DEBUG
        self._setup_env(__event_call__, debug)
        byok_active = bool(
            self.valves.BYOK_BASE_URL
            and (
                uv.BYOK_API_KEY
                or self.valves.BYOK_API_KEY
                or self.valves.BYOK_BEARER_TOKEN
            )
        )
        if not self.valves.GH_TOKEN and not byok_active:
            return "Error: ÈÖçÁΩÆÁº∫Â§±„ÄÇ"
        rid = (
            __metadata__.get("base_model_id")
            if __metadata__ and __metadata__.get("base_model_id")
            else body.get("model", "")
        )
        rmid = self._clean_model_id(rid)
        mi = next(
            (x for x in (self._model_cache or []) if x.get("raw_id") == rmid), None
        )
        isr = (
            mi.get("meta", {}).get("capabilities", {}).get("reasoning", False)
            if mi
            else any(k in rmid.lower() for k in ["gpt", "codex"])
        )
        isb = (
            mi.get("source") == "byok"
            if mi
            else (
                not bool(re.search(r"[\(Ôºà]\d+(?:\.\d+)?x[\)Ôºâ]", rid)) and byok_active
            )
        )
        cid = str(
            (__metadata__ or {}).get("chat_id")
            or body.get("chat_id")
            or body.get("metadata", {}).get("chat_id", "")
        ).strip()
        sysp, _ = await self._extract_system_prompt(
            body,
            body.get("messages", []),
            body.get("model", ""),
            rmid,
            __event_call__,
            debug,
        )
        text, att = self._process_images(
            body.get("messages", []), __event_call__, debug
        )
        client = CopilotClient(self._build_client_config(body, uid, cid))
        try:
            await client.start()
            # ÂêåÊ≠•Êõ¥Êñ∞Â∑•ÂÖ∑ÂàùÂßãÂåñÂèÇÊï∞
            tools = await self._initialize_custom_tools(
                body=body,
                __user__=__user__,
                __event_call__=__event_call__,
                __request__=__request__,
                __metadata__=__metadata__,
            )
            prov = (
                {
                    "type": (uv.BYOK_TYPE or self.valves.BYOK_TYPE).lower() or "openai",
                    "wire_api": (uv.BYOK_WIRE_API or self.valves.BYOK_WIRE_API),
                    "base_url": uv.BYOK_BASE_URL or self.valves.BYOK_BASE_URL,
                }
                if isb
                else None
            )
            if prov:
                if uv.BYOK_API_KEY or self.valves.BYOK_API_KEY:
                    prov["api_key"] = uv.BYOK_API_KEY or self.valves.BYOK_API_KEY
                if self.valves.BYOK_BEARER_TOKEN:
                    prov["bearer_token"] = self.valves.BYOK_BEARER_TOKEN
            session = None
            if cid:
                try:
                    rp = {
                        "model": rmid,
                        "streaming": body.get("stream", False),
                        "tools": tools,
                        "system_message": {
                            "mode": "replace",
                            "content": (sysp.strip() + "\n" if sysp else "")
                            + FORMATTING_GUIDELINES,
                        },
                    }
                    if self.valves.ENABLE_MCP_SERVER:
                        mcp = self._parse_mcp_servers(__event_call__)
                        if mcp:
                            rp["mcp_servers"], rp["available_tools"] = mcp, None
                    else:
                        rp["available_tools"] = (
                            [t.name for t in tools] if tools else None
                        )
                    if isr:
                        eff = uv.REASONING_EFFORT or self.valves.REASONING_EFFORT
                        supp = (
                            mi.get("meta", {})
                            .get("capabilities", {})
                            .get("supported_reasoning_efforts", [])
                            if mi
                            else []
                        )
                        rp["reasoning_effort"] = (
                            (
                                eff
                                if eff in supp
                                else ("high" if "high" in supp else "medium")
                            )
                            if supp
                            else eff
                        )
                    if prov:
                        rp["provider"] = prov
                    session = await client.resume_session(cid, rp)
                except:
                    pass
            if not session:
                session = await client.create_session(
                    config=self._build_session_config(
                        cid,
                        rmid,
                        tools,
                        sysp,
                        body.get("stream", False),
                        prov,
                        uv.REASONING_EFFORT or self.valves.REASONING_EFFORT,
                        isr,
                        uv.COMPACTION_THRESHOLD,
                        uv.BUFFER_THRESHOLD,
                        __event_call__,
                        uid,
                    )
                )
            if body.get("stream", False):
                return self.stream_response(
                    client,
                    session,
                    {"prompt": text, "mode": "immediate", "attachments": att},
                    "",
                    __event_call__,
                    uv.REASONING_EFFORT or self.valves.REASONING_EFFORT,
                    uv.SHOW_THINKING,
                    debug,
                )
            else:
                r = await session.send_and_wait(
                    {"prompt": text, "mode": "immediate", "attachments": att}
                )
                return r.data.content if r else "Á©∫ÂìçÂ∫î„ÄÇ"
        except Exception as e:
            return f"ÈîôËØØ: {e}"
        finally:
            if not body.get("stream"):
                await client.stop()

    async def pipes(self, __user__: Optional[dict] = None) -> List[dict]:
        # Ëé∑ÂèñÁî®Êà∑ÈÖçÁΩÆ
        uv = self._get_user_valves(__user__)
        token = uv.GH_TOKEN or self.valves.GH_TOKEN

        # ÁéØÂ¢ÉÂàùÂßãÂåñ (Â∏¶Êúâ 24 Â∞èÊó∂ÂÜ∑Âç¥Êó∂Èó¥)
        from datetime import datetime

        now = datetime.now().timestamp()
        if not self.__class__._env_setup_done or (
            now - self.__class__._last_update_check > 86400
        ):
            self._setup_env(debug_enabled=uv.DEBUG or self.valves.DEBUG, token=token)
        elif token:
            os.environ["GH_TOKEN"] = os.environ["GITHUB_TOKEN"] = token

        # Á°ÆÂÆöÂÄçÁéáÈôêÂà∂
        eff_max = self.valves.MAX_MULTIPLIER
        if uv.MAX_MULTIPLIER is not None:
            eff_max = uv.MAX_MULTIPLIER

        # Á°ÆÂÆöÂÖ≥ÈîÆËØçÂíåÊèê‰æõÂïÜËøáÊª§
        ex_kw = [
            k.strip().lower()
            for k in (self.valves.EXCLUDE_KEYWORDS + "," + uv.EXCLUDE_KEYWORDS).split(
                ","
            )
            if k.strip()
        ]
        allowed_p = [
            p.strip().lower()
            for p in (uv.PROVIDERS if uv.PROVIDERS else self.valves.PROVIDERS).split(
                ","
            )
            if p.strip()
        ]

        # --- Êñ∞Â¢ûÔºöÈÖçÁΩÆÊÑüÁü•ÁºìÂ≠òÂà∑Êñ∞ ---
        # ËÆ°ÁÆóÂΩìÂâçÈÖçÁΩÆÊåáÁ∫π‰ª•Ê£ÄÊµãÂèòÂåñ
        current_config_str = f"{token}|{(uv.BYOK_BASE_URL if uv else '') or self.valves.BYOK_BASE_URL}|{(uv.BYOK_API_KEY if uv else '') or self.valves.BYOK_API_KEY}|{(uv.BYOK_BEARER_TOKEN if uv else '') or self.valves.BYOK_BEARER_TOKEN}"
        import hashlib

        current_config_hash = hashlib.md5(current_config_str.encode()).hexdigest()

        if (
            self._model_cache
            and self.__class__._last_byok_config_hash != current_config_hash
        ):
            self.__class__._model_cache = []
            self.__class__._last_byok_config_hash = current_config_hash

        # Â¶ÇÊûúÁºìÂ≠ò‰∏∫Á©∫ÔºåÂà∑Êñ∞Ê®°ÂûãÂàóË°®
        if not self._model_cache:
            self.__class__._last_byok_config_hash = current_config_hash
            byok_models = []
            standard_models = []

            # 1. Ëé∑Âèñ BYOK Ê®°Âûã (‰ºòÂÖà‰ΩøÁî®‰∏™‰∫∫ËÆæÁΩÆ)
            if ((uv.BYOK_BASE_URL if uv else "") or self.valves.BYOK_BASE_URL) and (
                (uv.BYOK_API_KEY if uv else "")
                or self.valves.BYOK_API_KEY
                or (uv.BYOK_BEARER_TOKEN if uv else "")
                or self.valves.BYOK_BEARER_TOKEN
            ):
                byok_models = await self._fetch_byok_models(uv=uv)

            # 2. Ëé∑ÂèñÊ†áÂáÜ Copilot Ê®°Âûã
            if token:
                c = await self._get_client()
                try:
                    raw_models = await c.list_models()
                    raw = raw_models if isinstance(raw_models, list) else []
                    processed = []

                    for m in raw:
                        try:
                            m_is_dict = isinstance(m, dict)
                            mid = m.get("id") if m_is_dict else getattr(m, "id", str(m))
                            bill = (
                                m.get("billing")
                                if m_is_dict
                                else getattr(m, "billing", None)
                            )
                            if bill and not isinstance(bill, dict):
                                bill = (
                                    bill.to_dict()
                                    if hasattr(bill, "to_dict")
                                    else vars(bill)
                                )

                            pol = (
                                m.get("policy")
                                if m_is_dict
                                else getattr(m, "policy", None)
                            )
                            if pol and not isinstance(pol, dict):
                                pol = (
                                    pol.to_dict()
                                    if hasattr(pol, "to_dict")
                                    else vars(pol)
                                )

                            if (pol or {}).get("state") == "disabled":
                                continue

                            cap = (
                                m.get("capabilities")
                                if m_is_dict
                                else getattr(m, "capabilities", None)
                            )
                            vis, reas, ctx, supp = False, False, None, []
                            if cap:
                                if not isinstance(cap, dict):
                                    cap = (
                                        cap.to_dict()
                                        if hasattr(cap, "to_dict")
                                        else vars(cap)
                                    )
                                s = cap.get("supports", {})
                                vis, reas = s.get("vision", False), s.get(
                                    "reasoning_effort", False
                                )
                                l = cap.get("limits", {})
                                ctx = l.get("max_context_window_tokens")

                            raw_eff = (
                                m.get("supported_reasoning_efforts")
                                if m_is_dict
                                else getattr(m, "supported_reasoning_efforts", [])
                            ) or []
                            supp = [str(e).lower() for e in raw_eff if e]
                            mult = (bill or {}).get("multiplier", 1)
                            cid = self._clean_model_id(mid)
                            processed.append(
                                {
                                    "id": f"{self.id}-{mid}",
                                    "name": (
                                        f"-{cid} ({mult}x)"
                                        if mult > 0
                                        else f"-üî• {cid} (0x)"
                                    ),
                                    "multiplier": mult,
                                    "raw_id": mid,
                                    "source": "copilot",
                                    "provider": self._get_provider_name(m),
                                    "meta": {
                                        "capabilities": {
                                            "vision": vis,
                                            "reasoning": reas,
                                            "supported_reasoning_efforts": supp,
                                        },
                                        "context_length": ctx,
                                    },
                                }
                            )
                        except:
                            continue

                    processed.sort(key=lambda x: (x["multiplier"], x["raw_id"]))
                    standard_models = processed
                    self._standard_model_ids = {m["raw_id"] for m in processed}
                except:
                    pass
                finally:
                    await c.stop()

            self._model_cache = standard_models + byok_models

        if not self._model_cache:
            return [
                {"id": "error", "name": "Êú™ÊâæÂà∞‰ªª‰ΩïÊ®°Âûã„ÄÇËØ∑Ê£ÄÊü• Token Êàñ BYOK ÈÖçÁΩÆ„ÄÇ"}
            ]

        # 3. ÂÆûÊó∂ËøáÊª§ÁªìÊûú
        res = []
        for m in self._model_cache:
            # Êèê‰æõÂïÜËøáÊª§
            if allowed_p and m.get("provider", "Unknown").lower() not in allowed_p:
                continue

            mid, mname = (m.get("raw_id") or m.get("id", "")).lower(), m.get(
                "name", ""
            ).lower()
            # ÂÖ≥ÈîÆËØçËøáÊª§
            if any(kw in mid or kw in mname for kw in ex_kw):
                continue

            # ÂÄçÁéáÈôêÂà∂ (‰ªÖÈôê Copilot ÂÆòÊñπÊ®°Âûã)
            if m.get("source") == "copilot":
                if float(m.get("multiplier", 1)) > (float(eff_max) + 0.0001):
                    continue

            res.append(m)

        return res if res else [{"id": "none", "name": "Ê≤°ÊúâÂåπÈÖçÂΩìÂâçËøáÊª§Êù°‰ª∂ÁöÑÊ®°Âûã"}]

    async def stream_response(
        self,
        client,
        session,
        payload,
        init_msg,
        __event_call__,
        effort="",
        show_thinking=True,
        debug=False,
    ) -> AsyncGenerator:
        queue, done, sentinel = asyncio.Queue(), asyncio.Event(), object()
        state = {"thinking_started": False, "content_sent": False}
        has_content = False

        def handler(event):
            etype = (
                event.type.value if hasattr(event.type, "value") else str(event.type)
            )

            def get_attr(a):
                if not hasattr(event, "data") or event.data is None:
                    return None
                return (
                    event.data.get(a)
                    if isinstance(event.data, dict)
                    else getattr(event.data, a, None)
                )

            if etype == "assistant.message_delta":
                delta = (
                    get_attr("delta_content")
                    or get_attr("deltaContent")
                    or get_attr("content")
                )
                if delta:
                    state["content_sent"] = True
                    if state["thinking_started"]:
                        queue.put_nowait("\n</think>\n")
                        state["thinking_started"] = False
                    queue.put_nowait(delta)
            elif etype == "assistant.reasoning_delta":
                delta = (
                    get_attr("reasoning_text")
                    or get_attr("reasoningText")
                    or get_attr("delta_content")
                )
                if delta and not state["content_sent"] and show_thinking:
                    if not state["thinking_started"]:
                        queue.put_nowait("<think>\n")
                        state["thinking_started"] = True
                    queue.put_nowait(delta)
            elif etype == "assistant.usage":
                queue.put_nowait(
                    {
                        "choices": [{"delta": {}, "finish_reason": "stop", "index": 0}],
                        "usage": {
                            "prompt_tokens": get_attr("input_tokens") or 0,
                            "completion_tokens": get_attr("output_tokens") or 0,
                            "total_tokens": get_attr("total_tokens") or 0,
                        },
                    }
                )
            elif etype == "session.idle":
                done.set()
                queue.put_nowait(sentinel)
            elif etype == "session.error":
                queue.put_nowait(f"\n[ÈîôËØØ: {get_attr('message')}]")
                done.set()
                queue.put_nowait(sentinel)

        unsubscribe = session.on(handler)
        asyncio.create_task(session.send(payload))
        try:
            while not done.is_set() or not queue.empty():
                try:
                    chunk = await asyncio.wait_for(
                        queue.get(), timeout=float(self.valves.TIMEOUT)
                    )
                    if chunk is sentinel:
                        break
                    if chunk:
                        has_content = True
                        yield chunk
                except asyncio.TimeoutError:
                    if done.is_set():
                        break
                    continue
            if state["thinking_started"]:
                yield "\n</think>\n"
            if not has_content:
                yield "‚ö†Ô∏è Êú™ËøîÂõûÂÜÖÂÆπ„ÄÇ"
        except Exception as e:
            yield f"\n[ÊµÅÈîôËØØ: {e}]"
        finally:
            unsubscribe()
            await client.stop()

    async def _extract_system_prompt(
        self,
        body,
        messages,
        request_model,
        real_model_id,
        __event_call__=None,
        debug_enabled=False,
    ):
        sysp, src = None, ""
        if body.get("system_prompt"):
            sysp, src = body.get("system_prompt"), "body_explicit"
        if not sysp:
            meta = body.get("metadata", {}).get("model", {}).get("params", {})
            if meta.get("system"):
                sysp, src = meta.get("system"), "metadata_params"
        if not sysp:
            try:
                from open_webui.models.models import Models

                for mid in [request_model, real_model_id]:
                    m_rec = Models.get_model_by_id(mid)
                    if (
                        m_rec
                        and hasattr(m_rec, "params")
                        and isinstance(m_rec.params, dict)
                        and m_rec.params.get("system")
                    ):
                        sysp, src = m_rec.params.get("system"), f"Ê®°ÂûãÂ∫ì:{mid}"
                        break
            except:
                pass
        if not sysp:
            for msg in messages:
                if msg.get("role") == "system":
                    sysp, src = msg.get("content", ""), "Ê∂àÊÅØÂéÜÂè≤"
                    break
        if sysp:
            await self._emit_debug_log(
                f"Á≥ªÁªüÊèêÁ§∫ËØçÊù•Ê∫ê: {src} ({len(sysp)} Â≠óÁ¨¶)",
                __event_call__,
                debug_enabled,
            )
        return sysp, src

    def _build_client_config(self, body, user_id=None, chat_id=None):
        c = {
            "cli_path": os.environ.get("COPILOT_CLI_PATH"),
            "cwd": self._get_workspace_dir(user_id, chat_id),
        }
        if self.valves.LOG_LEVEL:
            c["log_level"] = self.valves.LOG_LEVEL
        if self.valves.CUSTOM_ENV_VARS:
            try:
                e = json.loads(self.valves.CUSTOM_ENV_VARS)
                c.update({"env": e}) if isinstance(e, dict) else None
            except:
                pass
        return c
