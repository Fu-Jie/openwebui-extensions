"""
title: GitHub Copilot Official SDK Pipe
author: Fu-Jie
author_url: https://github.com/Fu-Jie/awesome-openwebui
funding_url: https://github.com/open-webui
description: é›†æˆ GitHub Copilot SDKã€‚æ”¯æŒåŠ¨æ€æ¨¡å‹ã€å¤šè½®å¯¹è¯ã€æµå¼è¾“å‡ºã€å¤šæ¨¡æ€è¾“å…¥ã€æ— é™ä¼šè¯åŠå‰ç«¯è°ƒè¯•æ—¥å¿—ã€‚
version: 0.3.0
requirements: github-copilot-sdk==0.1.22
"""

import os
import re
import time
import json
import base64
import tempfile
import asyncio
import logging
import shutil
import subprocess
import sys
import hashlib
from pathlib import Path
from typing import Optional, Union, AsyncGenerator, List, Any, Dict, Callable
from types import SimpleNamespace
from pydantic import BaseModel, Field, create_model
from datetime import datetime, timezone
import contextlib

# å¯¼å…¥ Copilot SDK æ¨¡å—
from copilot import CopilotClient, define_tool

# å¯¼å…¥ OpenWebUI é…ç½®å’Œå·¥å…·æ¨¡å—
from open_webui.config import TOOL_SERVER_CONNECTIONS
from open_webui.utils.tools import get_tools as get_openwebui_tools
from open_webui.models.tools import Tools
from open_webui.models.users import Users

# Setup logger
logger = logging.getLogger(__name__)


class Pipe:
    class Valves(BaseModel):
        GH_TOKEN: str = Field(
            default="",
            description="GitHub OAuth Token (æ¥è‡ª 'gh auth token')ï¼Œç”¨äº Copilot Chat (å¿…é¡»)",
        )
        COPILOT_CLI_VERSION: str = Field(
            default="0.0.405",
            description="æŒ‡å®šå®‰è£…/å¼ºåˆ¶ä½¿ç”¨çš„ Copilot CLI ç‰ˆæœ¬ (ä¾‹å¦‚ '0.0.405')ã€‚ç•™ç©ºåˆ™ä½¿ç”¨æœ€æ–°ç‰ˆã€‚",
        )
        DEBUG: bool = Field(
            default=False,
            description="å¯ç”¨æŠ€æœ¯è°ƒè¯•æ—¥å¿—ï¼ˆè¿æ¥ä¿¡æ¯ç­‰ï¼‰",
        )
        LOG_LEVEL: str = Field(
            default="error",
            description="Copilot CLI æ—¥å¿—çº§åˆ«ï¼šnone, error, warning, info, debug, all",
        )
        SHOW_THINKING: bool = Field(
            default=True,
            description="æ˜¾ç¤ºæ¨¡å‹æ¨ç†/æ€è€ƒè¿‡ç¨‹",
        )
        EXCLUDE_KEYWORDS: str = Field(
            default="",
            description="æ’é™¤åŒ…å«è¿™äº›å…³é”®è¯çš„æ¨¡å‹ï¼ˆé€—å·åˆ†éš”ï¼Œå¦‚ï¼šcodex, haikuï¼‰",
        )
        WORKSPACE_DIR: str = Field(
            default="",
            description="æ–‡ä»¶æ“ä½œçš„å—é™å·¥ä½œåŒºç›®å½•ï¼›ä¸ºç©ºåˆ™ä½¿ç”¨å½“å‰è¿›ç¨‹ç›®å½•",
        )
        INFINITE_SESSION: bool = Field(
            default=True,
            description="å¯ç”¨æ— é™ä¼šè¯ï¼ˆè‡ªåŠ¨ä¸Šä¸‹æ–‡å‹ç¼©ï¼‰",
        )
        COMPACTION_THRESHOLD: float = Field(
            default=0.8,
            description="åå°å‹ç¼©é˜ˆå€¼ (0.0-1.0)",
        )
        BUFFER_THRESHOLD: float = Field(
            default=0.95,
            description="ç¼“å†²åŒºè€—å°½é˜ˆå€¼ (0.0-1.0)",
        )
        TIMEOUT: int = Field(
            default=300,
            description="æ¯ä¸ªæµå¼åˆ†å—è¶…æ—¶ï¼ˆç§’ï¼‰",
        )
        CUSTOM_ENV_VARS: str = Field(
            default="",
            description='è‡ªå®šä¹‰ç¯å¢ƒå˜é‡ï¼ˆJSON æ ¼å¼ï¼Œä¾‹å¦‚ {"VAR": "value"}ï¼‰',
        )

        ENABLE_OPENWEBUI_TOOLS: bool = Field(
            default=True,
            description="å¯ç”¨ OpenWebUI å·¥å…· (åŒ…æ‹¬è‡ªå®šä¹‰å·¥å…·å’Œå·¥å…·æœåŠ¡å™¨å·¥å…·)ã€‚",
        )
        ENABLE_MCP_SERVER: bool = Field(
            default=True,
            description="å¯ç”¨ç›´æ¥ MCP å®¢æˆ·ç«¯è¿æ¥ (æ¨è)ã€‚",
        )
        REASONING_EFFORT: str = Field(
            default="medium",
            description="æ¨ç†å¼ºåº¦çº§åˆ«: low, medium, high. (gpt-5.2-codex é¢å¤–æ”¯æŒ xhigh)",
        )
        ENFORCE_FORMATTING: bool = Field(
            default=True,
            description="åœ¨ç³»ç»Ÿæç¤ºè¯ä¸­æ·»åŠ æ ¼å¼åŒ–æŒ‡å¯¼ï¼Œä»¥æé«˜è¾“å‡ºçš„å¯è¯»æ€§ï¼ˆæ®µè½ã€æ¢è¡Œã€ç»“æ„ï¼‰ã€‚",
        )
        ALLOWED_AGENT_MODELS: str = Field(
            default="",
            description="ç”¨äºç”Ÿæˆä»£ç†çš„æ¨¡å‹ç™½åå•ï¼ˆé€—å·åˆ†éš”ï¼‰ã€‚å¦‚æœä¸ºç©ºï¼Œåˆ™ä¸å¼ºåˆ¶æ‰§è¡ŒæœåŠ¡å™¨ç«¯é™åˆ¶ã€‚",
        )
        FALLBACK_AGENT_MODEL: str = Field(
            default="",
            description="å½“è¯·æ±‚çš„æ¨¡å‹ä¸åœ¨ç™½åå•ä¸­æ—¶ä½¿ç”¨çš„å¤‡ç”¨æ¨¡å‹ã€‚å¦‚æœä¸ºç©ºï¼Œåˆ™æ‹’ç»ä¸å…è®¸çš„æ¨¡å‹ã€‚",
        )

    class UserValves(BaseModel):
        GH_TOKEN: str = Field(
            default="",
            description="ä¸ªäºº GitHub Fine-grained Token (è¦†ç›–å…¨å±€è®¾ç½®)",
        )
        REASONING_EFFORT: str = Field(
            default="",
            description="æ¨ç†å¼ºåº¦çº§åˆ« (low, medium, high, xhigh)ã€‚ç•™ç©ºä»¥ä½¿ç”¨å…¨å±€è®¾ç½®ã€‚",
        )
        DEBUG: bool = Field(
            default=False,
            description="å¯ç”¨æŠ€æœ¯è°ƒè¯•æ—¥å¿—ï¼ˆè¿æ¥ä¿¡æ¯ç­‰ï¼‰",
        )
        SHOW_THINKING: bool = Field(
            default=True,
            description="æ˜¾ç¤ºæ¨¡å‹çš„æ¨ç†/æ€è€ƒè¿‡ç¨‹",
        )

        ENABLE_OPENWEBUI_TOOLS: bool = Field(
            default=True,
            description="å¯ç”¨ OpenWebUI å·¥å…· (åŒ…æ‹¬è‡ªå®šä¹‰å·¥å…·å’Œå·¥å…·æœåŠ¡å™¨å·¥å…·ï¼Œè¦†ç›–å…¨å±€è®¾ç½®)ã€‚",
        )
        ENABLE_MCP_SERVER: bool = Field(
            default=True,
            description="å¯ç”¨åŠ¨æ€ MCP æœåŠ¡å™¨åŠ è½½ (è¦†ç›–å…¨å±€è®¾ç½®)ã€‚",
        )

        ENFORCE_FORMATTING: bool = Field(
            default=True,
            description="å¼ºåˆ¶å¯ç”¨æ ¼å¼åŒ–æŒ‡å¯¼ (è¦†ç›–å…¨å±€è®¾ç½®)",
        )

    def __init__(self):
        self.type = "pipe"
        self.id = "copilotsdk"
        self.name = "copilotsdk"
        self.valves = self.Valves()
        self.temp_dir = tempfile.mkdtemp(prefix="copilot_images_")
        self.thinking_started = False
        self._model_cache = []  # æ¨¡å‹åˆ—è¡¨ç¼“å­˜
        self._last_update_check = 0  # ä¸Šæ¬¡ CLI æ›´æ–°æ£€æŸ¥æ—¶é—´

    def __del__(self):
        try:
            shutil.rmtree(self.temp_dir)
        except:
            pass

    # ==================== ç³»ç»Ÿå›ºå®šå…¥å£ ====================
    # pipe() æ˜¯ OpenWebUI è°ƒç”¨çš„ç¨³å®šå…¥å£ã€‚
    # å°†è¯¥éƒ¨åˆ†æ”¾åœ¨å‰é¢ï¼Œä¾¿äºå¿«é€Ÿå®šä½ä¸ç»´æŠ¤ã€‚
    # ======================================================
    async def pipe(
        self,
        body: dict,
        __metadata__: Optional[dict] = None,
        __user__: Optional[dict] = None,
        __event_emitter__=None,
        __event_call__=None,
    ) -> Union[str, AsyncGenerator]:
        return await self._pipe_impl(
            body,
            __metadata__=__metadata__,
            __user__=__user__,
            __event_emitter__=__event_emitter__,
            __event_call__=__event_call__,
        )

    # ==================== åŠŸèƒ½æ€§åˆ†åŒºè¯´æ˜ ====================
    # 1) å·¥å…·æ³¨å†Œï¼šå®šä¹‰å·¥å…·å¹¶åœ¨ _initialize_custom_tools ä¸­æ³¨å†Œ
    # 2) è°ƒè¯•æ—¥å¿—ï¼š_emit_debug_log / _emit_debug_log_sync
    # 3) æç¤ºè¯/ä¼šè¯ï¼š_extract_system_prompt / _build_session_config / _build_prompt
    # 4) è¿è¡Œæµç¨‹ï¼špipe() è´Ÿè´£è¯·æ±‚ï¼Œstream_response() è´Ÿè´£æµå¼è¾“å‡º
    # ======================================================
    # ==================== è‡ªå®šä¹‰å·¥å…·ç¤ºä¾‹ ====================
    # å·¥å…·æ³¨å†Œï¼šåœ¨æ¨¡å—çº§åˆ«æ·»åŠ  @define_tool è£…é¥°çš„å‡½æ•°ï¼Œ
    # ç„¶ååœ¨ _initialize_custom_tools() çš„ all_tools å­—å…¸ä¸­æ³¨å†Œã€‚

    def _extract_text_from_content(self, content) -> str:
        """ä»å„ç§æ¶ˆæ¯å†…å®¹æ ¼å¼ä¸­æå–æ–‡æœ¬å†…å®¹"""
        if isinstance(content, str):
            return content
        elif isinstance(content, list):
            text_parts = []
            for item in content:
                if isinstance(item, dict) and item.get("type") == "text":
                    text_parts.append(item.get("text", ""))
            return " ".join(text_parts)
        return ""

    def _apply_formatting_hint(self, prompt: str) -> str:
        """åœ¨å¯ç”¨æ ¼å¼åŒ–æ—¶ï¼Œå‘ç”¨æˆ·æç¤ºè¯è¿½åŠ è½»é‡æ ¼å¼åŒ–è¦æ±‚ã€‚"""
        if not self.valves.ENFORCE_FORMATTING:
            return prompt

        if not prompt:
            return prompt

        if "[æ ¼å¼åŒ–æŒ‡å—]" in prompt or "[æ ¼å¼åŒ–è¦æ±‚]" in prompt:
            return prompt

        formatting_hint = (
            "\n\n[æ ¼å¼åŒ–è¦æ±‚]\n" "è¯·ä½¿ç”¨æ¸…æ™°çš„æ®µè½ä¸æ¢è¡Œï¼Œå¿…è¦æ—¶ä½¿ç”¨é¡¹ç›®ç¬¦å·åˆ—è¡¨ã€‚"
        )
        return f"{prompt}{formatting_hint}"

    def _dedupe_preserve_order(self, items: List[str]) -> List[str]:
        """å»é‡ä¿åº"""
        seen = set()
        result = []
        for item in items:
            if not item or item in seen:
                continue
            seen.add(item)
            result.append(item)
        return result

    def _collect_model_ids(
        self, body: dict, request_model: str, real_model_id: str
    ) -> List[str]:
        """æ”¶é›†å¯èƒ½çš„æ¨¡å‹ IDï¼ˆæ¥è‡ªè¯·æ±‚/metadata/body paramsï¼‰"""
        model_ids: List[str] = []
        if request_model:
            model_ids.append(request_model)
        if request_model.startswith(f"{self.id}-"):
            model_ids.append(request_model[len(f"{self.id}-") :])
        if real_model_id:
            model_ids.append(real_model_id)

        metadata = body.get("metadata", {})
        if isinstance(metadata, dict):
            meta_model = metadata.get("model")
            meta_model_id = metadata.get("model_id")
            if isinstance(meta_model, str):
                model_ids.append(meta_model)
            if isinstance(meta_model_id, str):
                model_ids.append(meta_model_id)

        body_params = body.get("params", {})
        if isinstance(body_params, dict):
            for key in ("model", "model_id", "modelId"):
                val = body_params.get(key)
                if isinstance(val, str):
                    model_ids.append(val)

        return self._dedupe_preserve_order(model_ids)

    async def _extract_system_prompt(
        self,
        body: dict,
        messages: List[dict],
        request_model: str,
        real_model_id: str,
        __event_call__=None,
    ) -> tuple[Optional[str], str]:
        """ä» metadata/æ¨¡å‹ DB/body/messages æå–ç³»ç»Ÿæç¤ºè¯"""
        system_prompt_content: Optional[str] = None
        system_prompt_source = ""

        # 1) metadata.model.params.system
        metadata = body.get("metadata", {})
        if isinstance(metadata, dict):
            meta_model = metadata.get("model")
            if isinstance(meta_model, dict):
                meta_params = meta_model.get("params")
                if isinstance(meta_params, dict) and meta_params.get("system"):
                    system_prompt_content = meta_params.get("system")
                    system_prompt_source = "metadata.model.params"
                    await self._emit_debug_log(
                        f"ä» metadata.model.params æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                        __event_call__,
                    )

        # 2) æ¨¡å‹ DB
        if not system_prompt_content:
            try:
                from open_webui.models.models import Models

                model_ids_to_try = self._collect_model_ids(
                    body, request_model, real_model_id
                )
                for mid in model_ids_to_try:
                    model_record = Models.get_model_by_id(mid)
                    if model_record and hasattr(model_record, "params"):
                        params = model_record.params
                        if isinstance(params, dict):
                            system_prompt_content = params.get("system")
                            if system_prompt_content:
                                system_prompt_source = f"model_db:{mid}"
                                await self._emit_debug_log(
                                    f"ä»æ¨¡å‹æ•°æ®åº“æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                                    __event_call__,
                                )
                                break
            except Exception as e:
                await self._emit_debug_log(
                    f"ä»æ¨¡å‹æ•°æ®åº“æå–ç³»ç»Ÿæç¤ºè¯å¤±è´¥: {e}",
                    __event_call__,
                )

        # 3) body.params.system
        if not system_prompt_content:
            body_params = body.get("params", {})
            if isinstance(body_params, dict):
                system_prompt_content = body_params.get("system")
                if system_prompt_content:
                    system_prompt_source = "body_params"
                    await self._emit_debug_log(
                        f"ä» body.params æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                        __event_call__,
                    )

        # 4) messages (role=system)
        if not system_prompt_content:
            for msg in messages:
                if msg.get("role") == "system":
                    system_prompt_content = self._extract_text_from_content(
                        msg.get("content", "")
                    )
                    if system_prompt_content:
                        system_prompt_source = "messages_system"
                        await self._emit_debug_log(
                            f"ä»æ¶ˆæ¯ä¸­æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                            __event_call__,
                        )
                    break

        return system_prompt_content, system_prompt_source

    def _get_workspace_dir(self) -> str:
        """è·å–å…·æœ‰æ™ºèƒ½é»˜è®¤å€¼çš„æœ‰æ•ˆå·¥ä½œç©ºé—´ç›®å½•ã€‚"""
        if self.valves.WORKSPACE_DIR:
            return self.valves.WORKSPACE_DIR

        # OpenWebUI å®¹å™¨çš„æ™ºèƒ½é»˜è®¤å€¼
        if os.path.exists("/app/backend/data"):
            cwd = "/app/backend/data/copilot_workspace"
        else:
            # æœ¬åœ°å›é€€ï¼šå½“å‰å·¥ä½œç›®å½•çš„å­ç›®å½•
            cwd = os.path.join(os.getcwd(), "copilot_workspace")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(cwd):
            try:
                os.makedirs(cwd, exist_ok=True)
            except Exception as e:
                print(f"Error creating workspace {cwd}: {e}")
                return os.getcwd()  # å¦‚æœåˆ›å»ºå¤±è´¥å›é€€åˆ° CWD

        return cwd

    def _parse_allowed_models(self) -> list:
        """å°† ALLOWED_AGENT_MODELS é…ç½®è§£æä¸ºæ¨¡å‹ ID åˆ—è¡¨ã€‚"""
        if not self.valves.ALLOWED_AGENT_MODELS:
            return []
        return [
            model.strip()
            for model in self.valves.ALLOWED_AGENT_MODELS.split(",")
            if model.strip()
        ]

    def _sanitize_model(self, requested_model: str) -> str:
        """
        å¼ºåˆ¶æ‰§è¡Œæ¨¡å‹ç™½åå•å’Œå¤‡ç”¨é€»è¾‘ã€‚
        
        è¿”å›éªŒè¯åçš„æˆ–å¤‡ç”¨çš„æ¨¡å‹ IDã€‚
        å¦‚æœæ¨¡å‹ä¸å…è®¸ä¸”æ²¡æœ‰å¯ç”¨çš„å¤‡ç”¨æ¨¡å‹ï¼Œåˆ™å¼•å‘ ValueErrorã€‚
        """
        allowed_models = self._parse_allowed_models()
        
        # å¦‚æœæœªé…ç½®ç™½åå•ï¼Œåˆ™å…è®¸ä»»ä½•æ¨¡å‹ï¼ˆå‘åå…¼å®¹ï¼‰
        if not allowed_models:
            return requested_model
        
        # æ£€æŸ¥è¯·æ±‚çš„æ¨¡å‹æ˜¯å¦åœ¨ç™½åå•ä¸­
        if requested_model in allowed_models:
            return requested_model
        
        # æ¨¡å‹ä¸å…è®¸ - æ£€æŸ¥å¤‡ç”¨æ¨¡å‹
        fallback_model = self.valves.FALLBACK_AGENT_MODEL.strip()
        
        if fallback_model:
            # éªŒè¯å¤‡ç”¨æ¨¡å‹æ˜¯å¦åœ¨ç™½åå•ä¸­
            if fallback_model in allowed_models:
                logger.info(
                    f"æ¨¡å‹ '{requested_model}' ä¸åœ¨ç™½åå•ä¸­ã€‚ä½¿ç”¨å¤‡ç”¨æ¨¡å‹ï¼š{fallback_model}"
                )
                return fallback_model
            else:
                raise ValueError(
                    f"æ¨¡å‹ '{requested_model}' ä¸åœ¨ç™½åå•ä¸­ï¼Œå¤‡ç”¨æ¨¡å‹ '{fallback_model}' ä¹Ÿä¸åœ¨ç™½åå•ä¸­ã€‚"
                )
        else:
            raise ValueError(
                f"æ¨¡å‹ '{requested_model}' ä¸åœ¨å…è®¸çš„æ¨¡å‹åˆ—è¡¨ä¸­ï¼š{', '.join(allowed_models)}"
            )

    def _build_client_config(self, body: dict) -> dict:
        """æ ¹æ® Valves å’Œè¯·æ±‚æ„å»º CopilotClient é…ç½®"""
        cwd = self._get_workspace_dir()
        client_config = {}
        if os.environ.get("COPILOT_CLI_PATH"):
            client_config["cli_path"] = os.environ["COPILOT_CLI_PATH"]
        client_config["cwd"] = cwd

        if self.valves.LOG_LEVEL:
            client_config["log_level"] = self.valves.LOG_LEVEL

        if self.valves.CUSTOM_ENV_VARS:
            try:
                custom_env = json.loads(self.valves.CUSTOM_ENV_VARS)
                if isinstance(custom_env, dict):
                    client_config["env"] = custom_env
            except:
                pass

        return client_config

    async def _initialize_custom_tools(self, __user__=None, __event_call__=None):
        """æ ¹æ®é…ç½®åˆå§‹åŒ–è‡ªå®šä¹‰å·¥å…·"""

        if not self.valves.ENABLE_OPENWEBUI_TOOLS:
            return []

        # åŠ¨æ€åŠ è½½ OpenWebUI å·¥å…·
        openwebui_tools = await self._load_openwebui_tools(
            __user__=__user__, __event_call__=__event_call__
        )

        return openwebui_tools

    def _json_schema_to_python_type(self, schema: dict) -> Any:
        """å°† JSON Schema ç±»å‹è½¬æ¢ä¸º Python ç±»å‹ä»¥ç”¨äº Pydantic æ¨¡å‹ã€‚"""
        if not isinstance(schema, dict):
            return Any

        schema_type = schema.get("type")
        if isinstance(schema_type, list):
            schema_type = next((t for t in schema_type if t != "null"), schema_type[0])

        if schema_type == "string":
            return str
        if schema_type == "integer":
            return int
        if schema_type == "number":
            return float
        if schema_type == "boolean":
            return bool
        if schema_type == "object":
            return Dict[str, Any]
        if schema_type == "array":
            items_schema = schema.get("items", {})
            item_type = self._json_schema_to_python_type(items_schema)
            return List[item_type]

        return Any

    def _convert_openwebui_tool(self, tool_name: str, tool_dict: dict):
        """å°† OpenWebUI å·¥å…·å®šä¹‰è½¬æ¢ä¸º Copilot SDK å·¥å…·ã€‚"""
        # å‡€åŒ–å·¥å…·åç§°ä»¥åŒ¹é…æ¨¡å¼ ^[a-zA-Z0-9_-]+$
        sanitized_tool_name = re.sub(r"[^a-zA-Z0-9_-]", "_", tool_name)

        # å¦‚æœå‡€åŒ–åçš„åç§°ä¸ºç©ºæˆ–ä»…åŒ…å«åˆ†éš”ç¬¦ï¼ˆä¾‹å¦‚çº¯ä¸­æ–‡åç§°ï¼‰ï¼Œç”Ÿæˆå›é€€åç§°
        if not sanitized_tool_name or re.match(r"^[_.-]+$", sanitized_tool_name):
            hash_suffix = hashlib.md5(tool_name.encode("utf-8")).hexdigest()[:8]
            sanitized_tool_name = f"tool_{hash_suffix}"

        if sanitized_tool_name != tool_name:
            logger.debug(f"å°†å·¥å…·åç§° '{tool_name}' å‡€åŒ–ä¸º '{sanitized_tool_name}'")

        spec = tool_dict.get("spec", {}) if isinstance(tool_dict, dict) else {}
        params_schema = spec.get("parameters", {}) if isinstance(spec, dict) else {}
        properties = params_schema.get("properties", {})
        required = params_schema.get("required", [])

        if not isinstance(properties, dict):
            properties = {}
        if not isinstance(required, list):
            required = []

        required_set = set(required)
        fields = {}
        for param_name, param_schema in properties.items():
            param_type = self._json_schema_to_python_type(param_schema)
            description = ""
            if isinstance(param_schema, dict):
                description = param_schema.get("description", "")

            if param_name in required_set:
                if description:
                    fields[param_name] = (
                        param_type,
                        Field(..., description=description),
                    )
                else:
                    fields[param_name] = (param_type, ...)
            else:
                optional_type = Optional[param_type]
                if description:
                    fields[param_name] = (
                        optional_type,
                        Field(default=None, description=description),
                    )
                else:
                    fields[param_name] = (optional_type, None)

        if fields:
            ParamsModel = create_model(f"{sanitized_tool_name}_Params", **fields)
        else:
            ParamsModel = create_model(f"{sanitized_tool_name}_Params")

        tool_callable = tool_dict.get("callable")
        tool_description = spec.get("description", "") if isinstance(spec, dict) else ""
        if not tool_description and isinstance(spec, dict):
            tool_description = spec.get("summary", "")

        # å…³é”®: å¦‚æœå·¥å…·åç§°è¢«å‡€åŒ–ï¼ˆä¾‹å¦‚ä¸­æ–‡è½¬å“ˆå¸Œï¼‰ï¼Œè¯­ä¹‰ä¼šä¸¢å¤±ã€‚
        # æˆ‘ä»¬å¿…é¡»å°†åŸå§‹åç§°æ³¨å…¥åˆ°æè¿°ä¸­ï¼Œä»¥ä¾¿æ¨¡å‹çŸ¥é“å®ƒçš„ä½œç”¨ã€‚
        if sanitized_tool_name != tool_name:
            tool_description = f"åŠŸèƒ½ '{tool_name}': {tool_description}"

        async def _tool(params):
            payload = params.model_dump() if hasattr(params, "model_dump") else {}
            return await tool_callable(**payload)

        _tool.__name__ = sanitized_tool_name
        _tool.__doc__ = tool_description

        # è½¬æ¢è°ƒè¯•æ—¥å¿—
        logger.debug(
            f"æ­£åœ¨è½¬æ¢å·¥å…· '{sanitized_tool_name}': {tool_description[:50]}..."
        )

        # æ ¸å¿ƒå…³é”®ç‚¹ï¼šå¿…é¡»æ˜¾å¼ä¼ é€’ typesï¼Œå¦åˆ™ define_tool æ— æ³•æ¨æ–­åŠ¨æ€å‡½æ•°çš„å‚æ•°
        # æ˜¾å¼ä¼ é€’ name ç¡®ä¿ SDK æ³¨å†Œçš„åç§°æ­£ç¡®
        return define_tool(
            name=sanitized_tool_name,
            description=tool_description,
            params_type=ParamsModel,
        )(_tool)

    def _build_openwebui_request(self):
        """æ„å»ºä¸€ä¸ªæœ€å°çš„ request æ¨¡æ‹Ÿå¯¹è±¡ç”¨äº OpenWebUI å·¥å…·åŠ è½½ã€‚"""
        app_state = SimpleNamespace(
            config=SimpleNamespace(
                TOOL_SERVER_CONNECTIONS=TOOL_SERVER_CONNECTIONS.value
            ),
            TOOLS={},
        )
        app = SimpleNamespace(state=app_state)
        request = SimpleNamespace(
            app=app,
            cookies={},
            state=SimpleNamespace(token=SimpleNamespace(credentials="")),
        )
        return request

    async def _load_openwebui_tools(self, __user__=None, __event_call__=None):
        """åŠ¨æ€åŠ è½½ OpenWebUI å·¥å…·å¹¶è½¬æ¢ä¸º Copilot SDK å·¥å…·ã€‚"""
        if isinstance(__user__, (list, tuple)):
            user_data = __user__[0] if __user__ else {}
        elif isinstance(__user__, dict):
            user_data = __user__
        else:
            user_data = {}

        if not user_data:
            return []

        user_id = user_data.get("id") or user_data.get("user_id")
        if not user_id:
            return []

        user = Users.get_user_by_id(user_id)
        if not user:
            return []

        # 1. è·å–ç”¨æˆ·è‡ªå®šä¹‰å·¥å…· (Python è„šæœ¬)
        tool_items = Tools.get_tools_by_user_id(user_id, permission="read")
        tool_ids = [tool.id for tool in tool_items] if tool_items else []

        # 2. è·å– OpenAPI å·¥å…·æœåŠ¡å™¨å·¥å…·
        # æˆ‘ä»¬æ‰‹åŠ¨æ·»åŠ å·²å¯ç”¨çš„ OpenAPI æœåŠ¡å™¨ï¼Œå› ä¸º Tools.get_tools_by_user_id ä»…æ£€æŸ¥æ•°æ®åº“ã€‚
        # open_webui.utils.tools.get_tools ä¼šå¤„ç†å®é™…çš„åŠ è½½å’Œè®¿é—®æ§åˆ¶ã€‚
        if hasattr(TOOL_SERVER_CONNECTIONS, "value"):
            for server in TOOL_SERVER_CONNECTIONS.value:
                # æˆ‘ä»¬åœ¨æ­¤å¤„ä»…æ·»åŠ  'openapi' æœåŠ¡å™¨ï¼Œå› ä¸º get_tools ç›®å‰ä¼¼ä¹ä»…æ”¯æŒ 'openapi' (é»˜è®¤ä¸ºæ­¤)ã€‚
                # MCP å·¥å…·é€šè¿‡ ENABLE_MCP_SERVER å•ç‹¬å¤„ç†ã€‚
                if server.get("type") == "openapi":
                    # get_tools æœŸæœ›çš„æ ¼å¼: "server:<id>" éšå« type="openapi"
                    server_id = server.get("id")
                    if server_id:
                        tool_ids.append(f"server:{server_id}")

        if not tool_ids:
            return []

        request = self._build_openwebui_request()
        extra_params = {
            "__request__": request,
            "__user__": user_data,
            "__event_emitter__": None,
            "__event_call__": __event_call__,
            "__chat_id__": None,
            "__message_id__": None,
            "__model_knowledge__": [],
        }

        tools_dict = await get_openwebui_tools(request, tool_ids, user, extra_params)
        if not tools_dict:
            return []

        converted_tools = []
        for tool_name, tool_def in tools_dict.items():
            try:
                converted_tools.append(
                    self._convert_openwebui_tool(tool_name, tool_def)
                )
            except Exception as e:
                await self._emit_debug_log(
                    f"åŠ è½½ OpenWebUI å·¥å…· '{tool_name}' å¤±è´¥: {e}",
                    __event_call__,
                )

        return converted_tools

    def _parse_mcp_servers(self) -> Optional[dict]:
        """
        ä» OpenWebUI TOOL_SERVER_CONNECTIONS åŠ¨æ€åŠ è½½ MCP æœåŠ¡å™¨é…ç½®ã€‚
        è¿”å›å…¼å®¹ CopilotClient çš„ mcp_servers å­—å…¸ã€‚
        """
        if not self.valves.ENABLE_MCP_SERVER:
            return None

        mcp_servers = {}

        # éå† OpenWebUI å·¥å…·æœåŠ¡å™¨è¿æ¥
        if hasattr(TOOL_SERVER_CONNECTIONS, "value"):
            connections = TOOL_SERVER_CONNECTIONS.value
        else:
            connections = []

        for conn in connections:
            if conn.get("type") == "mcp":
                info = conn.get("info", {})
                # ä½¿ç”¨ info ä¸­çš„ ID æˆ–è‡ªåŠ¨ç”Ÿæˆ
                raw_id = info.get("id", f"mcp-server-{len(mcp_servers)}")

                # å‡€åŒ– server_id (ä½¿ç”¨ä¸å·¥å…·ç›¸åŒçš„é€»è¾‘)
                server_id = re.sub(r"[^a-zA-Z0-9_-]", "_", raw_id)
                if not server_id or re.match(r"^[_.-]+$", server_id):
                    hash_suffix = hashlib.md5(raw_id.encode("utf-8")).hexdigest()[:8]
                    server_id = f"server_{hash_suffix}"

                url = conn.get("url")
                if not url:
                    continue

                # æ„å»º Header (å¤„ç†è®¤è¯)
                headers = {}
                auth_type = conn.get("auth_type", "bearer")
                key = conn.get("key", "")

                if auth_type == "bearer" and key:
                    headers["Authorization"] = f"Bearer {key}"
                elif auth_type == "basic" and key:
                    headers["Authorization"] = f"Basic {key}"

                # åˆå¹¶è‡ªå®šä¹‰ headers
                custom_headers = conn.get("headers", {})
                if isinstance(custom_headers, dict):
                    headers.update(custom_headers)

                mcp_servers[server_id] = {
                    "type": "http",
                    "url": url,
                    "headers": headers,
                    "tools": ["*"],  # é»˜è®¤å¯ç”¨æ‰€æœ‰å·¥å…·
                }

        return mcp_servers if mcp_servers else None

    def _build_session_config(
        self,
        chat_id: Optional[str],
        real_model_id: str,
        custom_tools: List[Any],
        system_prompt_content: Optional[str],
        is_streaming: bool,
    ):
        """æ„å»º Copilot SDK çš„ SessionConfig"""
        from copilot.types import SessionConfig, InfiniteSessionConfig

        infinite_session_config = None
        if self.valves.INFINITE_SESSION:
            infinite_session_config = InfiniteSessionConfig(
                enabled=True,
                background_compaction_threshold=self.valves.COMPACTION_THRESHOLD,
                buffer_exhaustion_threshold=self.valves.BUFFER_THRESHOLD,
            )

        system_message_config = None
        if system_prompt_content or self.valves.ENFORCE_FORMATTING:
            # æ„å»ºç³»ç»Ÿæ¶ˆæ¯å†…å®¹
            system_parts = []

            if system_prompt_content:
                system_parts.append(system_prompt_content)

            if self.valves.ENFORCE_FORMATTING:
                formatting_instruction = (
                    "\n\n[æ ¼å¼åŒ–æŒ‡å—]\n"
                    "åœ¨æä¾›è§£é‡Šæˆ–æè¿°æ—¶ï¼š\n"
                    "- ä½¿ç”¨æ¸…æ™°çš„æ®µè½åˆ†éš”ï¼ˆåŒæ¢è¡Œï¼‰\n"
                    "- å°†é•¿å¥æ‹†åˆ†ä¸ºå¤šä¸ªçŸ­å¥\n"
                    "- å¯¹å¤šä¸ªè¦ç‚¹ä½¿ç”¨é¡¹ç›®ç¬¦å·æˆ–ç¼–å·åˆ—è¡¨\n"
                    "- ä¸ºä¸»è¦éƒ¨åˆ†æ·»åŠ æ ‡é¢˜ï¼ˆ##ã€###ï¼‰\n"
                    "- ç¡®ä¿ä¸åŒä¸»é¢˜ä¹‹é—´æœ‰é€‚å½“çš„é—´è·"
                )
                system_parts.append(formatting_instruction)
                logger.info(f"[ENFORCE_FORMATTING] å·²æ·»åŠ æ ¼å¼åŒ–æŒ‡å¯¼åˆ°ç³»ç»Ÿæç¤ºè¯")

            if system_parts:
                system_message_config = {
                    "mode": "append",
                    "content": "\n".join(system_parts),
                }

        # å‡†å¤‡ä¼šè¯é…ç½®å‚æ•°
        session_params = {
            "session_id": chat_id if chat_id else None,
            "model": real_model_id,
            "streaming": is_streaming,
            "tools": custom_tools,
            "system_message": system_message_config,
            "infinite_sessions": infinite_session_config,
            # æ³¨å†Œæƒé™å¤„ç† Hook
        }

        mcp_servers = self._parse_mcp_servers()
        if mcp_servers:
            session_params["mcp_servers"] = mcp_servers

        return SessionConfig(**session_params)

    def _dedupe_preserve_order(self, items: List[str]) -> List[str]:
        """å»é‡ä¿åº"""
        seen = set()
        result = []
        for item in items:
            if not item or item in seen:
                continue
            seen.add(item)
            result.append(item)
        return result

    def _collect_model_ids(
        self, body: dict, request_model: str, real_model_id: str
    ) -> List[str]:
        """æ”¶é›†å¯èƒ½çš„æ¨¡å‹ IDï¼ˆæ¥è‡ªè¯·æ±‚/metadata/body paramsï¼‰"""
        model_ids: List[str] = []
        if request_model:
            model_ids.append(request_model)
        if request_model.startswith(f"{self.id}-"):
            model_ids.append(request_model[len(f"{self.id}-") :])
        if real_model_id:
            model_ids.append(real_model_id)

        metadata = body.get("metadata", {})
        if isinstance(metadata, dict):
            meta_model = metadata.get("model")
            meta_model_id = metadata.get("model_id")
            if isinstance(meta_model, str):
                model_ids.append(meta_model)
            if isinstance(meta_model_id, str):
                model_ids.append(meta_model_id)

        body_params = body.get("params", {})
        if isinstance(body_params, dict):
            for key in ("model", "model_id", "modelId"):
                val = body_params.get(key)
                if isinstance(val, str):
                    model_ids.append(val)

        return self._dedupe_preserve_order(model_ids)

    async def _extract_system_prompt(
        self,
        body: dict,
        messages: List[dict],
        request_model: str,
        real_model_id: str,
        __event_call__=None,
    ) -> tuple[Optional[str], str]:
        """ä» metadata/æ¨¡å‹ DB/body/messages æå–ç³»ç»Ÿæç¤ºè¯"""
        system_prompt_content: Optional[str] = None
        system_prompt_source = ""

        # 1) metadata.model.params.system
        metadata = body.get("metadata", {})
        if isinstance(metadata, dict):
            meta_model = metadata.get("model")
            if isinstance(meta_model, dict):
                meta_params = meta_model.get("params")
                if isinstance(meta_params, dict) and meta_params.get("system"):
                    system_prompt_content = meta_params.get("system")
                    system_prompt_source = "metadata.model.params"
                    await self._emit_debug_log(
                        f"ä» metadata.model.params æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                        __event_call__,
                    )

        # 2) æ¨¡å‹ DB
        if not system_prompt_content:
            try:
                from open_webui.models.models import Models

                model_ids_to_try = self._collect_model_ids(
                    body, request_model, real_model_id
                )
                for mid in model_ids_to_try:
                    model_record = Models.get_model_by_id(mid)
                    if model_record and hasattr(model_record, "params"):
                        params = model_record.params
                        if isinstance(params, dict):
                            system_prompt_content = params.get("system")
                            if system_prompt_content:
                                system_prompt_source = f"model_db:{mid}"
                                await self._emit_debug_log(
                                    f"ä»æ¨¡å‹æ•°æ®åº“æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                                    __event_call__,
                                )
                                break
            except Exception as e:
                await self._emit_debug_log(
                    f"ä»æ¨¡å‹æ•°æ®åº“æå–ç³»ç»Ÿæç¤ºè¯å¤±è´¥: {e}",
                    __event_call__,
                )

        # 3) body.params.system
        if not system_prompt_content:
            body_params = body.get("params", {})
            if isinstance(body_params, dict):
                system_prompt_content = body_params.get("system")
                if system_prompt_content:
                    system_prompt_source = "body_params"
                    await self._emit_debug_log(
                        f"ä» body.params æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                        __event_call__,
                    )

        # 4) messages (role=system)
        if not system_prompt_content:
            for msg in messages:
                if msg.get("role") == "system":
                    system_prompt_content = self._extract_text_from_content(
                        msg.get("content", "")
                    )
                    if system_prompt_content:
                        system_prompt_source = "messages_system"
                        await self._emit_debug_log(
                            f"ä»æ¶ˆæ¯ä¸­æå–ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿åº¦: {len(system_prompt_content)}ï¼‰",
                            __event_call__,
                        )
                    break

        return system_prompt_content, system_prompt_source

    async def _emit_debug_log(self, message: str, __event_call__=None):
        """åœ¨ DEBUG å¼€å¯æ—¶å°†æ—¥å¿—è¾“å‡ºåˆ°å‰ç«¯æ§åˆ¶å°ã€‚"""
        if not self.valves.DEBUG:
            return

        logger.debug(f"[Copilot Pipe] {message}")

        if not __event_call__:
            return

        try:
            js_code = f"""
                (async function() {{
                    console.debug("%c[Copilot Pipe] " + {json.dumps(message, ensure_ascii=False)}, "color: #3b82f6;");
                }})();
            """
            await __event_call__({"type": "execute", "data": {"code": js_code}})
        except Exception as e:
            logger.debug(f"[Copilot Pipe] å‰ç«¯è°ƒè¯•æ—¥å¿—å¤±è´¥: {e}")

    def _emit_debug_log_sync(self, message: str, __event_call__=None):
        """åœ¨éå¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­è¾“å‡ºè°ƒè¯•æ—¥å¿—ã€‚"""
        if not self.valves.DEBUG:
            return

        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            logger.debug(f"[Copilot Pipe] {message}")
            return

        loop.create_task(self._emit_debug_log(message, __event_call__))

    async def _emit_native_message(self, message_data: dict, __event_call__=None):
        """å‘é€åŸç”Ÿ OpenAI æ ¼å¼æ¶ˆæ¯äº‹ä»¶ç”¨äºå·¥å…·è°ƒç”¨/ç»“æœã€‚"""
        if not __event_call__:
            return

        try:
            await __event_call__({"type": "message", "data": message_data})
            await self._emit_debug_log(
                f"å·²å‘é€åŸç”Ÿæ¶ˆæ¯: {message_data.get('role')} - {list(message_data.keys())}",
                __event_call__,
            )
        except Exception as e:
            logger.warning(f"å‘é€åŸç”Ÿæ¶ˆæ¯å¤±è´¥: {e}")
            await self._emit_debug_log(
                f"åŸç”Ÿæ¶ˆæ¯å‘é€å¤±è´¥: {e}ã€‚å›é€€åˆ°æ–‡æœ¬æ˜¾ç¤ºã€‚", __event_call__
            )

    def _get_user_context(self):
        """è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆå ä½ï¼Œé¢„ç•™ï¼‰ã€‚"""
        return {}

    def _get_chat_context(
        self, body: dict, __metadata__: Optional[dict] = None, __event_call__=None
    ) -> Dict[str, str]:
        """
        é«˜åº¦å¯é çš„èŠå¤©ä¸Šä¸‹æ–‡æå–é€»è¾‘ã€‚
        ä¼˜å…ˆçº§ï¼š__metadata__ > body['chat_id'] > body['metadata']['chat_id']
        """
        chat_id = ""
        source = "none"

        # 1. ä¼˜å…ˆä» __metadata__ è·å– (OpenWebUI æ³¨å…¥çš„æœ€å¯é æ¥æº)
        if __metadata__ and isinstance(__metadata__, dict):
            chat_id = __metadata__.get("chat_id", "")
            if chat_id:
                source = "__metadata__"

        # 2. å…¶æ¬¡ä» body é¡¶å±‚è·å–
        if not chat_id and isinstance(body, dict):
            chat_id = body.get("chat_id", "")
            if chat_id:
                source = "body_root"

        # 3. æœ€åä» body.metadata è·å–
        if not chat_id and isinstance(body, dict):
            body_metadata = body.get("metadata", {})
            if isinstance(body_metadata, dict):
                chat_id = body_metadata.get("chat_id", "")
                if chat_id:
                    source = "body_metadata"

        # è°ƒè¯•ï¼šè®°å½• ID æ¥æº
        if chat_id:
            self._emit_debug_log_sync(
                f"æå–åˆ° ChatID: {chat_id} (æ¥æº: {source})", __event_call__
            )
        else:
            # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œè®°å½•ä¸€ä¸‹ body çš„é”®ï¼Œæ–¹ä¾¿æ’æŸ¥
            keys = list(body.keys()) if isinstance(body, dict) else "not a dict"
            self._emit_debug_log_sync(
                f"è­¦å‘Š: æœªèƒ½æå–åˆ° ChatIDã€‚Body é”®: {keys}", __event_call__
            )

        return {
            "chat_id": str(chat_id).strip(),
        }

    async def pipes(self) -> List[dict]:
        """åŠ¨æ€è·å–æ¨¡å‹åˆ—è¡¨"""
        # å¦‚æœæœ‰ç¼“å­˜ï¼Œç›´æ¥è¿”å›
        if self._model_cache:
            return self._model_cache

        await self._emit_debug_log("æ­£åœ¨åŠ¨æ€è·å–æ¨¡å‹åˆ—è¡¨...")
        try:
            self._setup_env()
            if not self.valves.GH_TOKEN:
                return [{"id": f"{self.id}-error", "name": "Error: GH_TOKEN not set"}]

            client_config = {}
            if os.environ.get("COPILOT_CLI_PATH"):
                client_config["cli_path"] = os.environ["COPILOT_CLI_PATH"]

            client = CopilotClient(client_config)
            try:
                await client.start()
                models = await client.list_models()

                # æ›´æ–°ç¼“å­˜
                self._model_cache = []
                exclude_list = [
                    k.strip().lower()
                    for k in self.valves.EXCLUDE_KEYWORDS.split(",")
                    if k.strip()
                ]

                models_with_info = []
                for m in models:
                    # å…¼å®¹å­—å…¸å’Œå¯¹è±¡è®¿é—®æ–¹å¼
                    m_id = (
                        m.get("id") if isinstance(m, dict) else getattr(m, "id", str(m))
                    )
                    m_name = (
                        m.get("name")
                        if isinstance(m, dict)
                        else getattr(m, "name", m_id)
                    )
                    m_policy = (
                        m.get("policy")
                        if isinstance(m, dict)
                        else getattr(m, "policy", {})
                    )
                    m_billing = (
                        m.get("billing")
                        if isinstance(m, dict)
                        else getattr(m, "billing", {})
                    )

                    # æ£€æŸ¥ç­–ç•¥çŠ¶æ€
                    state = (
                        m_policy.get("state")
                        if isinstance(m_policy, dict)
                        else getattr(m_policy, "state", "enabled")
                    )
                    if state == "disabled":
                        continue

                    # è¿‡æ»¤é€»è¾‘
                    if any(kw in m_id.lower() for kw in exclude_list):
                        continue

                    # è·å–å€ç‡
                    multiplier = (
                        m_billing.get("multiplier", 1)
                        if isinstance(m_billing, dict)
                        else getattr(m_billing, "multiplier", 1)
                    )

                    # æ ¼å¼åŒ–æ˜¾ç¤ºåç§°
                    if multiplier == 0:
                        display_name = f"-ğŸ”¥ {m_id} (unlimited)"
                    else:
                        display_name = f"-{m_id} ({multiplier}x)"

                    models_with_info.append(
                        {
                            "id": f"{self.id}-{m_id}",
                            "name": display_name,
                            "multiplier": multiplier,
                            "raw_id": m_id,
                        }
                    )

                # æ’åºï¼šå€ç‡å‡åºï¼Œç„¶åæ˜¯åŸå§‹IDå‡åº
                models_with_info.sort(key=lambda x: (x["multiplier"], x["raw_id"]))
                self._model_cache = [
                    {"id": m["id"], "name": m["name"]} for m in models_with_info
                ]

                await self._emit_debug_log(
                    f"æˆåŠŸè·å– {len(self._model_cache)} ä¸ªæ¨¡å‹ (å·²è¿‡æ»¤)"
                )
                return self._model_cache
            except Exception as e:
                await self._emit_debug_log(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
                # å¤±è´¥æ—¶è¿”å›é»˜è®¤æ¨¡å‹
                return [
                    {
                        "id": f"{self.id}-gpt-5-mini",
                        "name": f"GitHub Copilot (gpt-5-mini)",
                    }
                ]
            finally:
                await client.stop()
        except Exception as e:
            await self._emit_debug_log(f"Pipes Error: {e}")
            return [
                {
                    "id": f"{self.id}-gpt-5-mini",
                    "name": f"GitHub Copilot (gpt-5-mini)",
                }
            ]

    async def _get_client(self):
        """Helper to get or create a CopilotClient instance."""
        # ç¡®å®šå·¥ä½œç©ºé—´ç›®å½•
        cwd = self.valves.WORKSPACE_DIR if self.valves.WORKSPACE_DIR else os.getcwd()

        client_config = {}
        if os.environ.get("COPILOT_CLI_PATH"):
            client_config["cli_path"] = os.environ["COPILOT_CLI_PATH"]
        client_config["cwd"] = cwd

        # è®¾ç½®æ—¥å¿—çº§åˆ«
        if self.valves.LOG_LEVEL:
            client_config["log_level"] = self.valves.LOG_LEVEL

        # æ·»åŠ è‡ªå®šä¹‰ç¯å¢ƒå˜é‡
        if self.valves.CUSTOM_ENV_VARS:
            try:
                custom_env = json.loads(self.valves.CUSTOM_ENV_VARS)
                if isinstance(custom_env, dict):
                    client_config["env"] = custom_env
            except:
                pass  # é™é»˜å¤±è´¥ï¼Œå› ä¸ºè¿™æ˜¯åŒæ­¥æ–¹æ³•ä¸”ä¸åº”å½±å“ä¸»æµç¨‹

        client = CopilotClient(client_config)
        await client.start()
        return client

    def _setup_env(self, __event_call__=None):
        cli_path = "/usr/local/bin/copilot"
        if os.environ.get("COPILOT_CLI_PATH"):
            cli_path = os.environ["COPILOT_CLI_PATH"]

        target_version = self.valves.COPILOT_CLI_VERSION.strip()
        found = False
        current_version = None

        # å†…éƒ¨ helper: è·å–ç‰ˆæœ¬
        def get_cli_version(path):
            try:
                output = (
                    subprocess.check_output(
                        [path, "--version"], stderr=subprocess.STDOUT
                    )
                    .decode()
                    .strip()
                )
                # Copilot CLI è¾“å‡ºé€šå¸¸åŒ…å« "copilot version X.Y.Z" æˆ–ç›´æ¥æ˜¯ç‰ˆæœ¬å·
                match = re.search(r"(\d+\.\d+\.\d+)", output)
                return match.group(1) if match else output
            except Exception:
                return None

        # æ£€æŸ¥é»˜è®¤è·¯å¾„
        if os.path.exists(cli_path):
            found = True
            current_version = get_cli_version(cli_path)

        # äºŒæ¬¡æ£€æŸ¥ç³»ç»Ÿè·¯å¾„
        if not found:
            sys_path = shutil.which("copilot")
            if sys_path:
                cli_path = sys_path
                found = True
                current_version = get_cli_version(cli_path)

        # åˆ¤æ–­æ˜¯å¦éœ€è¦å®‰è£…/æ›´æ–°
        should_install = False
        install_reason = ""

        if not found:
            should_install = True
            install_reason = "CLI æœªæ‰¾åˆ°"
        elif target_version:
            # æ ‡å‡†åŒ–ç‰ˆæœ¬å· (ç§»é™¤ 'v' å‰ç¼€)
            norm_target = target_version.lstrip("v")
            norm_current = current_version.lstrip("v") if current_version else ""

            if norm_target != norm_current:
                should_install = True
                install_reason = (
                    f"ç‰ˆæœ¬ä¸åŒ¹é… (å½“å‰: {current_version}, ç›®æ ‡: {target_version})"
                )

        if should_install:
            if self.valves.DEBUG:
                self._emit_debug_log_sync(
                    f"æ­£åœ¨å®‰è£… Copilot CLI: {install_reason}...", __event_call__
                )
            try:
                env = os.environ.copy()
                if target_version:
                    env["VERSION"] = target_version

                subprocess.run(
                    "curl -fsSL https://gh.io/copilot-install | bash",
                    shell=True,
                    check=True,
                    env=env,
                )

                # ä¼˜å…ˆæ£€æŸ¥é»˜è®¤å®‰è£…è·¯å¾„ï¼Œå…¶æ¬¡æ˜¯ç³»ç»Ÿè·¯å¾„
                if os.path.exists("/usr/local/bin/copilot"):
                    cli_path = "/usr/local/bin/copilot"
                    found = True
                elif shutil.which("copilot"):
                    cli_path = shutil.which("copilot")
                    found = True

                if found:
                    current_version = get_cli_version(cli_path)
            except Exception as e:
                if self.valves.DEBUG:
                    self._emit_debug_log_sync(
                        f"Copilot CLI å®‰è£…å¤±è´¥: {e}", __event_call__
                    )

        if found:
            os.environ["COPILOT_CLI_PATH"] = cli_path
            cli_dir = os.path.dirname(cli_path)
            if cli_dir not in os.environ["PATH"]:
                os.environ["PATH"] = f"{cli_dir}:{os.environ['PATH']}"

            if self.valves.DEBUG:
                self._emit_debug_log_sync(
                    f"å·²æ‰¾åˆ° Copilot CLI: {cli_path} (ç‰ˆæœ¬: {current_version})",
                    __event_call__,
                )
        else:
            if self.valves.DEBUG:
                self._emit_debug_log_sync(
                    "é”™è¯¯: æœªæ‰¾åˆ° Copilot CLIã€‚ç›¸å…³ Agent åŠŸèƒ½å°†è¢«ç¦ç”¨ã€‚",
                    __event_call__,
                )

        if self.valves.GH_TOKEN:
            os.environ["GH_TOKEN"] = self.valves.GH_TOKEN
            os.environ["GITHUB_TOKEN"] = self.valves.GH_TOKEN
        else:
            if self.valves.DEBUG:
                self._emit_debug_log_sync("Warning: GH_TOKEN æœªè®¾ç½®ã€‚", __event_call__)

        self._sync_mcp_config(__event_call__)

    def _process_images(self, messages, __event_call__=None):
        attachments = []
        text_content = ""
        if not messages:
            return "", []
        last_msg = messages[-1]
        content = last_msg.get("content", "")

        if isinstance(content, list):
            for item in content:
                if item.get("type") == "text":
                    text_content += item.get("text", "")
                elif item.get("type") == "image_url":
                    image_url = item.get("image_url", {}).get("url", "")
                    if image_url.startswith("data:image"):
                        try:
                            header, encoded = image_url.split(",", 1)
                            ext = header.split(";")[0].split("/")[-1]
                            file_name = f"image_{len(attachments)}.{ext}"
                            file_path = os.path.join(self.temp_dir, file_name)
                            with open(file_path, "wb") as f:
                                f.write(base64.b64decode(encoded))
                            attachments.append(
                                {
                                    "type": "file",
                                    "path": file_path,
                                    "display_name": file_name,
                                }
                            )
                            self._emit_debug_log_sync(
                                f"Image processed: {file_path}", __event_call__
                            )
                        except Exception as e:
                            self._emit_debug_log_sync(
                                f"Image error: {e}", __event_call__
                            )
        else:
            text_content = str(content)
        return text_content, attachments

    def _sync_copilot_config(self, reasoning_effort: str, __event_call__=None):
        """
        åŠ¨æ€æ›´æ–° ~/.copilot/config.json ä¸­çš„ reasoning_effort è®¾ç½®ã€‚
        å¦‚æœ API æ³¨å…¥è¢«å¿½ç•¥ï¼Œè¿™æä¾›äº†æœ€åçš„ä¿éšœã€‚
        """
        if not reasoning_effort:
            return

        effort = reasoning_effort

        # æ£€æŸ¥æ¨¡å‹å¯¹ xhigh çš„æ”¯æŒ
        # ç›®å‰ä»… gpt-5.2-codex æ”¯æŒ xhigh
        # åœ¨ _sync_copilot_config ä¸­å¾ˆéš¾è·å¾—å‡†ç¡®çš„å½“å‰æ¨¡å‹ IDï¼Œ
        # å› æ­¤è¿™é‡Œæˆ‘ä»¬æ”¾å®½é™åˆ¶ï¼Œå…è®¸å†™å…¥ xhighã€‚
        # å¦‚æœæ¨¡å‹ä¸æ”¯æŒï¼ŒCopilot CLI å¯èƒ½ä¼šå¿½ç•¥æˆ–é™çº§å¤„ç†ï¼Œä½†è¿™æ¯”åœ¨è¿™é‡Œç¡¬ç¼–ç åˆ¤æ–­æ›´å®‰å…¨ï¼Œ
        # å› ä¸ºè·å–å½“å‰è¯·æ±‚çš„ body éœ€è¦ä¿®æ”¹å‡½æ•°ç­¾åã€‚

        try:
            # ç›®æ ‡æ ‡å‡†è·¯å¾„ ~/.copilot/config.json
            config_path = os.path.expanduser("~/.copilot/config.json")
            config_dir = os.path.dirname(config_path)

            # ä»…åœ¨ç›®å½•å­˜åœ¨æ—¶æ‰§è¡Œï¼ˆé¿å…åœ¨é”™è¯¯ç¯å¢ƒåˆ›å»ºåƒåœ¾æ–‡ä»¶ï¼‰
            if not os.path.exists(config_dir):
                return

            data = {}
            # è¯»å–ç°æœ‰é…ç½®
            if os.path.exists(config_path):
                try:
                    with open(config_path, "r") as f:
                        data = json.load(f)
                except Exception:
                    data = {}

            # å¦‚æœå€¼æœ‰å˜åŒ–åˆ™æ›´æ–°
            current_val = data.get("reasoning_effort")
            if current_val != effort:
                data["reasoning_effort"] = effort
                try:
                    with open(config_path, "w") as f:
                        json.dump(data, f, indent=4)

                    self._emit_debug_log_sync(
                        f"å·²åŠ¨æ€æ›´æ–° ~/.copilot/config.json: reasoning_effort='{effort}'",
                        __event_call__,
                    )
                except Exception as e:
                    self._emit_debug_log_sync(
                        f"å†™å…¥ config.json å¤±è´¥: {e}", __event_call__
                    )
        except Exception as e:
            self._emit_debug_log_sync(f"é…ç½®åŒæ­¥æ£€æŸ¥å¤±è´¥: {e}", __event_call__)

    def _sync_mcp_config(self, __event_call__=None):
        """å·²å¼ƒç”¨ï¼šMCP é…ç½®ç°åœ¨é€šè¿‡ SessionConfig åŠ¨æ€å¤„ç†ã€‚"""
        pass

    # ==================== å†…éƒ¨å®ç° ====================
    # _pipe_impl() åŒ…å«ä¸»è¯·æ±‚å¤„ç†é€»è¾‘ã€‚
    # ================================================
    def _sync_copilot_config(self, reasoning_effort: str, __event_call__=None):
        """
        å¦‚æœè®¾ç½®äº† REASONING_EFFORTï¼Œåˆ™åŠ¨æ€æ›´æ–° ~/.copilot/config.jsonã€‚
        è¿™æä¾›äº†ä¸€ä¸ªå›é€€æœºåˆ¶ï¼Œä»¥é˜² API æ³¨å…¥è¢«æœåŠ¡å™¨å¿½ç•¥ã€‚
        """
        if not reasoning_effort:
            return

        effort = reasoning_effort

        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒ xhigh
        # ç›®å‰åªæœ‰ gpt-5.2-codex æ”¯æŒ xhigh
        if effort == "xhigh":
            # ç®€å•æ£€æŸ¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹ ID
            if (
                "gpt-5.2-codex"
                not in self._collect_model_ids(
                    body={},
                    request_model=self.id,
                    real_model_id=None,
                )[0].lower()
            ):
                # å¦‚æœä¸æ”¯æŒåˆ™å›é€€åˆ° high
                effort = "high"

        try:
            # ç›®æ ‡æ ‡å‡†è·¯å¾„ ~/.copilot/config.json
            config_path = os.path.expanduser("~/.copilot/config.json")
            config_dir = os.path.dirname(config_path)

            # ä»…å½“ç›®å½•å­˜åœ¨æ—¶æ‰ç»§ç»­ï¼ˆé¿å…åœ¨è·¯å¾„é”™è¯¯æ—¶åˆ›å»ºåƒåœ¾æ–‡ä»¶ï¼‰
            if not os.path.exists(config_dir):
                return

            data = {}
            # è¯»å–ç°æœ‰é…ç½®
            if os.path.exists(config_path):
                try:
                    with open(config_path, "r") as f:
                        data = json.load(f)
                except Exception:
                    data = {}

            # å¦‚æœæœ‰å˜åŒ–åˆ™æ›´æ–°
            current_val = data.get("reasoning_effort")
            if current_val != effort:
                data["reasoning_effort"] = effort
                try:
                    with open(config_path, "w") as f:
                        json.dump(data, f, indent=4)

                    self._emit_debug_log_sync(
                        f"å·²åŠ¨æ€æ›´æ–° ~/.copilot/config.json: reasoning_effort='{effort}'",
                        __event_call__,
                    )
                except Exception as e:
                    self._emit_debug_log_sync(
                        f"å†™å…¥ config.json å¤±è´¥: {e}", __event_call__
                    )
        except Exception as e:
            self._emit_debug_log_sync(f"é…ç½®åŒæ­¥æ£€æŸ¥å¤±è´¥: {e}", __event_call__)

    async def _update_copilot_cli(self, cli_path: str, __event_call__=None):
        """å¼‚æ­¥ä»»åŠ¡ï¼šå¦‚æœéœ€è¦åˆ™æ›´æ–° Copilot CLIã€‚"""
        import time

        try:
            # æ£€æŸ¥é¢‘ç‡ï¼ˆä¾‹å¦‚ï¼šæ¯å°æ—¶ä¸€æ¬¡ï¼‰
            now = time.time()
            if now - self._last_update_check < 3600:
                return

            self._last_update_check = now

            if self.valves.DEBUG:
                self._emit_debug_log_sync(
                    "è§¦å‘å¼‚æ­¥ Copilot CLI æ›´æ–°æ£€æŸ¥...", __event_call__
                )

            # æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå­è¿›ç¨‹æ¥è¿è¡Œæ›´æ–°
            process = await asyncio.create_subprocess_exec(
                cli_path,
                "update",
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )

            stdout, stderr = await process.communicate()

            if self.valves.DEBUG and process.returncode == 0:
                self._emit_debug_log_sync("Copilot CLI æ›´æ–°æ£€æŸ¥å®Œæˆ", __event_call__)
            elif process.returncode != 0 and self.valves.DEBUG:
                self._emit_debug_log_sync(
                    f"Copilot CLI æ›´æ–°å¤±è´¥: {stderr.decode()}", __event_call__
                )

        except Exception as e:
            if self.valves.DEBUG:
                self._emit_debug_log_sync(f"CLI æ›´æ–°ä»»åŠ¡å¼‚å¸¸: {e}", __event_call__)

    async def _pipe_impl(
        self,
        body: dict,
        __metadata__: Optional[dict] = None,
        __user__: Optional[dict] = None,
        __event_emitter__=None,
        __event_call__=None,
    ) -> Union[str, AsyncGenerator]:
        self._setup_env(__event_call__)

        cwd = self._get_workspace_dir()
        if self.valves.DEBUG:
            await self._emit_debug_log(f"å½“å‰å·¥ä½œç›®å½•: {cwd}", __event_call__)

        # CLI Update Check
        if os.environ.get("COPILOT_CLI_PATH"):
            asyncio.create_task(
                self._update_copilot_cli(os.environ["COPILOT_CLI_PATH"], __event_call__)
            )

        if not self.valves.GH_TOKEN:
            return "Error: è¯·åœ¨ Valves ä¸­é…ç½® GH_TOKENã€‚"

        # è§£æç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹
        request_model = body.get("model", "")
        real_model_id = request_model

        # ç¡®å®šæœ‰æ•ˆçš„æ¨ç†å¼ºåº¦å’Œè°ƒè¯•è®¾ç½®
        if __user__:
            raw_valves = __user__.get("valves", {})
            if isinstance(raw_valves, self.UserValves):
                user_valves = raw_valves
            elif isinstance(raw_valves, dict):
                user_valves = self.UserValves(**raw_valves)
            else:
                user_valves = self.UserValves()
        else:
            user_valves = self.UserValves()
        effective_reasoning_effort = (
            user_valves.REASONING_EFFORT
            if user_valves.REASONING_EFFORT
            else self.valves.REASONING_EFFORT
        )

        # Sync config for reasoning effort (Legacy/Fallback)
        self._sync_copilot_config(effective_reasoning_effort, __event_call__)

        # å¦‚æœç”¨æˆ·å¯ç”¨äº† DEBUGï¼Œåˆ™è¦†ç›–å…¨å±€è®¾ç½®
        if user_valves.DEBUG:
            self.valves.DEBUG = True

        # å¤„ç† SHOW_THINKINGï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è®¾ç½®ï¼‰
        show_thinking = (
            user_valves.SHOW_THINKING
            if user_valves.SHOW_THINKING is not None
            else self.valves.SHOW_THINKING
        )

        if request_model.startswith(f"{self.id}-"):
            real_model_id = request_model[len(f"{self.id}-") :]
            await self._emit_debug_log(
                f"ä½¿ç”¨é€‰æ‹©çš„æ¨¡å‹: {real_model_id}", __event_call__
            )
        elif __metadata__ and __metadata__.get("base_model_id"):
            base_model_id = __metadata__.get("base_model_id", "")
            if base_model_id.startswith(f"{self.id}-"):
                real_model_id = base_model_id[len(f"{self.id}-") :]
                await self._emit_debug_log(
                    f"ä½¿ç”¨åŸºç¡€æ¨¡å‹: {real_model_id} (ç»§æ‰¿è‡ªè‡ªå®šä¹‰æ¨¡å‹ {request_model})",
                    __event_call__,
                )

        # å¼ºåˆ¶æ‰§è¡Œæ¨¡å‹ç™½åå•å’Œå¤‡ç”¨é€»è¾‘ï¼ˆå¦‚æœå·²é…ç½®ï¼‰
        try:
            real_model_id = self._sanitize_model(real_model_id)
        except ValueError as e:
            await self._emit_debug_log(
                f"é˜»æ­¢ä»£ç†ç”Ÿæˆå°è¯•: {e}", __event_call__
            )
            return f"é”™è¯¯: {str(e)}"

        messages = body.get("messages", [])
        if not messages:
            return "No messages."

        # ä½¿ç”¨æ”¹è¿›çš„åŠ©æ‰‹è·å– Chat ID
        chat_ctx = self._get_chat_context(body, __metadata__, __event_call__)
        chat_id = chat_ctx.get("chat_id")

        # ä»å¤šä¸ªæ¥æºæå–ç³»ç»Ÿæç¤ºè¯
        system_prompt_content, system_prompt_source = await self._extract_system_prompt(
            body, messages, request_model, real_model_id, __event_call__
        )

        if system_prompt_content:
            preview = system_prompt_content[:60].replace("\n", " ")
            await self._emit_debug_log(
                f"ç³»ç»Ÿæç¤ºè¯å·²ç¡®è®¤ï¼ˆæ¥æº: {system_prompt_source}, é•¿åº¦: {len(system_prompt_content)}, é¢„è§ˆ: {preview}ï¼‰",
                __event_call__,
            )

        is_streaming = body.get("stream", False)
        await self._emit_debug_log(f"è¯·æ±‚æµå¼ä¼ è¾“: {is_streaming}", __event_call__)

        # å¤„ç†å¤šæ¨¡æ€ï¼ˆå›¾åƒï¼‰å’Œæå–æœ€åçš„æ¶ˆæ¯æ–‡æœ¬
        last_text, attachments = self._process_images(messages, __event_call__)

        client = CopilotClient(self._build_client_config(body))
        should_stop_client = True
        try:
            await client.start()

            # åˆå§‹åŒ–è‡ªå®šä¹‰å·¥å…·
            custom_tools = await self._initialize_custom_tools(
                __user__=__user__, __event_call__=__event_call__
            )
            if custom_tools:
                tool_names = [t.name for t in custom_tools]
                await self._emit_debug_log(
                    f"å·²å¯ç”¨ {len(custom_tools)} ä¸ªè‡ªå®šä¹‰å·¥å…·: {tool_names}",
                    __event_call__,
                )
                # è¯¦ç»†æ‰“å°æ¯ä¸ªå·¥å…·çš„æè¿° (ç”¨äºè°ƒè¯•)
                if self.valves.DEBUG:
                    for t in custom_tools:
                        await self._emit_debug_log(
                            f"ğŸ“‹ å·¥å…·è¯¦æƒ…: {t.name} - {t.description[:100]}...",
                            __event_call__,
                        )

            # æ£€æŸ¥ MCP æœåŠ¡å™¨
            mcp_servers = self._parse_mcp_servers()
            mcp_server_names = list(mcp_servers.keys()) if mcp_servers else []
            if mcp_server_names:
                await self._emit_debug_log(
                    f"ğŸ”Œ MCP æœåŠ¡å™¨å·²é…ç½®: {mcp_server_names}",
                    __event_call__,
                )
            else:
                await self._emit_debug_log(
                    "â„¹ï¸ æœªåœ¨ OpenWebUI è¿æ¥ä¸­å‘ç° MCP æœåŠ¡å™¨ã€‚",
                    __event_call__,
                )

            session = None

            if chat_id:
                try:
                    # å¤ç”¨å·²è§£æçš„ mcp_servers
                    resume_config = (
                        {"mcp_servers": mcp_servers} if mcp_servers else None
                    )
                    # å°è¯•ç›´æ¥ä½¿ç”¨ chat_id ä½œä¸º session_id æ¢å¤ä¼šè¯
                    session = (
                        await client.resume_session(chat_id, resume_config)
                        if resume_config
                        else await client.resume_session(chat_id)
                    )
                    await self._emit_debug_log(
                        f"å·²é€šè¿‡ ChatID æ¢å¤ä¼šè¯: {chat_id}", __event_call__
                    )

                    # æ˜¾ç¤ºå·¥ä½œç©ºé—´ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if self.valves.DEBUG:
                        if session.workspace_path:
                            await self._emit_debug_log(
                                f"ä¼šè¯å·¥ä½œç©ºé—´: {session.workspace_path}",
                                __event_call__,
                            )

                    is_new_session = False
                except Exception as e:
                    # æ¢å¤å¤±è´¥ï¼Œç£ç›˜ä¸Šå¯èƒ½ä¸å­˜åœ¨è¯¥ä¼šè¯
                    reasoning_effort = (effective_reasoning_effort,)
                    await self._emit_debug_log(
                        f"ä¼šè¯ {chat_id} ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ ({str(e)})ï¼Œå°†åˆ›å»ºæ–°ä¼šè¯ã€‚",
                        __event_call__,
                    )
                    session = None

            if session is None:
                session_config = self._build_session_config(
                    chat_id,
                    real_model_id,
                    custom_tools,
                    system_prompt_content,
                    is_streaming,
                )
                if system_prompt_content:
                    await self._emit_debug_log(
                        f"é…ç½®ç³»ç»Ÿæ¶ˆæ¯ï¼ˆæ¨¡å¼: appendï¼‰",
                        __event_call__,
                    )

                # æ˜¾ç¤ºç³»ç»Ÿé…ç½®é¢„è§ˆ
                if system_prompt_content or self.valves.ENFORCE_FORMATTING:
                    preview_parts = []
                    if system_prompt_content:
                        preview_parts.append(
                            f"è‡ªå®šä¹‰æç¤ºè¯: {system_prompt_content[:100]}..."
                        )
                    if self.valves.ENFORCE_FORMATTING:
                        preview_parts.append("æ ¼å¼åŒ–æŒ‡å¯¼: å·²å¯ç”¨")

                    if isinstance(session_config, dict):
                        system_config = session_config.get("system_message", {})
                    else:
                        system_config = getattr(session_config, "system_message", None)

                    if isinstance(system_config, dict):
                        full_content = system_config.get("content", "")
                    else:
                        full_content = ""

                    await self._emit_debug_log(
                        f"ç³»ç»Ÿæ¶ˆæ¯é…ç½® - {', '.join(preview_parts)} (æ€»é•¿åº¦: {len(full_content)} å­—ç¬¦)",
                        __event_call__,
                    )

                session = await client.create_session(config=session_config)

                # è·å–æ–°ä¼šè¯ ID
                new_sid = getattr(session, "session_id", getattr(session, "id", None))
                await self._emit_debug_log(f"åˆ›å»ºäº†æ–°ä¼šè¯: {new_sid}", __event_call__)

                # æ˜¾ç¤ºæ–°ä¼šè¯çš„å·¥ä½œç©ºé—´ä¿¡æ¯
                if self.valves.DEBUG:
                    if session.workspace_path:
                        await self._emit_debug_log(
                            f"ä¼šè¯å·¥ä½œç©ºé—´: {session.workspace_path}",
                            __event_call__,
                        )

            # æ„å»º Promptï¼ˆåŸºäºä¼šè¯ï¼šä»…å‘é€æœ€æ–°ç”¨æˆ·è¾“å…¥ï¼‰
            prompt = self._apply_formatting_hint(last_text)

            send_payload = {"prompt": prompt, "mode": "immediate"}
            if attachments:
                send_payload["attachments"] = attachments

            if body.get("stream", False):
                # ç¡®å®š UI æ˜¾ç¤ºçš„ä¼šè¯çŠ¶æ€æ¶ˆæ¯
                init_msg = ""
                if self.valves.DEBUG:
                    if is_new_session:
                        new_sid = getattr(
                            session, "session_id", getattr(session, "id", "unknown")
                        )
                        init_msg = f"> [Debug] åˆ›å»ºäº†æ–°ä¼šè¯: {new_sid}\n"
                    else:
                        init_msg = f"> [Debug] å·²é€šè¿‡ ChatID æ¢å¤ä¼šè¯: {chat_id}\n"

                    if mcp_server_names:
                        init_msg += f"> [Debug] ğŸ”Œ å·²è¿æ¥ MCP æœåŠ¡å™¨: {', '.join(mcp_server_names)}\n"

                return self.stream_response(
                    client,
                    session,
                    send_payload,
                    init_msg,
                    __event_call__,
                    reasoning_effort=effective_reasoning_effort,
                    show_thinking=show_thinking,
                )
            else:
                try:
                    response = await session.send_and_wait(send_payload)
                    return response.data.content if response else "Empty response."
                finally:
                    # æ¸…ç†ï¼šå¦‚æœæ²¡æœ‰ chat_idï¼ˆä¸´æ—¶ä¼šè¯ï¼‰ï¼Œé”€æ¯ä¼šè¯
                    if not chat_id:
                        try:
                            await session.destroy()
                        except Exception as cleanup_error:
                            await self._emit_debug_log(
                                f"ä¼šè¯æ¸…ç†è­¦å‘Š: {cleanup_error}",
                                __event_call__,
                            )
        except Exception as e:
            await self._emit_debug_log(f"è¯·æ±‚é”™è¯¯: {e}", __event_call__)
            return f"Error: {str(e)}"
        finally:
            if should_stop_client:
                try:
                    await client.stop()
                except:
                    pass

    async def stream_response(
        self,
        client,
        session,
        send_payload,
        init_message: str = "",
        __event_call__=None,
        reasoning_effort: str = "",
        show_thinking: bool = True,
    ) -> AsyncGenerator:
        """
        ä» Copilot SDK æµå¼ä¼ è¾“å“åº”ï¼Œå¤„ç†å„ç§äº‹ä»¶ç±»å‹ã€‚
        éµå¾ªå®˜æ–¹ SDK æ¨¡å¼è¿›è¡Œäº‹ä»¶å¤„ç†å’Œæµå¼ä¼ è¾“ã€‚
        """
        from copilot.generated.session_events import SessionEventType

        queue = asyncio.Queue()
        done = asyncio.Event()
        SENTINEL = object()
        # ä½¿ç”¨æœ¬åœ°çŠ¶æ€æ¥å¤„ç†å¹¶å‘å’Œè·Ÿè¸ª
        state = {"thinking_started": False, "content_sent": False}
        has_content = False  # è¿½è¸ªæ˜¯å¦å·²ç»è¾“å‡ºäº†å†…å®¹
        active_tools = {}  # æ˜ å°„ tool_call_id åˆ°å·¥å…·åç§°

        def get_event_type(event) -> str:
            """æå–äº‹ä»¶ç±»å‹ä¸ºå­—ç¬¦ä¸²ï¼Œå¤„ç†æšä¸¾å’Œå­—ç¬¦ä¸²ç±»å‹ã€‚"""
            if hasattr(event, "type"):
                event_type = event.type
                # å¤„ç† SessionEventType æšä¸¾
                if hasattr(event_type, "value"):
                    return event_type.value
                return str(event_type)
            return "unknown"

        def safe_get_data_attr(event, attr: str, default=None):
            """
            å®‰å…¨åœ°ä» event.data æå–å±æ€§ã€‚
            åŒæ—¶å¤„ç†å­—å…¸è®¿é—®å’Œå¯¹è±¡å±æ€§è®¿é—®ã€‚
            """
            if not hasattr(event, "data") or event.data is None:
                return default

            data = event.data

            # é¦–å…ˆå°è¯•ä½œä¸ºå­—å…¸
            if isinstance(data, dict):
                return data.get(attr, default)

            # å°è¯•ä½œä¸ºå¯¹è±¡å±æ€§
            return getattr(data, attr, default)

        def handler(event):
            """
            äº‹ä»¶å¤„ç†å™¨ï¼Œéµå¾ªå®˜æ–¹ SDK æ¨¡å¼ã€‚
            å¤„ç†æµå¼å¢é‡ã€æ¨ç†ã€å·¥å…·äº‹ä»¶å’Œä¼šè¯çŠ¶æ€ã€‚
            """
            event_type = get_event_type(event)

            # === æ¶ˆæ¯å¢é‡äº‹ä»¶ï¼ˆä¸»è¦æµå¼å†…å®¹ï¼‰===
            if event_type == "assistant.message_delta":
                # å®˜æ–¹ï¼šPython SDK ä½¿ç”¨ event.data.delta_content
                delta = safe_get_data_attr(
                    event, "delta_content"
                ) or safe_get_data_attr(event, "deltaContent")
                if delta:
                    state["content_sent"] = True
                    if state["thinking_started"]:
                        queue.put_nowait("\n</think>\n")
                        state["thinking_started"] = False
                    queue.put_nowait(delta)

            # === å®Œæ•´æ¶ˆæ¯äº‹ä»¶ï¼ˆéæµå¼å“åº”ï¼‰ ===
            elif event_type == "assistant.message":
                # å¤„ç†å®Œæ•´æ¶ˆæ¯ï¼ˆå½“ SDK è¿”å›å®Œæ•´å†…å®¹è€Œä¸æ˜¯å¢é‡æ—¶ï¼‰
                content = safe_get_data_attr(event, "content") or safe_get_data_attr(
                    event, "message"
                )
                if content:
                    state["content_sent"] = True
                    if state["thinking_started"]:
                        queue.put_nowait("\n</think>\n")
                        state["thinking_started"] = False
                    queue.put_nowait(content)

            # === æ¨ç†å¢é‡äº‹ä»¶ï¼ˆæ€ç»´é“¾æµå¼ä¼ è¾“ï¼‰===
            elif event_type == "assistant.reasoning_delta":
                delta = safe_get_data_attr(
                    event, "delta_content"
                ) or safe_get_data_attr(event, "deltaContent")
                if delta:
                    # å¦‚æœå†…å®¹å·²ç»å¼€å§‹ï¼ŒæŠ‘åˆ¶è¿Ÿåˆ°çš„æ¨ç†
                    if state["content_sent"]:
                        return

                    if not state["thinking_started"] and show_thinking:
                        queue.put_nowait("<think>\n")
                        state["thinking_started"] = True
                    if state["thinking_started"]:
                        queue.put_nowait(delta)

            # === å®Œæ•´æ¨ç†äº‹ä»¶ï¼ˆéæµå¼æ¨ç†ï¼‰ ===
            elif event_type == "assistant.reasoning":
                # å¤„ç†å®Œæ•´æ¨ç†å†…å®¹
                reasoning = safe_get_data_attr(event, "content") or safe_get_data_attr(
                    event, "reasoning"
                )
                if reasoning:
                    # å¦‚æœå†…å®¹å·²ç»å¼€å§‹ï¼ŒæŠ‘åˆ¶å»¶è¿Ÿåˆ°è¾¾çš„æ¨ç†
                    if state["content_sent"]:
                        return

                    if not state["thinking_started"] and show_thinking:
                        queue.put_nowait("<think>\n")
                        state["thinking_started"] = True
                    if state["thinking_started"]:
                        queue.put_nowait(reasoning)

            # === å·¥å…·æ‰§è¡Œäº‹ä»¶ ===
            elif event_type == "tool.execution_start":
                tool_name = (
                    safe_get_data_attr(event, "name")
                    or safe_get_data_attr(event, "tool_name")
                    or "æœªçŸ¥å·¥å…·"
                )
                tool_call_id = safe_get_data_attr(event, "tool_call_id", "")

                # è·å–å·¥å…·å‚æ•°
                tool_args = {}
                try:
                    args_obj = safe_get_data_attr(event, "arguments")
                    if isinstance(args_obj, dict):
                        tool_args = args_obj
                    elif isinstance(args_obj, str):
                        tool_args = json.loads(args_obj)
                except:
                    pass

                if tool_call_id:
                    active_tools[tool_call_id] = {
                        "name": tool_name,
                        "arguments": tool_args,
                    }

                # åœ¨æ˜¾ç¤ºå·¥å…·å‰å…³é—­æ€è€ƒæ ‡ç­¾
                if state["thinking_started"]:
                    queue.put_nowait("\n</think>\n")
                    state["thinking_started"] = False

                # ä½¿ç”¨æ”¹è¿›çš„æ ¼å¼å±•ç¤ºå·¥å…·è°ƒç”¨
                if tool_args:
                    tool_args_json = json.dumps(tool_args, indent=2, ensure_ascii=False)
                    tool_display = f"\n\n<details>\n<summary>ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}</summary>\n\n**å‚æ•°:**\n\n```json\n{tool_args_json}\n```\n\n</details>\n\n"
                else:
                    tool_display = f"\n\n<details>\n<summary>ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name}</summary>\n\n*æ— å‚æ•°*\n\n</details>\n\n"

                queue.put_nowait(tool_display)

                self._emit_debug_log_sync(f"å·¥å…·å¼€å§‹: {tool_name}", __event_call__)

            elif event_type == "tool.execution_complete":
                tool_call_id = safe_get_data_attr(event, "tool_call_id", "")
                tool_info = active_tools.get(tool_call_id)

                # å¤„ç†æ—§çš„å­—ç¬¦ä¸²æ ¼å¼å’Œæ–°çš„å­—å…¸æ ¼å¼
                if isinstance(tool_info, str):
                    tool_name = tool_info
                elif isinstance(tool_info, dict):
                    tool_name = tool_info.get("name", "æœªçŸ¥å·¥å…·")
                else:
                    tool_name = "æœªçŸ¥å·¥å…·"

                # å°è¯•è·å–ç»“æœå†…å®¹
                result_content = ""
                result_type = "success"
                try:
                    result_obj = safe_get_data_attr(event, "result")
                    if hasattr(result_obj, "content"):
                        result_content = result_obj.content
                    elif isinstance(result_obj, dict):
                        result_content = result_obj.get("content", "")
                        result_type = result_obj.get("result_type", "success")
                        if not result_content:
                            # å¦‚æœæ²¡æœ‰ content å­—æ®µï¼Œå°è¯•åºåˆ—åŒ–æ•´ä¸ªå­—å…¸
                            result_content = json.dumps(
                                result_obj, indent=2, ensure_ascii=False
                            )
                except Exception as e:
                    self._emit_debug_log_sync(f"æå–ç»“æœæ—¶å‡ºé”™: {e}", __event_call__)
                    result_type = "failure"
                    result_content = f"é”™è¯¯: {str(e)}"

                # ä½¿ç”¨æ”¹è¿›çš„æ ¼å¼å±•ç¤ºå·¥å…·ç»“æœ
                if result_content:
                    status_icon = "âœ…" if result_type == "success" else "âŒ"

                    # å°è¯•æ£€æµ‹å†…å®¹ç±»å‹ä»¥ä¾¿æ›´å¥½åœ°æ ¼å¼åŒ–
                    is_json = False
                    try:
                        json_obj = (
                            json.loads(result_content)
                            if isinstance(result_content, str)
                            else result_content
                        )
                        if isinstance(json_obj, (dict, list)):
                            result_content = json.dumps(
                                json_obj, indent=2, ensure_ascii=False
                            )
                            is_json = True
                    except:
                        pass

                    # æ ¹æ®å†…å®¹ç±»å‹æ ¼å¼åŒ–
                    if is_json:
                        # JSON å†…å®¹ï¼šä½¿ç”¨ä»£ç å—å’Œè¯­æ³•é«˜äº®
                        result_display = f"\n<details>\n<summary>{status_icon} æ‰§è¡Œç»“æœ: {tool_name}</summary>\n\n```json\n{result_content}\n```\n\n</details>\n\n"
                    else:
                        # çº¯æ–‡æœ¬ï¼šä¿ç•™æ ¼å¼ï¼Œä¸ä½¿ç”¨ä»£ç å—
                        result_display = f"\n<details>\n<summary>{status_icon} æ‰§è¡Œç»“æœ: {tool_name}</summary>\n\n{result_content}\n\n</details>\n\n"

                    queue.put_nowait(result_display)

            elif event_type == "tool.execution_progress":
                # å·¥å…·æ‰§è¡Œè¿›åº¦æ›´æ–°ï¼ˆç”¨äºé•¿æ—¶é—´è¿è¡Œçš„å·¥å…·ï¼‰
                tool_call_id = safe_get_data_attr(event, "tool_call_id", "")
                tool_info = active_tools.get(tool_call_id)
                tool_name = (
                    tool_info.get("name", "æœªçŸ¥å·¥å…·")
                    if isinstance(tool_info, dict)
                    else "æœªçŸ¥å·¥å…·"
                )

                progress = safe_get_data_attr(event, "progress", 0)
                message = safe_get_data_attr(event, "message", "")

                if message:
                    progress_display = f"\n> ğŸ”„ **{tool_name}**: {message}\n"
                    queue.put_nowait(progress_display)

                self._emit_debug_log_sync(
                    f"å·¥å…·è¿›åº¦: {tool_name} - {progress}%", __event_call__
                )

            elif event_type == "tool.execution_partial_result":
                # æµå¼å·¥å…·ç»“æœï¼ˆç”¨äºå¢é‡è¾“å‡ºçš„å·¥å…·ï¼‰
                tool_call_id = safe_get_data_attr(event, "tool_call_id", "")
                tool_info = active_tools.get(tool_call_id)
                tool_name = (
                    tool_info.get("name", "æœªçŸ¥å·¥å…·")
                    if isinstance(tool_info, dict)
                    else "æœªçŸ¥å·¥å…·"
                )

                partial_content = safe_get_data_attr(event, "content", "")
                if partial_content:
                    queue.put_nowait(partial_content)

                self._emit_debug_log_sync(f"å·¥å…·éƒ¨åˆ†ç»“æœ: {tool_name}", __event_call__)

            # === ä½¿ç”¨ç»Ÿè®¡äº‹ä»¶ ===
            elif event_type == "assistant.usage":
                # å½“å‰åŠ©æ‰‹å›åˆçš„ token ä½¿ç”¨é‡
                if self.valves.DEBUG:
                    input_tokens = safe_get_data_attr(event, "input_tokens", 0)
                    output_tokens = safe_get_data_attr(event, "output_tokens", 0)
                    total_tokens = safe_get_data_attr(event, "total_tokens", 0)
                pass

            elif event_type == "session.usage_info":
                # ä¼šè¯ç´¯è®¡ä½¿ç”¨ä¿¡æ¯
                pass

            # === ä¼šè¯çŠ¶æ€äº‹ä»¶ ===
            elif event_type == "session.compaction_start":
                self._emit_debug_log_sync("ä¼šè¯å‹ç¼©å·²å¼€å§‹", __event_call__)

            elif event_type == "session.compaction_complete":
                self._emit_debug_log_sync("ä¼šè¯å‹ç¼©å·²å®Œæˆ", __event_call__)

            elif event_type == "session.idle":
                # ä¼šè¯å¤„ç†å®Œæˆ - å‘å‡ºå®Œæˆä¿¡å·
                done.set()
                try:
                    queue.put_nowait(SENTINEL)
                except:
                    pass

            elif event_type == "session.error":
                error_msg = safe_get_data_attr(event, "message", "æœªçŸ¥é”™è¯¯")
                queue.put_nowait(f"\n[é”™è¯¯: {error_msg}]")
                done.set()
                try:
                    queue.put_nowait(SENTINEL)
                except:
                    pass

        unsubscribe = session.on(handler)

        self._emit_debug_log_sync(f"å·²è®¢é˜…äº‹ä»¶ã€‚æ­£åœ¨å‘é€è¯·æ±‚...", __event_call__)

        # ä½¿ç”¨ asyncio.create_task é˜²æ­¢ session.send é˜»å¡æµè¯»å–
        # å¦‚æœ SDK å®ç°ç­‰å¾…å®Œæˆã€‚
        send_task = asyncio.create_task(session.send(send_payload))
        self._emit_debug_log_sync(f"Prompt å·²å‘é€ (å¼‚æ­¥ä»»åŠ¡å·²å¯åŠ¨)", __event_call__)

        # å®‰å…¨çš„åˆå§‹ yieldï¼Œå¸¦é”™è¯¯å¤„ç†
        try:
            if self.valves.DEBUG:
                yield "<think>\n"
                if init_message:
                    yield init_message

                if reasoning_effort and reasoning_effort != "off":
                    yield f"> [Debug] å·²æ³¨å…¥æ¨ç†å¼ºåº¦ (Reasoning Effort): {reasoning_effort.upper()}\n"

                yield "> [Debug] è¿æ¥å·²å»ºç«‹ï¼Œç­‰å¾…å“åº”...\n"
                self.thinking_started = True
        except Exception as e:
            # å¦‚æœåˆå§‹ yield å¤±è´¥ï¼Œè®°å½•ä½†ç»§ç»­å¤„ç†
            self._emit_debug_log_sync(f"åˆå§‹ yield è­¦å‘Š: {e}", __event_call__)

        try:
            while not done.is_set():
                try:
                    chunk = await asyncio.wait_for(
                        queue.get(), timeout=float(self.valves.TIMEOUT)
                    )
                    if chunk is SENTINEL:
                        break
                    if chunk:
                        has_content = True
                        try:
                            yield chunk
                        except Exception as yield_error:
                            # å®¢æˆ·ç«¯å…³é—­è¿æ¥ï¼Œä¼˜é›…åœæ­¢
                            self._emit_debug_log_sync(
                                f"Yield é”™è¯¯ï¼ˆå®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Ÿï¼‰: {yield_error}",
                                __event_call__,
                            )
                            break
                except asyncio.TimeoutError:
                    if done.is_set():
                        break
                    if self.thinking_started:
                        try:
                            yield f"> [Debug] ç­‰å¾…å“åº”ä¸­ (å·²è¶…è¿‡ {self.valves.TIMEOUT} ç§’)...\n"
                        except:
                            # å¦‚æœè¶…æ—¶æœŸé—´ yield å¤±è´¥ï¼Œè¿æ¥å·²æ–­å¼€
                            break
                    continue

            while not queue.empty():
                chunk = queue.get_nowait()
                if chunk is SENTINEL:
                    break
                if chunk:
                    has_content = True
                    try:
                        yield chunk
                    except:
                        # è¿æ¥å…³é—­ï¼Œåœæ­¢ yielding
                        break

            if self.thinking_started:
                try:
                    yield "\n</think>\n"
                    has_content = True
                except:
                    pass  # è¿æ¥å·²å…³é—­

            # æ ¸å¿ƒä¿®å¤ï¼šå¦‚æœæ•´ä¸ªè¿‡ç¨‹æ²¡æœ‰ä»»ä½•è¾“å‡ºï¼Œè¿”å›ä¸€ä¸ªæç¤ºï¼Œé˜²æ­¢ OpenWebUI æŠ¥é”™
            if not has_content:
                try:
                    yield "âš ï¸ Copilot æœªè¿”å›ä»»ä½•å†…å®¹ã€‚è¯·æ£€æŸ¥æ¨¡å‹ ID æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•åœ¨ Valves ä¸­å¼€å¯ DEBUG æ¨¡å¼æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ã€‚"
                except:
                    pass  # è¿æ¥å·²å…³é—­

        except Exception as e:
            try:
                yield f"\n[Stream Error: {str(e)}]"
            except:
                pass  # è¿æ¥å·²å…³é—­
        finally:
            unsubscribe()
            # é”€æ¯ä¼šè¯å¯¹è±¡ä»¥é‡Šæ”¾å†…å­˜ï¼Œä½†ä¿ç•™ç£ç›˜æ•°æ®
            await session.destroy()
